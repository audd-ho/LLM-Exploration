{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation Function Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Segmentation Function PREPARATION FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Semantic Segmentation Function PREPARATION FUNCTIONS\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "def window(seq, n=3):\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def climb(co_score_list, list_index, mode = \"l\"):\n",
    "    res_score = 0\n",
    "    if mode == \"l\":\n",
    "        while (list_index >= 0):\n",
    "            if co_score_list[list_index] > res_score:\n",
    "                res_score = co_score_list[list_index]\n",
    "                list_index -= 1\n",
    "            else:\n",
    "                break\n",
    "        return res_score\n",
    "    else:\n",
    "        list_len = len(co_score_list)\n",
    "        while (list_index < list_len):\n",
    "            if co_score_list[list_index] > res_score:\n",
    "                res_score = co_score_list[list_index]\n",
    "                list_index += 1\n",
    "            else:\n",
    "                break\n",
    "        return res_score\n",
    "    \n",
    "def get_depth_score_list(co_score_list):\n",
    "    res_depth_score_list = []\n",
    "    co_score_len = len(co_score_list)\n",
    "    for i in range(co_score_len):\n",
    "        i_co_score = co_score_list[i]\n",
    "        l_peak = climb(co_score_list, i, \"l\")\n",
    "        r_peak = climb(co_score_list, i, \"r\")\n",
    "        i_depth_score = 0.5 * (l_peak + r_peak - (2*i_co_score))\n",
    "        res_depth_score_list.append(i_depth_score)\n",
    "    return np.array(res_depth_score_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import argrelmax\n",
    "\n",
    "def get_local_maxima(depth_scores, order=1):\n",
    "    maxima_ids = argrelmax(depth_scores, order=order)[0]\n",
    "    filtered_scores = np.zeros(len(depth_scores))\n",
    "    filtered_scores[maxima_ids] = depth_scores[maxima_ids]\n",
    "    return filtered_scores\n",
    "\n",
    "def compute_threshold(scores): ## maybe can make this more picky, by making threshold higher, like (np.std(s) / 3) or /4 or more instead?\n",
    "    s = scores[np.nonzero(scores)]\n",
    "    threshold = np.mean(s) - (np.std(s) / 2)\n",
    "    # threshold = np.mean(s) - (np.std(s))\n",
    "    return threshold\n",
    "\n",
    "def get_threshold_segments(scores, threshold=0.1):\n",
    "    segment_ids = np.where(scores >= threshold)[0]\n",
    "    return segment_ids\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def primitively_naive_tokeniser(text):\n",
    "    toks_list = text.split(\" \")\n",
    "    return toks_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Segmentation Function Portions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Semantic Segmentation Function Portions\n",
    "\n",
    "WINDOW_SIZE = 3\n",
    "\n",
    "def sentence_to_sliding_window(sentence_s):\n",
    "    sentence_words_toks = primitively_naive_tokeniser(sentence_s)\n",
    "    window_size_split = list(window(sentence_words_toks, WINDOW_SIZE))\n",
    "    window_splited_texts = [' '.join([window_toks for window_toks in each_window]) for each_window in window_size_split]\n",
    "    return window_splited_texts\n",
    "\n",
    "def coherence_score_list_from_embedding_list(window_splited_embedding_list):\n",
    "    coherence_scores_list = [cosine_sim(pair[0], pair[1]) for pair in zip(window_splited_embedding_list[:-1], window_splited_embedding_list[1:])]\n",
    "    return coherence_scores_list\n",
    "\n",
    "def plot_data_points(vary_data, thres = -1):\n",
    "    plt.plot(vary_data)\n",
    "    if (thres == -1):\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.plot([thres for i in range(len(vary_data))])\n",
    "        plt.show()\n",
    "\n",
    "def filtered_indexes_list_to_splitted_segments_by_semantics(original_sent, filtered_indexes_list):\n",
    "    sentence_words_toks = primitively_naive_tokeniser(original_sent)\n",
    "    segment_key_breaks = get_threshold_segments(filtered_indexes_list, compute_threshold(filtered_indexes_list))\n",
    "    segment_demark = [0] + [(ids + (WINDOW_SIZE-1)) for ids in segment_key_breaks] + [len(sentence_words_toks)]\n",
    "    segment_demark_intervals = list(zip(segment_demark[:-1], segment_demark[1:]))\n",
    "    resultant_segments_after_split_by_interval = [\" \".join(sentence_words_toks[interval_points[0]:interval_points[1]]) for interval_points in segment_demark_intervals]\n",
    "    return resultant_segments_after_split_by_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Segmentation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Semantic Segmentation Function\n",
    "\n",
    "def semantic_segmentation_function(embedding_model_function, sentence_text, intermediate_status = False, graph_status = False):\n",
    "    windowed_parts = sentence_to_sliding_window(sentence_text)\n",
    "    if intermediate_status:\n",
    "        print(f\"windowed_parts: {windowed_parts}\")\n",
    "    \n",
    "    # if ensure \"embedding_model_function\" accept only 1 string and return 1d array/tensor then can use the below code, current should still work!!, as long as return 1d array for single string!!\n",
    "    # embedding_list = [embedding_model_function(windowed_part) for windowed_part in windowed_parts]\n",
    "    \n",
    "    ## if list of input strings can produce 2d array/tensor automatically, then can just use below one!!, only 1 time embed bunch at once!!\n",
    "    embedding_list = embedding_model_function(windowed_parts)\n",
    "    if intermediate_status:\n",
    "        print(f\"embedding_list: {embedding_list}\")\n",
    "    \"\"\"\n",
    "    if graph_status:\n",
    "        print(\"Embedding List Plot\") # bad! like no use\n",
    "        plot_data_points(embedding_list) # bad! like no use\n",
    "    \"\"\"\n",
    "    \n",
    "    windowed_parts_coherence_score_list = coherence_score_list_from_embedding_list(embedding_list)\n",
    "    if intermediate_status:\n",
    "        print(f\"windowed_parts_coherence_score_list: {windowed_parts_coherence_score_list}\")\n",
    "    if graph_status:\n",
    "        print(\"Coherence Score Plot:\")\n",
    "        plot_data_points(windowed_parts_coherence_score_list)\n",
    "    \n",
    "    windowed_parts_depth_score_list = get_depth_score_list(windowed_parts_coherence_score_list)\n",
    "    if intermediate_status:\n",
    "        print(f\"windowed_parts_depth_score_list: {windowed_parts_depth_score_list}\")\n",
    "    if graph_status:\n",
    "        print(\"Depth Score Plot:\")\n",
    "        plot_data_points(windowed_parts_depth_score_list)\n",
    "    \n",
    "    windowed_parts_filtered_depth_score_list = get_local_maxima(windowed_parts_depth_score_list)\n",
    "    if intermediate_status:\n",
    "        print(f\"windowed_parts_filtered_depth_score_list: {windowed_parts_filtered_depth_score_list}\")\n",
    "    if graph_status:\n",
    "        print(\"Filtered Depth Score Plot:\")\n",
    "        plot_data_points(windowed_parts_filtered_depth_score_list)\n",
    "    \n",
    "    filtered_threshold = compute_threshold(windowed_parts_filtered_depth_score_list)\n",
    "    if intermediate_status:\n",
    "        print(f\"filtered_threshold: {filtered_threshold}\")\n",
    "    if graph_status:\n",
    "        print(\"Filtered Depth Score With Threshold Line Plot:\")\n",
    "        plot_data_points(windowed_parts_filtered_depth_score_list, filtered_threshold)\n",
    "\n",
    "    #sentences_tokenised = primitively_naive_tokeniser(sentences)\n",
    "    #sentences_topics_splitted = filtered_indexes_list_to_splitted_sent(sentences_tokenised, windowed_sentences_filtered_depth_score_v1_list)\n",
    "    sentences_topics_splitted = filtered_indexes_list_to_splitted_segments_by_semantics(sentence_text, windowed_parts_filtered_depth_score_list)\n",
    "    return sentences_topics_splitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lock Model\n",
    "def lock_semantic_segmentation_function(embedding_model_function):\n",
    "    def lockED_semantic_segmentation_function(sentence_text, intermediate_status = False, graph_status = False): # all these default params need to have because the locked function can have the option to leave the args blank for them to let it be default!\n",
    "        return semantic_segmentation_function(embedding_model_function=embedding_model_function, sentence_text=sentence_text, intermediate_status=intermediate_status, graph_status=graph_status)\n",
    "    return lockED_semantic_segmentation_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Example Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Employees receive free flight benefits',\n",
       " 'to return to home country once',\n",
       " 'a year and',\n",
       " 'free flight benefits for business trips']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Eg. \"get_sentence_embedding_MiniLM_L6_v2\" embedding and statuses = False\n",
    "semantic_segmentation_function(get_sentence_embedding_MiniLM_L6_v2, \"Employees receive free flight benefits to return to home country once a year and free flight benefits for business trips\", intermediate_status=False, graph_status=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Employees receive free flight benefits',\n",
       " 'to return to home country once',\n",
       " 'a year and',\n",
       " 'free flight benefits for business trips']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Locked Model\n",
    "semantic_segmentation_locked_model_MiniLM_L6_v2 = lock_semantic_segmentation_function(get_sentence_embedding_MiniLM_L6_v2)\n",
    "semantic_segmentation_locked_model_MiniLM_L6_v2(\"Employees receive free flight benefits to return to home country once a year and free flight benefits for business trips\", intermediate_status=False, graph_status=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
