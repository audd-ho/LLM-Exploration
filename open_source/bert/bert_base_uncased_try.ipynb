{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google-bert/bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "## this is for masking version of the bert model!\n",
    "\"\"\"\n",
    "\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased-venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## for embedding!!, use BertModel and not AutoModelForMaskedLM\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\"abc\"]\n",
    "\n",
    "# Tokenize and encode text using batch_encode_plus\n",
    "# The function returns a dictionary containing the token IDs and attention masks\n",
    "encoding = tokenizer.batch_encode_plus(\n",
    "    text,                    # List of input texts\n",
    "    padding=True,              # Pad to the maximum sequence length\n",
    "    truncation=True,           # Truncate to the maximum sequence length if necessary\n",
    "    return_tensors='pt',      # Return PyTorch tensors\n",
    "    add_special_tokens=True    # Add special tokens CLS and SEP\n",
    ")\n",
    "\n",
    "print(encoding) \n",
    "\n",
    "input_ids = encoding['input_ids']  # Token IDs\n",
    "# print input IDs\n",
    "print(f\"Input ID: {input_ids}\")\n",
    "attention_mask = encoding['attention_mask']  # Attention mask\n",
    "# print attention mask\n",
    "print(f\"Attention mask: {attention_mask}\")\n",
    "\n",
    "\n",
    "# Generate embeddings using BERT model\n",
    "with torch.no_grad(): ## need import torch if want use/do this\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    word_embeddings = outputs.last_hidden_state  # This contains the embeddings\n",
    "\n",
    "# Decode the token IDs back to text\n",
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "#print decoded text\n",
    "print(f\"Decoded Text: {decoded_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized Text: ['abc', '##12', '##3']\n",
      "Encoded Text: tensor([[  101,  5925, 12521,  2509,   102]])\n",
      "{'input_ids': tensor([[  101,  5925, 12521,  2509,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "text = \"abc123\"\n",
    "\n",
    "# Tokenize the text again for reference\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "#print tokenized text\n",
    "print(f\"tokenized Text: {tokenized_text}\")\n",
    "# Encode the text\n",
    "encoded_text = tokenizer.encode(text, return_tensors='pt')  # Returns a tensor\n",
    "# Print encoded text\n",
    "print(f\"Encoded Text: {encoded_text}\")\n",
    "\n",
    "encoded_text_plus = tokenizer.encode_plus(text, return_tensors='pt')\n",
    "print(encoded_text_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1:  MaskedLMOutput(loss=None, logits=tensor([[[ -6.5954,  -6.5422,  -6.5436,  ...,  -5.7315,  -5.6304,  -3.7748],\n",
      "         [ -7.5854,  -7.7376,  -7.7166,  ...,  -7.6155,  -7.8209,  -2.3627],\n",
      "         [ -5.1827,  -5.8171,  -5.9971,  ...,  -5.1309,  -6.4651,  -3.5165],\n",
      "         [-10.3041, -10.6987, -10.7929,  ...,  -9.5141,  -9.8526,  -6.2101],\n",
      "         [-11.1503, -10.8655, -10.8055,  ...,  -8.7106,  -9.5394,  -8.8477]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "output = model(encoded_text)\n",
    "print(\"#1: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BertForMaskedLM(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BertOnlyMLMHead(\n    (predictions): BertLMPredictionHead(\n      (transform): BertPredictionHeadTransform(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (transform_act_fn): GELUActivation()\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n    )\n  )\n) argument after ** must be a mapping, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_text) \u001b[38;5;66;03m## cannot cos \"argument after ** must be a mapping, not Tensor\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#2: \u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "\u001b[1;31mTypeError\u001b[0m: BertForMaskedLM(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (cls): BertOnlyMLMHead(\n    (predictions): BertLMPredictionHead(\n      (transform): BertPredictionHeadTransform(\n        (dense): Linear(in_features=768, out_features=768, bias=True)\n        (transform_act_fn): GELUActivation()\n        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      )\n      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n    )\n  )\n) argument after ** must be a mapping, not Tensor"
     ]
    }
   ],
   "source": [
    "output = model(**encoded_text) ## cannot cos \"argument after ** must be a mapping, not Tensor\"\n",
    "print(\"#2: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoded_text_plus\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#3: \u001b[39m\u001b[38;5;124m\"\u001b[39m, output)\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1487\u001b[0m, in \u001b[0;36mBertForMaskedLM.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1479\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;124;03m    Labels for computing the masked language modeling loss. Indices should be in `[-100, 0, ...,\u001b[39;00m\n\u001b[0;32m   1481\u001b[0m \u001b[38;5;124;03m    config.vocab_size]` (see `input_ids` docstring) Tokens with indices set to `-100` are ignored (masked), the\u001b[39;00m\n\u001b[0;32m   1482\u001b[0m \u001b[38;5;124;03m    loss is only computed for the tokens with labels in `[0, ..., config.vocab_size]`\u001b[39;00m\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1485\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1487\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1488\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1489\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1493\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1495\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1502\u001b[0m prediction_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls(sequence_output)\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1052\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1050\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot specify both input_ids and inputs_embeds at the same time\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1052\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwarn_if_padding_and_no_attention_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1053\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\transformers\\modeling_utils.py:4457\u001b[0m, in \u001b[0;36mPreTrainedModel.warn_if_padding_and_no_attention_mask\u001b[1;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[0;32m   4454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   4456\u001b[0m \u001b[38;5;66;03m# Check only the first and last input IDs to reduce overhead.\u001b[39;00m\n\u001b[1;32m-> 4457\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43minput_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[0;32m   4458\u001b[0m     warn_string \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   4459\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe strongly recommend passing in an `attention_mask` since your input_ids may be padded. See \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4460\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/troubleshooting\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4461\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#incorrect-output-when-padding-tokens-arent-masked.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4462\u001b[0m     )\n\u001b[0;32m   4464\u001b[0m     \u001b[38;5;66;03m# If the pad token is equal to either BOS, EOS, or SEP, we do not know whether the user should use an\u001b[39;00m\n\u001b[0;32m   4465\u001b[0m     \u001b[38;5;66;03m# attention_mask or not. In this case, we should still show a warning because this is a rare case.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\bert\\bert-base-uncased\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:256\u001b[0m, in \u001b[0;36mBatchEncoding.__getitem__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[item]\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encodings \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encodings\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m    258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key][item] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mkeys()}\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "output = model(encoded_text_plus)\n",
    "print(\"#3: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#4:  MaskedLMOutput(loss=None, logits=tensor([[[ -6.5954,  -6.5422,  -6.5436,  ...,  -5.7315,  -5.6304,  -3.7748],\n",
      "         [ -7.5854,  -7.7376,  -7.7166,  ...,  -7.6155,  -7.8209,  -2.3627],\n",
      "         [ -5.1827,  -5.8171,  -5.9971,  ...,  -5.1309,  -6.4651,  -3.5165],\n",
      "         [-10.3041, -10.6987, -10.7929,  ...,  -9.5141,  -9.8526,  -6.2101],\n",
      "         [-11.1503, -10.8655, -10.8055,  ...,  -8.7106,  -9.5394,  -8.8477]]],\n",
      "       grad_fn=<ViewBackward0>), hidden_states=None, attentions=None)\n"
     ]
    }
   ],
   "source": [
    "output = model(**encoded_text_plus)\n",
    "print(\"#4: \", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(text):\n",
    "    encoded_text_with_input_ids_and_attention_masks_etc = tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
    "    model_output =  model(**encoded_text_with_input_ids_and_attention_masks_etc)\n",
    "    \"\"\"\n",
    "    print(tokenizer.tokenize(text))\n",
    "    print(encoded_text_with_input_ids_and_attention_masks_etc)\n",
    "    \n",
    "    print(model_output)\n",
    "\n",
    "    print(model_output[0])\n",
    "    print(model_output.last_hidden_state)\n",
    "    \"\"\"\n",
    "    return model_output[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_word_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mi want to kill people\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mget_word_embedding\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_word_embedding\u001b[39m(text):\n\u001b[1;32m----> 2\u001b[0m     encoded_text_with_input_ids_and_attention_masks_etc \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mencode_plus(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     model_output \u001b[38;5;241m=\u001b[39m  model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_text_with_input_ids_and_attention_masks_etc)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m    print(tokenizer.tokenize(text))\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    print(encoded_text_with_input_ids_and_attention_masks_etc)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    print(model_output.last_hidden_state)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "get_word_embedding(\"i want to kill people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(text):\n",
    "    encoded_text_with_input_ids_and_attention_masks_etc = tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
    "    model_output =  model(**encoded_text_with_input_ids_and_attention_masks_etc)\n",
    "    return model_output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0106,  0.1323,  0.1282,  ..., -0.4946,  0.0366,  0.1418],\n",
      "        [ 0.2336,  0.2490, -0.1087,  ..., -0.3529,  0.3312,  0.3367],\n",
      "        [ 0.9315,  0.9158,  1.1255,  ..., -0.9469, -0.0023,  0.0410],\n",
      "        [-0.1725, -0.7705,  0.8230,  ..., -0.2080, -0.0336, -0.7374],\n",
      "        [ 0.6461, -0.0204, -0.1173,  ..., -0.2163, -0.6109, -0.3366]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(get_word_embedding(\"i love you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('[CLS]',\n",
       "  tensor([-3.5563e-01,  7.6927e-02, -1.0376e-01, -4.0746e-02, -2.1151e-01,\n",
       "           8.2666e-02,  2.2463e-01,  2.4771e-01, -2.0665e-01, -4.6616e-02,\n",
       "          -9.9115e-02, -1.7627e-02, -6.3732e-02,  2.5278e-01,  9.8815e-03,\n",
       "           9.7530e-02, -2.6173e-01,  3.9854e-01,  2.9848e-01, -1.4321e-01,\n",
       "          -2.3226e-01, -1.8624e-01, -2.2774e-01, -3.6241e-01,  4.7075e-02,\n",
       "          -4.9511e-02, -4.5702e-02, -7.3345e-02,  2.2849e-01,  2.2118e-01,\n",
       "          -8.9468e-03,  2.4675e-01, -1.1940e-01,  5.2065e-03,  1.8890e-02,\n",
       "           1.2755e-01, -1.0527e-02, -1.9132e-02, -1.1296e-02,  2.1618e-01,\n",
       "           4.9049e-02, -8.2607e-02,  1.5517e-01, -4.3656e-02, -1.1945e-02,\n",
       "          -2.3611e-01, -1.7448e+00,  4.5237e-02, -2.5230e-01, -7.9770e-04,\n",
       "          -2.5913e-01,  4.7024e-02,  1.4371e-01,  1.8214e-01, -6.4814e-02,\n",
       "           4.5649e-01, -1.2924e-01,  5.4144e-01,  1.6165e-01,  2.0138e-01,\n",
       "          -1.8698e-01, -1.5207e-01, -1.1585e-01,  1.5808e-01, -2.8148e-04,\n",
       "           1.4871e-01,  1.7055e-02,  4.2038e-01, -1.3273e-01,  3.5793e-01,\n",
       "          -2.9688e-01,  1.3736e-01,  1.8978e-01, -1.9542e-02, -7.6112e-02,\n",
       "          -1.5352e-01, -9.1118e-02,  1.7137e-01, -1.4371e-01,  5.2238e-02,\n",
       "           9.8099e-02, -7.3760e-03,  1.2133e-01,  2.2774e-01,  1.9517e-01,\n",
       "           2.4847e-01, -1.9410e-01, -2.6967e-01,  2.9423e-01,  4.7249e-01,\n",
       "           5.8350e-02, -1.0221e-01,  1.0323e-01,  2.6148e-01,  2.4761e-01,\n",
       "          -8.5738e-02,  3.7285e-02, -5.7376e-03,  1.8078e-01,  1.5713e-01,\n",
       "          -1.8656e-01, -3.9871e-02,  4.0362e-02, -1.4639e-01, -2.4548e-01,\n",
       "          -1.5333e-02, -2.3682e-01, -6.8488e-02,  6.2805e-02, -3.0023e+00,\n",
       "           1.6778e-01,  1.4484e-01, -2.3979e-01,  8.5677e-02,  1.9993e-01,\n",
       "           5.0499e-01,  4.7067e-01,  9.4759e-02,  1.2264e-01,  8.8886e-02,\n",
       "           7.6023e-02,  5.7617e-01, -4.9145e-02,  2.2105e-02,  3.3418e-01,\n",
       "           5.2684e-01,  1.2845e-01, -2.5794e-02,  3.2082e-02,  8.7711e-02,\n",
       "          -3.3012e-02,  3.4234e-01,  1.7122e-01, -1.8027e-01, -1.0082e-01,\n",
       "          -2.3073e-01,  5.8173e-02,  2.4684e-01,  1.3699e-01, -9.5618e-03,\n",
       "          -3.3030e-01, -1.5983e-01, -3.3910e+00,  1.1860e-01,  4.7153e-01,\n",
       "          -9.2577e-03, -3.5797e-01, -4.3795e-03,  1.0914e-01,  3.5781e-01,\n",
       "          -1.2245e-02, -3.7333e-02,  6.0519e-02,  2.4974e-01, -1.4597e-01,\n",
       "           1.7222e-01, -2.4385e-02, -1.3090e-01,  1.6813e-02,  3.7768e-01,\n",
       "          -1.0150e-01,  1.1629e-01,  3.2390e-02, -1.4512e-01,  1.0032e-01,\n",
       "          -9.0777e-02,  5.6637e-02,  2.3673e-01,  2.8599e-01, -1.0875e-02,\n",
       "          -4.8993e-01, -3.7000e-01,  5.5471e-02,  2.0874e-01,  3.1958e-01,\n",
       "          -2.9152e-01,  1.7289e-01,  2.4142e-01,  7.0384e-02,  3.8783e-02,\n",
       "          -8.9563e-02,  2.5189e-01, -2.9841e-02, -1.4201e-01,  8.3311e-02,\n",
       "           1.1770e-01,  3.2843e-01, -3.0387e-01,  1.6032e-01, -1.0824e-01,\n",
       "          -9.6169e-02,  2.7300e-01,  3.6416e-01,  8.9572e-02,  2.5097e-01,\n",
       "          -8.0737e-02,  1.0499e-01, -2.7267e-01,  4.4746e-01,  2.8913e-01,\n",
       "           1.9893e-01,  8.5552e-02,  1.6265e-01, -2.7635e-02,  6.5260e-02,\n",
       "           3.8242e+00, -3.7222e-02, -2.7413e-01,  7.0333e-02, -5.3708e-02,\n",
       "          -2.9120e-02,  2.6342e-01,  1.8494e-01, -1.3595e-01,  1.7186e-01,\n",
       "          -3.1585e-01,  5.9927e-01,  4.1810e-02,  1.2124e-01, -1.5373e-01,\n",
       "           2.5993e-01, -7.4407e-02,  9.6991e-02,  1.3018e-01, -2.8232e-01,\n",
       "           4.0544e-01,  1.2989e-01,  2.3906e-01, -8.3537e-02, -7.9893e-01,\n",
       "           1.0756e-01, -1.6334e-01, -1.9114e-01,  2.3868e-01, -1.5593e-01,\n",
       "           7.1013e-02, -5.0475e-02, -2.0780e-01,  1.9453e-01,  4.6358e-02,\n",
       "           1.3056e-01,  1.8996e-01,  9.6201e-02, -8.5892e-03, -3.7107e-01,\n",
       "          -1.8096e-01,  5.8108e-01,  2.2029e-02,  1.3759e-01,  5.4928e-02,\n",
       "           2.3696e-01, -1.5094e-01, -2.2810e-01, -2.8787e-01, -1.8803e-01,\n",
       "           5.3236e-02,  2.1528e-02,  2.9432e-02, -2.2831e-01,  6.4735e-03,\n",
       "          -3.3072e-01, -6.4221e-02,  4.1011e-01, -1.8429e-01, -1.4029e-01,\n",
       "          -3.7026e-01, -1.4257e-01, -9.2791e-02,  3.6424e-01, -8.5312e-02,\n",
       "           3.5944e-02, -6.0699e-02, -1.4260e-01, -4.6536e+00, -5.3353e-02,\n",
       "           2.5050e-01,  2.3513e-01,  2.4082e-01, -2.1649e-01,  1.2152e-01,\n",
       "           5.1230e-01,  1.1616e-01, -9.1973e-02,  2.2929e-01,  6.8202e-02,\n",
       "          -6.7348e-03,  1.9093e-01, -3.6088e-01,  2.4668e-01, -3.6373e-02,\n",
       "           2.1537e-01,  5.8886e-02,  5.5879e-02,  1.9958e-01,  4.0623e-01,\n",
       "          -2.9246e-01, -3.1787e-01,  2.7477e-01, -2.4600e-01, -5.5469e-02,\n",
       "           1.4135e-01,  1.0890e-01, -3.3810e-01, -1.1560e-01, -3.3233e-02,\n",
       "           1.5060e-01, -6.0958e-02, -9.9737e-02, -2.7473e+00, -1.3252e-01,\n",
       "          -1.7580e-02, -3.2218e-01, -9.4158e-03, -1.0258e-01,  2.6615e-01,\n",
       "           9.8870e-02, -5.9053e-02,  2.5780e-01, -1.3786e-01,  8.4401e-02,\n",
       "          -1.7436e-01,  3.2138e-01, -4.4963e-02,  2.5366e-01,  2.1390e-01,\n",
       "           3.0169e-01,  1.2938e-01,  2.4956e-02,  1.5027e-01,  1.3930e-02,\n",
       "          -1.1464e-01,  1.1472e-01,  4.8819e-02,  2.4699e-01, -1.2547e-01,\n",
       "          -7.5868e-02, -3.5706e-01, -7.1161e-02,  6.3965e-02, -8.5881e-02,\n",
       "          -1.2865e-01,  2.7720e-02, -2.2913e-01, -2.9208e-01,  4.8092e-01,\n",
       "           7.5831e-02,  3.7884e-01,  1.7438e-01, -1.1658e-01,  3.7816e-01,\n",
       "           1.5810e-01,  7.4594e-02,  2.0224e-01,  1.7448e-01, -4.5792e-02,\n",
       "          -2.5041e-01,  1.3977e-01, -1.5287e-01, -1.3497e-01, -9.4000e-02,\n",
       "           1.1489e+00, -1.2379e-01,  2.5239e-01, -1.1883e-02,  1.8763e-01,\n",
       "           5.5686e-02,  3.3671e-01,  2.1763e-01,  6.9452e-01,  1.9396e-01,\n",
       "           1.3329e-01, -2.1548e-01, -8.6666e-02, -2.4397e-01,  1.0747e-01,\n",
       "          -4.1623e-01, -2.0424e-01,  1.5013e-02, -3.3559e-01,  1.6908e-01,\n",
       "           9.1319e-02, -7.5311e-01, -5.5078e-02,  1.1124e-01, -2.0882e-01,\n",
       "           2.5067e-01,  5.1852e-02, -1.3725e-01, -3.9512e-01, -2.3935e-04,\n",
       "           6.6938e-03,  2.9656e-01, -3.9472e-02,  7.8780e-02, -4.5643e-02,\n",
       "          -4.4805e-02, -3.6399e-02,  2.4839e-01, -1.4848e-01,  2.3771e-01,\n",
       "          -7.6058e-03,  6.3956e-02, -4.0664e-02,  1.6051e-01,  3.3218e-01,\n",
       "          -7.0817e-01,  2.3699e-01, -2.0451e-01, -1.9799e-01, -2.8198e-01,\n",
       "          -1.3689e-01, -6.3562e-04, -3.2594e-01,  4.5677e-02, -1.4067e-01,\n",
       "           1.3995e-02,  2.1872e-01,  2.2067e-01,  8.3336e-02,  2.1836e-01,\n",
       "          -5.9063e-02,  1.1082e-01,  7.7352e-01,  1.3541e-01, -2.1983e-01,\n",
       "           1.7048e-01,  8.7768e-02,  3.0950e-01, -7.9072e-02,  2.8357e-01,\n",
       "           6.7676e-02,  3.6836e-02,  1.1412e-01,  7.6120e-02,  1.4425e-01,\n",
       "          -1.7579e-01, -4.6774e-01, -2.3972e-01, -1.5395e-01, -3.2422e-01,\n",
       "          -3.0400e-02, -5.1857e-01,  6.8480e-03, -2.1795e-01, -3.9859e-01,\n",
       "           3.8566e-01,  1.7875e-01,  4.2450e-02,  2.2570e-01, -2.1368e-02,\n",
       "          -1.4588e-01,  4.6620e-01,  9.3044e-02,  2.6144e-01,  1.6895e-01,\n",
       "          -1.1229e-01, -9.0379e-02,  2.1042e-01,  1.9110e-01, -4.7206e-01,\n",
       "           2.7616e-01, -2.4612e-02,  2.9308e-02, -2.0340e-01,  1.2981e-01,\n",
       "          -2.2965e-01, -5.3958e-02,  2.2825e-01, -9.1594e-02,  3.5433e-02,\n",
       "          -1.0121e+00,  1.9641e-01,  2.4373e-01, -1.8377e-01,  2.8095e-01,\n",
       "          -7.8517e-02, -1.4795e-01,  4.2271e-01, -1.4965e-01, -7.8581e-04,\n",
       "          -3.1968e-01, -8.4549e-02, -1.6578e-01, -1.1817e-01, -9.4112e-02,\n",
       "          -3.1969e-02,  2.3920e-01,  1.3956e-01,  7.2511e-03,  2.2806e-01,\n",
       "          -1.6617e-01,  4.8628e-01, -2.5384e-02, -4.3342e-01, -4.5665e-02,\n",
       "          -1.1847e-01, -1.7135e-02,  3.8343e-01, -2.6285e-01, -1.3555e-01,\n",
       "           1.8981e-01, -1.8953e-01, -3.5865e-01, -1.3915e-01, -4.9855e-02,\n",
       "           1.1492e-01,  7.5565e-02, -3.5044e-03,  2.8247e-01,  2.7226e-01,\n",
       "          -1.7150e-01, -1.5318e-01, -8.4756e-02, -4.0751e-01,  3.7492e-01,\n",
       "           3.2680e-01, -2.7532e-01,  1.8109e-01,  3.1316e-01, -2.5721e-01,\n",
       "          -1.2891e-01, -2.2270e-02,  1.9260e-02, -1.4139e-01, -2.5980e-02,\n",
       "           1.1315e-01,  4.8945e-02, -3.4875e-01, -3.2943e-01, -1.6319e-01,\n",
       "           1.4903e-01, -1.2854e-01, -1.0961e-01,  1.2659e-01, -1.2943e-01,\n",
       "          -5.5408e-01,  2.2294e-01,  8.6372e-02, -6.8352e-02,  1.5346e-01,\n",
       "           2.9015e-01,  9.1236e-02, -7.5354e-02,  4.8562e-02, -6.3045e-01,\n",
       "           1.9562e-01, -1.3461e-01,  2.6878e-02,  1.1711e-02, -3.9163e-01,\n",
       "           9.4303e-03, -3.9277e-01, -4.7435e-01, -1.3973e-01, -1.1065e-01,\n",
       "           8.4196e-02,  8.7448e-02,  2.4210e-01, -1.5749e-01, -4.0002e-02,\n",
       "          -2.8608e-01, -3.6889e-01,  4.1274e-01,  3.7727e-03,  2.7179e-01,\n",
       "          -1.5093e-01, -7.3036e-03,  1.8892e-01, -7.7716e-02,  1.0497e-01,\n",
       "          -8.5285e-02,  4.2692e-01, -3.1749e-02,  2.1652e-01,  1.3588e-02,\n",
       "          -6.1896e-02,  3.3835e-01,  1.6895e-01, -3.0104e-01, -4.6104e-02,\n",
       "           6.5377e-02,  4.1560e-01, -1.9487e-01, -2.8897e-01,  1.4032e-01,\n",
       "           1.0983e-01, -1.8564e-02, -9.8332e-03,  2.4729e+00,  5.0511e-01,\n",
       "           1.2566e-01,  1.9425e-01,  2.0179e-01,  1.8505e-03,  6.1780e-02,\n",
       "          -2.3904e-01, -8.7246e-02,  2.5006e-01, -1.4336e-01,  8.9684e-02,\n",
       "          -3.2210e-01,  2.5413e-01,  8.0081e-02,  8.4717e-02, -2.4975e-01,\n",
       "          -2.8568e-01, -2.2653e-01,  1.2322e-01, -2.4607e-01,  1.6470e-01,\n",
       "           1.4594e-01, -5.9774e-02,  2.9788e-02,  4.6548e-02,  1.0806e-01,\n",
       "          -3.0954e-01,  2.1963e-03, -8.8848e-02, -2.0297e-01, -3.7273e-03,\n",
       "           1.3123e-01,  3.1235e-01,  3.3788e-02,  3.0658e-01,  8.8463e-02,\n",
       "          -4.5722e-01, -3.1182e-01,  4.4481e-02, -1.0926e-01, -1.0247e-01,\n",
       "           4.5586e-01,  6.7874e-02,  1.1407e-01,  2.7594e-01,  4.7243e-02,\n",
       "          -3.0824e-01,  1.2806e-01,  5.5878e-02,  5.5094e-03, -4.1378e-01,\n",
       "          -2.5646e-01, -7.1456e-03, -2.6403e-01, -7.7779e-02,  7.8044e-02,\n",
       "          -2.1099e-03, -2.0918e-01,  3.6681e-01,  2.0328e-02,  1.8175e-01,\n",
       "           1.0778e-01, -5.7068e-01,  8.8741e-02,  1.0482e-01, -1.2976e-01,\n",
       "           1.5846e-01, -9.3549e-02,  7.9828e-02,  1.2124e-01, -9.7084e-02,\n",
       "           7.7074e-02,  2.3649e-02,  1.6865e-01, -4.2446e-02, -2.7354e-01,\n",
       "          -3.9389e-02,  1.6653e-01, -3.3095e+00, -3.2679e-02, -3.4167e-03,\n",
       "           1.7560e-01,  1.5490e-01,  1.2191e-01,  4.4146e-02,  2.4293e-01,\n",
       "          -7.6190e-02, -7.2546e-02,  3.4420e-03,  1.4989e-01,  2.3021e-01,\n",
       "           2.3296e-01,  7.3909e-02,  3.1401e-02,  1.4018e-01, -1.7697e-01,\n",
       "           5.3864e-03, -5.7572e-02, -1.7111e-01, -1.2664e-01, -3.3257e-01,\n",
       "           1.0437e-01, -1.8358e-01,  2.3399e-01, -2.0078e-01, -1.7522e-01,\n",
       "           2.9118e-02,  3.3749e-02, -5.7104e-02,  1.1822e-01,  1.5124e-02,\n",
       "           4.2054e-01, -2.5176e-01, -9.2718e-02,  5.6029e-02,  9.8722e-02,\n",
       "          -8.0095e-03,  1.9703e-01,  7.8674e-02,  2.8510e-01, -2.4918e-02,\n",
       "           2.6431e-01, -4.6145e-01,  7.2506e-02,  2.4421e-01, -7.9641e-02,\n",
       "           3.8809e-01, -9.7480e-02, -1.4198e-01,  2.7306e-01,  1.1834e-02,\n",
       "           1.4177e-01,  3.1700e-01,  9.2019e-02,  1.4744e-01,  4.6996e-02,\n",
       "          -1.0036e-01, -7.7764e-02,  1.1515e-01, -1.1239e-01,  6.5719e-02,\n",
       "           5.5787e-02,  9.2298e-02, -2.4200e-01,  1.0523e-01, -2.3057e-02,\n",
       "          -3.6171e-02, -4.1687e-02, -1.2593e-01, -2.2631e-02,  2.5163e-01,\n",
       "           2.5798e-02,  1.4770e-01,  2.0047e-01,  2.5629e-01,  2.4631e-01,\n",
       "           2.2931e-02,  1.9735e-01,  9.3497e-02, -3.5089e-01, -2.2288e-01,\n",
       "           1.5945e-01,  1.1067e-01, -8.8039e+00, -2.1656e-01, -4.4266e-01,\n",
       "          -2.9965e-01,  1.4908e-01, -2.2722e-01,  2.2767e-01, -5.4375e-02,\n",
       "           9.6679e-02,  2.8792e-01,  7.6204e-02, -1.4498e-01,  1.5392e-02,\n",
       "          -1.2575e-01,  1.6281e-01,  4.7022e-01], grad_fn=<UnbindBackward0>)),\n",
       " ('hi',\n",
       "  tensor([-1.2903e-01, -3.8313e-02,  2.9849e-01, -3.3556e-01, -4.7074e-01,\n",
       "          -6.6699e-02, -2.7963e-02, -4.5961e-01,  6.4231e-02, -1.6013e-01,\n",
       "          -4.3428e-01, -3.4689e-01, -4.2955e-01,  3.8645e-01,  2.5130e-01,\n",
       "           8.1379e-02,  2.2529e-01,  3.4625e-02, -2.9707e-01,  5.3005e-01,\n",
       "          -2.4771e-01, -3.6017e-02, -2.1074e-01, -4.0046e-01,  1.1451e-01,\n",
       "          -1.6489e-01, -9.9514e-02, -2.1417e-03, -2.6037e-01,  2.0970e-01,\n",
       "          -1.3618e-01,  1.0239e-01,  3.6532e-02, -6.8511e-01, -5.0953e-01,\n",
       "           9.7086e-02,  9.6164e-02, -6.9826e-02, -5.4838e-02,  1.3247e-01,\n",
       "          -1.4961e-01, -1.1730e+00,  8.6555e-02,  3.4335e-01, -4.7876e-01,\n",
       "          -5.9040e-02, -9.8835e-01,  2.3604e-01,  1.1684e-01, -1.3562e-01,\n",
       "          -7.9659e-01, -1.9303e-01, -4.3180e-01,  1.4453e-01, -3.7459e-01,\n",
       "           3.1449e-01,  9.4769e-02, -2.4281e-01, -2.1477e-02,  1.8678e-01,\n",
       "           2.7502e-01, -7.6889e-01,  1.2004e-02, -2.8287e-02, -1.8705e-01,\n",
       "           9.3751e-02,  1.8114e-01,  5.7427e-01, -5.5240e-01,  2.8423e-01,\n",
       "          -2.2257e-01,  1.2864e-01,  1.4587e-01,  3.9749e-02,  1.6894e-01,\n",
       "          -3.8113e-01, -1.3129e-01, -5.2570e-02,  6.2416e-04,  2.8884e-01,\n",
       "           7.3062e-01,  5.0628e-01,  6.8508e-01,  3.6786e-01,  4.2909e-03,\n",
       "           5.5789e-02,  5.5824e-02,  4.9868e-02,  3.9921e-02,  1.9925e-01,\n",
       "          -2.0925e-01, -4.6895e-01,  3.6842e-01,  2.6721e-01,  2.9584e-01,\n",
       "          -3.2421e-01, -1.6653e-01,  3.4102e-02,  1.1045e-01,  1.8625e-01,\n",
       "           1.8033e-01, -2.2816e-01, -4.6876e-01,  3.3350e-01, -7.3155e-01,\n",
       "          -1.0366e-01,  5.7574e-02, -5.0714e-01,  4.1335e-02, -2.0956e-01,\n",
       "          -7.6992e-02,  4.3882e-03,  3.0725e-01,  7.7555e-02, -1.0579e-01,\n",
       "           5.2721e-01,  4.0329e-01, -5.4011e-02, -1.6885e-01,  2.8286e-02,\n",
       "          -1.5623e-01,  5.3185e-01,  3.2450e-03,  5.6462e-01,  4.6137e-01,\n",
       "           7.0591e-01, -9.0942e-02,  5.6821e-01, -2.7627e-02,  3.9758e-02,\n",
       "          -3.6143e-01, -2.0482e-01,  3.0136e-01, -3.6281e-01,  1.4609e-01,\n",
       "          -2.8286e-01, -1.3869e-01,  4.0736e-01, -3.2152e-01, -4.8048e-02,\n",
       "           2.3990e-01,  3.2863e-01,  5.3687e-01, -2.7338e-01,  1.7813e-01,\n",
       "           6.5750e-01, -3.1460e-01,  1.3610e-01, -4.3588e-01,  9.1366e-02,\n",
       "           2.0692e-01,  5.0200e-01,  4.7271e-02, -2.1697e-01,  2.6043e-01,\n",
       "           3.9687e-01, -4.4654e-01,  2.0122e-01,  6.0362e-02,  6.3521e-01,\n",
       "           6.4747e-01,  1.2188e-01, -3.9567e-01, -1.2906e-01,  9.7703e-04,\n",
       "          -4.0640e-02, -3.0715e-01,  5.9124e-01, -1.4065e-01, -1.8774e-01,\n",
       "          -1.9921e-01, -1.1450e+00,  3.1803e-01,  3.2771e-01,  3.8383e-01,\n",
       "          -9.7558e-02,  5.3951e-01,  2.6256e-01, -1.3631e-01, -8.0329e-02,\n",
       "          -1.9951e-01, -1.9890e-01, -5.2996e-02,  2.7574e-02, -1.3079e-01,\n",
       "           6.3579e-01,  7.4298e-01, -5.5275e-01,  5.5800e-01, -1.1610e-01,\n",
       "           4.2823e-01, -9.4248e-02, -3.2777e-01, -2.5958e-01,  6.5262e-01,\n",
       "          -2.6050e-01,  1.8922e-01,  3.0467e-02,  3.7067e-01,  1.0726e-01,\n",
       "           9.4762e-02,  1.8789e-01,  4.3274e-01, -9.8116e-02, -2.3486e-02,\n",
       "           3.5983e-01,  4.2129e-02, -1.6325e-01, -8.2525e-01, -2.9898e-01,\n",
       "          -8.5272e-02,  3.1980e-01,  5.6080e-01, -4.5546e-01,  5.0116e-01,\n",
       "          -3.2970e-01,  5.4517e-01, -9.7329e-02,  3.7844e-01, -6.2771e-02,\n",
       "           4.6793e-01, -4.4804e-01, -3.0985e-01,  2.1459e-01, -2.6586e-01,\n",
       "           9.2491e-01,  4.8816e-01, -1.8533e-01,  6.5453e-01,  6.1301e-01,\n",
       "          -2.5497e-01, -4.1200e-01,  1.5700e-01,  3.2604e-01, -1.2332e-01,\n",
       "           1.9403e-01,  1.8129e-01, -1.4640e-01,  1.4512e-01, -6.0359e-02,\n",
       "          -4.0602e-02,  3.2556e-01, -1.6376e-01, -5.8616e-02,  8.8246e-02,\n",
       "          -4.5152e-01,  6.1605e-01, -1.9906e-01, -2.0216e-01, -1.9133e-01,\n",
       "           1.3583e-01, -2.9107e-01,  2.1634e-01, -4.3335e-01,  1.3308e-01,\n",
       "          -2.6316e-01,  3.4265e-01,  3.0316e-01,  1.8344e-01,  2.3991e-01,\n",
       "          -9.6221e-01,  1.6574e-01,  9.1835e-02, -3.5328e-01, -2.2271e-01,\n",
       "          -4.2728e-01, -2.6148e-01,  1.9768e-01,  4.6464e-01, -2.2369e-01,\n",
       "          -1.6819e-02, -3.5502e-01,  4.8075e-01,  2.3719e-01, -4.2130e-01,\n",
       "          -1.9181e-01,  6.2701e-01,  2.0209e-01,  2.9911e-02,  2.8258e-02,\n",
       "           2.7269e-01,  6.6895e-01, -6.5244e-01, -7.8775e-01,  4.2373e-02,\n",
       "          -9.5358e-02, -4.9876e-02, -2.1402e-01,  2.8944e-02, -3.7407e-01,\n",
       "          -2.1834e-02,  4.9059e-01, -2.8894e-01, -2.1037e-01,  2.6720e-01,\n",
       "          -3.3682e-01, -1.6986e-01,  9.3423e-01, -4.0577e-01,  3.0015e-02,\n",
       "          -3.4193e-01, -7.9966e-02,  5.4796e-02, -7.7046e-02,  1.9849e-01,\n",
       "          -6.6754e-02, -1.6044e-01, -3.9127e-02, -6.1386e+00, -8.3542e-01,\n",
       "          -2.9821e-01, -3.8192e-01,  3.2774e-01, -2.4391e-01,  1.9686e-02,\n",
       "          -3.1315e-02,  3.8494e-01,  2.5895e-01,  2.0956e-01,  8.2556e-02,\n",
       "           5.3626e-02,  1.3296e-01, -1.5052e-01,  3.1148e-01, -2.9812e-01,\n",
       "           1.1279e-01,  2.1696e-02,  5.5186e-01, -2.9504e-06, -3.8771e-01,\n",
       "          -2.9587e-01,  2.2786e-01, -2.2737e-01,  4.8196e-01, -1.3052e-01,\n",
       "           1.3890e-02, -8.3983e-01, -2.7534e-01,  1.3044e-01, -5.4461e-02,\n",
       "          -1.5409e-01,  5.0811e-01, -4.0461e-01, -2.8073e-01,  3.3368e-01,\n",
       "          -1.9915e-01, -4.4034e-01,  7.2089e-02, -3.3551e-01, -7.1766e-01,\n",
       "          -2.8895e-01, -2.6104e-01,  1.2392e-01, -2.3921e-03, -3.8632e-01,\n",
       "          -9.2311e-01, -7.1467e-02,  1.4444e-01, -4.2598e-01, -1.7817e-01,\n",
       "           3.1447e-01, -3.4595e-02,  1.6207e-02, -1.7131e-02, -4.9834e-02,\n",
       "           1.8244e-01,  4.9938e-01, -2.8514e-01,  3.5606e-01, -2.4385e-01,\n",
       "          -5.9013e-01,  2.5615e-02, -3.5844e-01, -1.4144e-01,  7.2694e-02,\n",
       "          -2.1770e-01, -1.3331e-01,  3.6717e-01, -2.5591e-01,  1.9818e-01,\n",
       "           2.3432e-01, -1.2163e+00, -2.3062e-01, -2.6695e-01,  5.5806e-01,\n",
       "          -6.6798e-01, -9.2797e-02, -2.1795e-01, -4.9746e-01, -8.0747e-01,\n",
       "          -1.2256e-01,  2.3756e-01,  4.2639e-01, -4.1947e-01, -3.4342e-01,\n",
       "          -9.7054e-02,  2.1011e-01,  2.8146e-01,  1.4611e-01, -2.2043e-01,\n",
       "           2.0952e-01,  3.6693e-01,  2.3170e-02,  5.4143e-01,  2.0391e-01,\n",
       "           2.5745e-03,  8.7686e-01, -2.8754e-01,  3.2857e-02,  1.3861e-01,\n",
       "          -2.9658e-01, -6.0397e-01,  1.8950e-01,  2.9103e-01, -7.1548e-01,\n",
       "          -1.4232e-01,  3.6300e-01,  4.8170e-02,  2.3237e-01, -3.4606e-01,\n",
       "          -2.1192e-01,  1.8213e-01,  3.3341e-01,  1.0977e-01, -5.8111e-01,\n",
       "           7.6689e-01,  2.7968e-01,  5.7571e-01, -3.9618e-01,  5.2433e-01,\n",
       "          -2.2254e-01, -4.0667e-01, -4.5736e-01,  5.7418e-01, -1.7591e-01,\n",
       "           5.5604e-01, -6.1827e-01,  1.2528e-01,  7.5917e-02, -4.8902e-02,\n",
       "          -1.0116e-01,  6.6580e-02,  2.4830e-01, -9.3734e-02, -2.8320e-01,\n",
       "           3.9134e-01, -1.7327e-01,  9.7635e-02,  4.5012e-01, -4.3827e-01,\n",
       "          -9.3812e-02,  4.0719e-01,  1.7575e-01,  4.1391e-01,  2.2262e-01,\n",
       "          -2.0713e-01,  6.2897e-03,  3.2610e-01,  3.4854e-01, -7.9142e-01,\n",
       "           4.1993e-01,  1.5223e-01, -1.2418e-01, -1.6171e-01,  8.2011e-01,\n",
       "          -3.8043e-01, -6.4232e-01, -1.5514e-01,  1.5334e-01, -2.4577e-01,\n",
       "          -7.0371e-01,  9.3205e-02,  3.1434e-01,  7.5298e-01,  5.5603e-02,\n",
       "           1.7558e-01, -1.1489e-01, -1.7944e-01, -2.6679e-01,  2.3194e-01,\n",
       "          -5.3907e-01, -3.7133e-01, -1.0316e-01, -8.5695e-02,  2.3042e-02,\n",
       "           1.2615e-02, -8.5400e-02, -2.0528e-01,  4.4652e-02,  3.4140e-01,\n",
       "          -2.7364e-01,  4.7776e-02,  1.2261e-01, -6.5129e-01, -3.2773e-01,\n",
       "           1.5499e-02, -5.9552e-02,  3.5406e-01, -7.1169e-02, -4.9217e-01,\n",
       "          -1.4727e-01, -2.5102e-01, -1.7982e-01, -3.5364e-01,  1.5109e-01,\n",
       "           1.8259e-01,  1.3220e-01,  5.6776e-01,  5.4548e-01,  1.5373e-01,\n",
       "          -2.8887e-01, -3.4131e-01,  7.8148e-02, -4.1672e-01,  2.2829e-01,\n",
       "           3.7168e-01, -2.8925e-01,  7.5619e-02,  2.1776e-02, -6.3354e-01,\n",
       "          -3.6717e-02,  3.7089e-02, -1.4114e-01, -2.4252e-01, -2.3812e-01,\n",
       "          -3.1033e-01, -1.4105e-01, -3.6065e-01, -5.5250e-02, -3.8710e-01,\n",
       "          -1.9026e-01, -2.9067e-01, -1.4090e-01, -1.3312e-01,  2.8842e-01,\n",
       "          -3.7676e-01,  2.9715e-01, -3.8119e-01,  3.2719e-01,  4.1834e-02,\n",
       "           1.2046e-01,  6.9778e-01, -2.7492e-01, -6.8067e-01, -7.1236e-01,\n",
       "           4.1614e-01, -3.2068e-01,  1.2759e-01,  1.3996e-01, -6.5790e-01,\n",
       "           1.1104e-01, -5.0757e-01, -1.9445e-01,  3.4225e-01, -1.3777e-01,\n",
       "           4.6040e-01,  1.2619e-01,  5.2031e-01, -1.0416e-01, -5.3499e-02,\n",
       "          -8.7059e-02, -2.8891e-01,  4.4453e-01, -1.0766e+00,  2.2103e-01,\n",
       "          -3.9262e-01, -3.2792e-01,  5.4388e-01, -5.1146e-02, -6.3157e-02,\n",
       "          -2.1286e-01,  5.2803e-01, -1.4022e-01,  5.5493e-01,  1.4608e-01,\n",
       "          -2.2155e-01,  4.5874e-01,  5.0948e-02, -3.7615e-01,  1.2462e-01,\n",
       "           3.3731e-01,  2.3484e-01, -2.2507e-01, -6.0502e-01, -4.4507e-02,\n",
       "           1.6705e-01,  2.1448e-01,  1.3195e-01, -2.3174e-02,  7.6536e-01,\n",
       "           3.6393e-02,  5.0186e-01,  4.3458e-01, -3.0403e-01,  1.2863e-01,\n",
       "          -6.2205e-01,  1.1174e-01,  4.0728e-01,  1.0220e-01,  7.6421e-01,\n",
       "          -3.7904e-01,  8.6432e-01, -2.5816e-01, -1.4368e-01,  2.1885e-01,\n",
       "          -8.6245e-02, -5.8055e-01,  3.8732e-01,  3.6796e-01,  3.6506e-01,\n",
       "          -1.0081e-01,  5.6147e-01, -3.9866e-01,  2.4581e-01,  2.2197e-01,\n",
       "          -5.9065e-01, -1.8528e-01,  4.1810e-01, -1.8090e-01,  2.3703e-02,\n",
       "          -1.0944e-01,  5.7044e-01, -1.9212e-02,  4.8083e-01,  2.0290e-01,\n",
       "          -5.3333e-01,  3.0634e-01, -9.1994e-04,  1.1740e-01,  2.2076e-01,\n",
       "           8.1036e-01,  2.5465e-01,  6.6385e-02,  1.5006e-01, -3.0005e-01,\n",
       "          -2.0948e-01,  6.0949e-01,  5.3898e-01,  3.3523e-01,  1.0838e-01,\n",
       "           1.8035e-02,  2.8439e-01, -2.3413e-01, -1.1329e-01,  1.6256e-01,\n",
       "           1.9195e-01,  2.4514e-02,  3.6176e-01, -5.5157e-02,  5.6614e-01,\n",
       "          -5.4602e-03,  2.3292e-02,  2.1726e-01,  2.3190e-01, -5.9591e-02,\n",
       "          -5.7910e-02,  2.9159e-01,  2.8576e-01,  7.5849e-04,  3.0710e-01,\n",
       "          -3.8814e-01, -3.4193e-01, -3.3414e-01,  6.4055e-01, -5.2074e-01,\n",
       "           3.4672e-01,  4.3271e-01,  3.9047e-01,  2.4531e-01, -2.4780e-01,\n",
       "           2.2520e-01,  1.5864e-01, -1.6931e-01, -3.5542e-01,  3.7611e-01,\n",
       "          -1.7744e-01, -2.7382e-02, -3.6485e-01, -5.9823e-01, -1.3582e-01,\n",
       "          -2.0212e-01,  9.0257e-01, -4.1054e-01, -2.0424e-01,  1.5145e-01,\n",
       "          -1.0247e-01,  9.4735e-02,  1.3066e-01, -3.7880e-01, -3.7635e-01,\n",
       "          -5.0467e-01, -6.5097e-01, -4.2802e-02, -4.6270e-01, -1.5226e-01,\n",
       "           7.6967e-01, -3.3667e-01,  2.8488e-01,  1.6555e-01,  1.5485e-01,\n",
       "           2.2071e-01, -1.8457e-01, -3.8343e-02, -5.2766e-01,  2.9850e-01,\n",
       "          -1.4840e-01,  4.7518e-01,  7.9703e-02,  1.2757e-02, -3.9614e-01,\n",
       "           1.7761e-01, -2.8169e-01,  8.3005e-02,  1.4556e-01, -3.3428e-01,\n",
       "          -5.1907e-02,  6.5870e-02, -3.6613e-01,  7.0136e-01,  4.3595e-01,\n",
       "          -4.0009e-03,  5.2171e-01, -5.4999e-01,  2.9169e-01,  4.6158e-01,\n",
       "           1.5419e-01, -3.5824e-01,  5.0761e-01, -6.1002e-01,  3.1930e-01,\n",
       "           3.1069e-01, -2.0341e-01,  2.6330e-01,  4.6206e-01,  9.8824e-02,\n",
       "           5.3247e-02, -6.3862e-02, -4.1412e-01,  4.8090e-01,  3.1146e-01,\n",
       "          -3.1414e-01, -1.8078e-01,  2.7811e-01, -2.9622e-01, -2.6807e-01,\n",
       "          -7.2721e-01, -4.4160e-02, -4.8303e-01, -2.4499e-02,  9.4267e-02,\n",
       "           4.0298e-01,  4.1479e-01, -3.8229e-01,  5.1487e-01, -4.1566e-01,\n",
       "          -4.0727e-01, -5.3019e-01, -1.8365e-01,  5.1197e-02,  1.0948e-01,\n",
       "           1.3207e-01,  1.4418e-01,  1.9399e-01,  6.0569e-01, -4.1888e-01,\n",
       "          -1.5475e-01,  3.5743e-01,  1.0369e-01], grad_fn=<UnbindBackward0>)),\n",
       " ('ada',\n",
       "  tensor([-5.7807e-01,  1.6980e-01,  1.0168e-01, -9.5992e-02, -4.4854e-01,\n",
       "          -1.3786e-01,  5.7507e-01, -1.7170e-01,  1.7876e-01, -9.6182e-02,\n",
       "          -4.3699e-02, -1.8197e-01, -2.9508e-02,  2.3846e-01,  1.1670e-02,\n",
       "           1.5311e-01, -6.2880e-02, -1.7933e-01,  2.7233e-01,  6.3665e-02,\n",
       "          -1.1858e-01,  3.3004e-02,  4.9708e-01, -2.6267e-01,  1.3760e-01,\n",
       "          -3.9707e-01,  1.6612e-01,  3.3416e-01, -7.3189e-02, -7.7048e-02,\n",
       "           1.3049e-01,  1.1205e-01, -2.6000e-01, -4.5612e-01, -5.7944e-01,\n",
       "           2.9809e-01, -2.2862e-01,  3.0363e-01,  9.3520e-03, -6.6297e-02,\n",
       "          -4.7832e-01, -7.8894e-01, -1.6201e-01,  9.1356e-02, -4.6621e-01,\n",
       "          -4.4050e-01, -6.4235e-01, -1.7092e-01,  4.7192e-01, -2.7619e-01,\n",
       "          -4.4882e-01,  2.4384e-01, -2.0438e-01, -3.0453e-01, -1.9384e-01,\n",
       "           2.3035e-01,  7.5531e-02, -2.8492e-01,  2.2710e-01,  9.5979e-02,\n",
       "           2.9610e-01, -1.9809e-01,  1.3805e-01,  3.1287e-01, -2.2965e-01,\n",
       "           2.2575e-01,  1.3936e-01,  1.4231e-01, -2.1955e-01, -1.6183e-02,\n",
       "           1.9748e-02,  1.2691e-01, -4.9015e-01, -3.7872e-02,  2.7324e-01,\n",
       "          -5.9255e-01, -1.7488e-01, -1.8166e-02, -2.2782e-01,  2.0041e-01,\n",
       "          -2.0271e-02, -2.4428e-01,  2.0958e-01,  1.9614e-01,  9.1215e-02,\n",
       "          -4.0822e-02,  1.0075e-01, -1.5646e-01, -1.2802e-01, -2.3915e-01,\n",
       "          -5.1106e-03, -3.5828e-01,  2.4697e-01,  9.3194e-02, -5.8913e-02,\n",
       "          -2.7244e-01,  9.7043e-02,  3.3053e-01, -2.5227e-01,  2.6501e-01,\n",
       "          -1.3394e-01, -3.1579e-01, -8.8976e-02, -2.3751e-01, -4.9919e-01,\n",
       "           3.6486e-02, -3.0221e-01, -4.8148e-01, -4.8586e-03, -1.7771e-01,\n",
       "          -4.0957e-01,  1.6181e-01,  4.5303e-01,  9.7673e-03, -1.1428e-01,\n",
       "           2.2106e-01,  2.4185e-01,  7.9854e-01,  1.4301e-01, -3.2163e-01,\n",
       "           2.5543e-01,  3.8441e-01, -1.4298e-02,  3.5762e-01,  4.0736e-01,\n",
       "           2.1201e-01, -3.1462e-01,  2.7005e-01,  1.5088e-01,  3.7863e-01,\n",
       "           9.4625e-02, -3.7699e-01,  2.2676e-01, -3.2474e-01, -1.5628e-01,\n",
       "           3.2021e-01, -4.6409e-01,  2.2395e-01,  9.3131e-02, -4.1560e-01,\n",
       "          -5.0412e-01,  4.2261e-01, -1.0999e-01, -3.7871e-01,  1.8958e-01,\n",
       "           3.8127e-01, -1.4048e-01,  2.6688e-01, -8.7364e-03,  5.7621e-01,\n",
       "           2.2668e-02,  4.3036e-01,  1.7559e-01, -8.0112e-02,  4.4532e-01,\n",
       "           3.8392e-01,  1.8504e-01, -2.2531e-01, -3.4431e-01,  1.9301e-01,\n",
       "           4.4029e-01,  3.6525e-01,  2.3185e-01, -6.7255e-02,  1.0685e-02,\n",
       "          -3.5662e-01, -2.5774e-01,  2.0612e-02, -1.4154e-01, -4.0319e-01,\n",
       "          -3.5582e-01, -4.8289e-01,  3.0096e-01, -6.8306e-02,  1.9629e-01,\n",
       "           4.6851e-01,  4.7002e-01, -1.8326e-01, -6.4035e-02,  6.6293e-01,\n",
       "          -2.9363e-01, -4.1954e-01, -1.0796e-01, -1.4873e-01,  4.7483e-01,\n",
       "           1.5985e-01, -1.3884e-01, -1.1107e-02,  5.9451e-01,  4.0689e-01,\n",
       "          -2.8473e-01,  9.1687e-02, -1.9860e-01,  8.8930e-03,  8.2847e-01,\n",
       "          -4.7921e-01, -3.5170e-02,  1.5619e-01, -8.6903e-02,  3.4918e-01,\n",
       "           7.0739e-02, -9.3597e-02,  6.6399e-01, -2.7747e-01, -1.2482e-01,\n",
       "           5.2951e-01,  8.5154e-02, -1.3483e-01,  8.5405e-02,  5.9873e-03,\n",
       "          -1.3917e-01,  1.4834e-02, -3.0012e-01, -2.7368e-01,  9.0441e-02,\n",
       "          -1.4528e-01,  5.4714e-01, -3.7414e-01,  2.1704e-01, -4.8365e-02,\n",
       "           2.2728e-01, -2.4124e-01, -8.8439e-02, -1.8648e-01,  3.1060e-02,\n",
       "           5.3510e-01,  5.3010e-01,  1.9442e-01,  4.5419e-01, -6.8071e-02,\n",
       "          -7.1339e-02, -3.8609e-02, -2.8360e-01, -7.3864e-01,  3.4439e-01,\n",
       "           3.2486e-01, -1.7542e-01,  6.6978e-02, -1.6976e-01, -3.5719e-02,\n",
       "          -2.2308e-01,  4.7250e-01,  4.1344e-01,  3.5876e-02,  2.2632e-01,\n",
       "          -8.2570e-02,  5.9506e-01,  1.3283e-02, -2.9744e-01,  2.0201e-01,\n",
       "          -4.3957e-01,  2.4014e-01,  2.6602e-01,  4.1071e-01,  4.7492e-01,\n",
       "          -1.7792e-01,  2.2791e-01, -1.6637e-01, -5.6930e-01,  1.0989e-01,\n",
       "          -3.9696e-02,  4.7094e-02,  2.3965e-01,  3.2468e-01, -3.9086e-01,\n",
       "          -3.5878e-01,  1.3877e-01,  4.0754e-02,  3.6230e-01,  1.7214e-01,\n",
       "           2.4979e-02,  2.3045e-01,  1.7504e-01,  2.8559e-01, -2.3318e-01,\n",
       "           4.2277e-02,  5.4245e-01, -3.8134e-01, -3.4227e-01,  2.5035e-02,\n",
       "           1.7619e-01,  4.6206e-01,  4.3886e-01, -3.4046e-01,  3.1030e-01,\n",
       "          -5.4815e-01,  3.2211e-01,  1.4963e-01, -2.4164e-02,  3.4255e-01,\n",
       "           1.9841e-01,  8.1177e-01, -2.3482e-02, -4.9372e-01,  3.9449e-01,\n",
       "          -2.4693e-01, -3.9240e-01,  4.8961e-01, -8.6677e-01,  1.0948e-01,\n",
       "          -6.6961e-01,  5.0323e-01,  6.8009e-02, -1.8901e-01, -2.2468e-01,\n",
       "           3.2848e-01, -6.9746e-01,  4.6415e-02, -6.4519e+00, -8.2467e-01,\n",
       "          -9.6578e-02, -9.0398e-02, -2.1243e-01, -3.0510e-01,  3.4601e-02,\n",
       "           1.1534e-01,  3.2142e-02, -3.6937e-02,  3.0348e-01,  1.8264e-01,\n",
       "          -8.8296e-03,  6.1719e-01, -3.8122e-01,  1.3489e-01,  1.0663e-01,\n",
       "          -5.9259e-02, -2.0904e-01,  3.9348e-01,  2.1065e-03, -2.7136e-01,\n",
       "          -1.7427e-01,  1.7675e-01,  1.4909e-01, -6.4361e-01,  5.8956e-01,\n",
       "           1.6193e-01, -3.4535e-01, -2.7553e-01,  5.4895e-01, -9.0712e-02,\n",
       "          -1.2583e-02,  7.4819e-01, -2.4378e-01, -2.5166e-02,  1.0260e-01,\n",
       "           1.6303e-03,  1.3571e-01, -5.8635e-02,  3.3629e-01, -4.7234e-01,\n",
       "          -4.1935e-01,  4.2430e-01,  3.3820e-02,  7.9842e-02, -4.5953e-01,\n",
       "           3.1897e-01,  6.5709e-02, -1.5938e-01,  3.9876e-01, -6.4343e-02,\n",
       "           3.1839e-02, -1.8207e-01,  2.1988e-01,  5.1808e-02, -1.3836e-01,\n",
       "           4.5485e-01,  5.1751e-01, -6.1905e-02,  4.7869e-01,  2.8588e-02,\n",
       "          -1.4740e-01, -1.5635e-01, -1.9987e-02,  2.3818e-02, -6.8729e-02,\n",
       "          -2.7322e-01, -2.3641e-01,  2.3001e-01, -6.2586e-02, -1.8619e-01,\n",
       "           9.0928e-02, -7.4096e-01, -9.6068e-02, -4.5896e-01,  7.8814e-01,\n",
       "          -2.1903e-01,  4.5911e-01, -5.5057e-02, -3.5111e-01, -3.2446e-01,\n",
       "           3.9441e-02,  1.1264e-01,  2.0170e-01, -3.3712e-02,  3.7058e-01,\n",
       "          -8.3367e-02,  7.9285e-02,  3.2107e-01,  3.6860e-01, -2.0001e-01,\n",
       "           2.3697e-02,  3.3958e-01, -2.5813e-02,  5.7003e-02, -1.3757e-01,\n",
       "          -3.0263e-01,  7.5606e-01, -3.0811e-02, -7.9620e-02, -1.5328e-01,\n",
       "          -9.9540e-02, -2.4442e-01, -2.0172e-01,  2.9370e-01, -5.9114e-01,\n",
       "           3.2912e-02,  3.1424e-01, -1.3101e-01, -1.0847e-02, -1.6540e-01,\n",
       "          -1.6227e-01, -1.1826e-02,  3.2701e-01,  1.3377e-01,  2.9637e-01,\n",
       "           3.6162e-01,  4.1138e-02,  2.2978e-01, -7.3488e-01,  3.9985e-01,\n",
       "          -1.2916e-01, -1.9569e-01, -1.5228e-01,  2.1229e-01,  1.5869e-01,\n",
       "           3.3939e-01, -2.8429e-01,  2.1011e-02,  4.9992e-01,  2.0708e-01,\n",
       "          -5.0699e-02,  3.9341e-02,  3.1431e-01,  5.6094e-03,  9.2264e-02,\n",
       "          -1.3728e-01, -3.5271e-02, -4.3972e-02,  9.8355e-02, -3.6653e-02,\n",
       "           2.2337e-01,  2.2634e-01,  7.2574e-01, -6.3525e-02, -1.3353e-02,\n",
       "           6.4234e-02,  2.2616e-01,  1.1236e-01,  4.8096e-01, -4.7286e-01,\n",
       "           1.6446e-01,  7.8586e-02,  8.9545e-02, -9.5184e-02,  6.1409e-01,\n",
       "           3.1687e-02, -7.5472e-01, -4.1266e-01, -2.7355e-01, -2.8398e-01,\n",
       "           1.2838e-01, -2.2280e-01,  2.1174e-02,  3.2195e-01,  1.2970e-01,\n",
       "          -6.5572e-01,  1.1913e-01,  6.4796e-02, -3.2679e-01,  5.9256e-02,\n",
       "          -2.5474e-01, -1.1712e-01,  1.9071e-01,  1.7522e-01, -1.2696e-01,\n",
       "          -3.1192e-01,  2.1833e-02,  3.4049e-01, -1.8811e-01,  1.2213e-01,\n",
       "           7.7290e-02, -2.2032e-02,  1.3573e-01, -6.4943e-01, -5.8559e-01,\n",
       "          -2.2613e-01,  1.8922e-01, -2.7368e-01,  1.2653e-01, -2.4558e-01,\n",
       "           4.1994e-02, -4.1202e-01,  8.7019e-02, -4.2232e-01,  1.7807e-01,\n",
       "           4.9033e-02, -9.8641e-02,  2.5160e-01, -2.9198e-02, -2.1776e-01,\n",
       "           8.5682e-02, -8.1972e-02, -1.7715e-01, -5.9869e-01, -4.2447e-02,\n",
       "           3.8926e-01,  1.6282e-01,  4.0325e-02,  2.8540e-01, -1.7541e-01,\n",
       "          -3.4695e-01, -1.6750e-02,  2.6975e-01,  2.4111e-01, -8.5583e-02,\n",
       "          -1.8597e-01, -1.0441e-01, -9.7071e-02, -5.4537e-01, -3.8909e-01,\n",
       "           6.9112e-01,  1.7466e-01, -4.9800e-01,  7.8070e-02,  1.3109e-01,\n",
       "          -3.7424e-01,  2.5552e-01, -6.5142e-01,  1.4177e-01, -3.6922e-02,\n",
       "           2.5784e-01,  2.6780e-01, -3.0890e-01, -2.5287e-01, -3.0471e-01,\n",
       "          -7.1809e-02, -1.0852e-01, -1.0102e-01, -4.3564e-01, -6.3272e-02,\n",
       "          -4.5587e-02, -6.3994e-02,  3.6503e-01, -2.4514e-01, -1.3077e-01,\n",
       "          -2.9686e-01,  7.9812e-02,  3.8055e-01, -1.3104e-01,  1.3212e-01,\n",
       "          -1.7634e-01,  7.1813e-02,  2.6977e-01, -3.0581e-01, -3.8566e-02,\n",
       "          -7.1937e-01, -2.0939e-01,  1.3028e-01, -1.3974e-01,  2.5434e-01,\n",
       "          -1.6698e-02,  2.4979e-01, -3.8474e-01,  3.4259e-01,  2.2128e-01,\n",
       "          -7.7244e-02,  3.4836e-01, -2.6621e-01, -3.4786e-01, -1.1979e-01,\n",
       "           5.9441e-01,  1.6896e-01, -4.1073e-01, -5.7934e-01,  2.7515e-03,\n",
       "          -1.4461e-01,  6.2408e-01,  3.6603e-01,  6.2484e-02,  4.0808e-01,\n",
       "           1.5350e-01,  2.8428e-01,  2.2238e-01, -2.8929e-01,  1.7309e-01,\n",
       "          -1.7249e-01, -3.2936e-01, -3.7117e-01, -2.6849e-02,  4.4000e-01,\n",
       "          -2.9968e-01,  7.1388e-01, -2.1530e-01,  6.5162e-02,  1.5135e-01,\n",
       "          -3.6121e-01, -5.6086e-01, -1.2848e-01,  3.2782e-01,  2.5542e-01,\n",
       "          -3.9811e-01,  9.7549e-02,  1.4907e-01,  1.0535e-01,  1.1554e-01,\n",
       "           4.1684e-02, -1.7374e-02,  2.2237e-01, -4.5706e-01, -1.0444e-01,\n",
       "           7.9062e-02,  2.6506e-01, -5.0800e-01,  5.5738e-01,  2.5509e-01,\n",
       "          -4.7486e-03, -3.2516e-01, -9.1774e-02, -4.5903e-01, -4.3266e-01,\n",
       "           1.9396e-01, -1.4784e-01, -8.4313e-02, -1.4089e-01,  1.3700e-01,\n",
       "           1.7273e-01,  2.5250e-01,  5.3039e-01,  4.1283e-01,  2.9298e-01,\n",
       "           7.2859e-02,  1.3617e-01, -2.3307e-01,  2.0403e-01,  6.1811e-02,\n",
       "          -4.2989e-01, -3.4292e-01,  7.4820e-02, -1.5035e-01,  1.0355e-02,\n",
       "          -9.2418e-02,  1.0379e-01, -1.2676e-01,  2.0305e-01,  1.0899e-01,\n",
       "           1.5662e-02, -1.8520e-01, -2.7762e-01,  8.4943e-02,  4.3099e-01,\n",
       "          -1.2459e-01, -3.1395e-01,  7.5780e-01,  2.1372e-01,  9.7762e-02,\n",
       "          -1.8382e-01,  2.5751e-01,  2.5687e-01, -5.5731e-02, -3.1103e-01,\n",
       "           4.6645e-01, -1.5985e-01, -1.4885e-01, -4.9918e-01,  2.7080e-01,\n",
       "           4.4754e-01, -1.3333e-01,  3.2694e-02, -3.9092e-01, -7.7403e-02,\n",
       "          -4.8305e-01,  8.7094e-01, -3.9822e-02, -1.2315e-02,  8.5815e-02,\n",
       "          -3.6484e-01, -7.0178e-02,  1.0405e-01, -4.4383e-01,  4.4092e-01,\n",
       "          -6.6638e-01, -5.1091e-01, -5.4029e-03, -3.7333e-01, -2.2825e-01,\n",
       "           3.5711e-01, -3.7718e-01, -1.5148e-01,  2.5549e-01,  2.2454e-01,\n",
       "           2.7625e-01, -5.8594e-01, -1.3053e-01, -6.7418e-01,  2.7502e-01,\n",
       "          -1.4560e-01,  4.8959e-01,  1.7982e-01,  3.3143e-01,  3.1148e-01,\n",
       "           7.7646e-02, -1.2785e-01, -5.5520e-03,  4.6726e-01,  2.3958e-01,\n",
       "          -3.5223e-01,  2.2622e-01,  1.2329e-01,  1.0646e-01,  4.6945e-02,\n",
       "          -1.2153e-01,  8.2074e-01,  3.9351e-01, -1.6291e-01,  7.3710e-02,\n",
       "          -2.1165e-01, -2.5635e-01,  4.3290e-01, -2.1354e-01,  1.1394e-01,\n",
       "           2.2182e-01, -5.4830e-02, -1.2519e-01,  7.7207e-01, -1.0700e-01,\n",
       "           1.5729e-01, -2.9165e-02, -2.9316e-02,  4.7233e-02, -4.7774e-01,\n",
       "          -1.2654e-01,  1.4653e-01, -1.1751e-01, -4.7373e-01, -8.4546e-02,\n",
       "           8.5814e-02,  1.7994e-01, -1.1826e-01,  4.5488e-01,  1.2205e-01,\n",
       "           5.3009e-01,  2.6332e-01, -4.0108e-01, -7.0441e-02, -7.7108e-01,\n",
       "          -2.8533e-01, -3.7608e-02, -1.2052e-01, -1.7465e-01, -2.6120e-01,\n",
       "          -3.3018e-01,  1.5539e-01,  1.8858e-01, -7.2297e-02, -1.2433e-01,\n",
       "          -8.3687e-02, -2.4571e-01, -4.2028e-01], grad_fn=<UnbindBackward0>)),\n",
       " ('##sd',\n",
       "  tensor([-4.1215e-01, -2.0899e-01, -3.8824e-01, -1.0932e-02, -2.8058e-01,\n",
       "           2.9180e-01,  3.8787e-01,  1.5286e-01, -2.8628e-01, -4.3431e-01,\n",
       "           3.0048e-02,  2.3906e-01,  5.6540e-03,  3.4668e-01, -1.3778e-01,\n",
       "          -4.3156e-01, -3.1547e-01,  2.2786e-01,  4.1718e-02,  2.5861e-01,\n",
       "          -1.6548e-01, -1.5436e-01, -2.3303e-01, -7.0181e-01,  4.6464e-02,\n",
       "           5.7317e-01, -2.5769e-01, -4.3634e-01, -3.0839e-01,  5.9572e-01,\n",
       "          -2.0529e-01, -1.7718e-01,  1.4260e-01,  2.7229e-01, -8.7540e-01,\n",
       "          -3.4837e-01, -4.7824e-01,  2.4543e-01, -3.6302e-01,  3.2675e-01,\n",
       "           1.2243e-01, -6.7509e-01,  2.1657e-01, -2.5855e-01, -1.2562e-01,\n",
       "          -3.8384e-01,  5.3881e-02,  1.7921e-01,  1.2565e-02, -1.3512e-01,\n",
       "          -1.0043e+00,  1.5680e-01, -2.8669e-01,  1.1824e-01, -2.1162e-01,\n",
       "          -1.5041e-01,  2.3977e-01,  1.3819e-01, -7.1722e-02, -2.5489e-01,\n",
       "           8.0869e-02, -4.3014e-01,  1.1049e-01,  2.0382e-01,  2.5572e-02,\n",
       "           1.5501e-01,  6.6708e-01,  4.5825e-01, -5.6105e-01,  3.6066e-01,\n",
       "           1.3758e-01,  1.6100e-01, -3.3007e-01, -3.0076e-01,  3.2747e-01,\n",
       "          -4.2050e-01, -3.7557e-01,  1.0643e-01,  4.0270e-02,  1.3188e-01,\n",
       "           1.1967e-01,  3.9441e-01,  1.0944e-01,  1.3388e-01,  1.7631e-01,\n",
       "          -4.0257e-01, -6.0526e-02, -3.5158e-01, -2.5551e-01,  3.1226e-01,\n",
       "          -9.4999e-03, -2.4732e-01,  1.7402e-01, -4.0157e-02,  5.4349e-01,\n",
       "           1.5097e-01, -2.4374e-01,  1.6666e-01,  1.9180e-01, -2.0133e-01,\n",
       "          -3.5125e-01, -5.5023e-01, -2.5892e-01,  2.5862e-01, -8.0232e-01,\n",
       "           2.1220e-01, -2.8587e-01, -2.5580e-01, -5.2233e-02, -1.3354e-01,\n",
       "           1.5018e-01,  9.4172e-02,  3.1037e-01, -3.9535e-02,  4.2787e-01,\n",
       "           5.8798e-01, -1.8844e-01,  8.7364e-01,  4.2792e-01, -1.0863e-01,\n",
       "           2.1281e-02, -1.4847e-01,  3.1815e-02,  7.1854e-01,  2.8023e-01,\n",
       "           7.5332e-01, -5.7028e-01, -1.9322e-01, -5.3855e-01, -1.8918e-01,\n",
       "           2.2090e-01,  2.1311e-01,  9.3975e-02,  2.3581e-01, -2.2912e-01,\n",
       "          -3.4010e-01, -3.0378e-01,  3.8280e-01,  3.0022e-01, -6.7442e-01,\n",
       "          -4.2119e-01,  6.2979e-01,  1.0801e-02, -9.3209e-02,  3.7941e-01,\n",
       "           2.7032e-01, -4.5089e-01, -1.3020e-01, -2.1822e-01,  2.1371e-01,\n",
       "          -5.7149e-02,  5.2012e-01,  2.1902e-02, -5.2248e-01, -4.4941e-02,\n",
       "           4.6636e-02, -2.0310e-01,  3.7240e-01,  1.2708e-01,  5.8292e-01,\n",
       "           5.4151e-01,  7.1203e-01, -3.5681e-01,  1.8329e-01,  2.2833e-01,\n",
       "          -1.5492e-01,  9.1553e-02,  1.0069e+00,  5.1508e-01, -4.1473e-01,\n",
       "          -5.5506e-01, -3.9087e-01,  7.0145e-01,  4.3858e-01, -4.9795e-02,\n",
       "           4.0831e-01,  3.3429e-01,  2.0608e-02, -3.2364e-01,  4.6554e-01,\n",
       "          -2.8647e-01, -7.1674e-02, -2.7121e-01, -7.7153e-01,  4.4441e-01,\n",
       "           4.1348e-01,  9.3979e-02, -7.3753e-01,  8.9544e-01,  6.1803e-02,\n",
       "          -9.1776e-01, -4.5898e-01, -1.9461e-01,  6.5471e-02,  2.2790e-01,\n",
       "          -5.8532e-01,  1.1265e-01, -3.1428e-02,  1.0406e+00,  1.4003e-01,\n",
       "           7.5412e-01, -4.2208e-01,  4.4744e-01,  4.0466e-01, -4.7401e-02,\n",
       "           6.8641e-01,  2.3564e-01, -1.8317e-01, -3.6919e-01, -3.6496e-01,\n",
       "          -6.2382e-01,  5.5697e-01, -3.6985e-02,  5.4838e-02,  4.6682e-01,\n",
       "          -5.2764e-01,  5.0612e-01, -3.6169e-01, -1.9879e-01, -7.6746e-02,\n",
       "           9.0871e-01, -3.9288e-01, -4.0895e-01,  1.9020e-01, -8.3840e-01,\n",
       "           2.1056e-01,  3.3938e-01, -2.1819e-01,  1.9079e-01, -5.8015e-01,\n",
       "           5.2531e-02, -2.3413e-01, -2.7116e-01, -1.7599e-01, -4.5679e-01,\n",
       "           5.6214e-01,  4.0662e-02,  9.3046e-02,  4.2316e-02, -1.4148e-01,\n",
       "          -2.2633e-01,  2.7654e-01,  4.5322e-01,  1.9918e-02, -4.4862e-03,\n",
       "           1.7908e-01,  1.1544e+00, -2.6364e-01,  3.7077e-01,  1.8510e-01,\n",
       "          -1.3046e-01, -7.3188e-01,  1.2127e-01, -9.0784e-02, -5.1912e-01,\n",
       "          -6.0295e-01, -9.7908e-02, -5.6860e-01,  3.4872e-01,  1.3293e-01,\n",
       "          -5.4117e-01, -1.3982e-01,  1.2366e+00, -2.1862e-01,  1.7208e-01,\n",
       "          -1.8679e-01,  2.8833e-02, -2.3772e-01,  5.1056e-01, -2.4334e-01,\n",
       "          -6.4454e-04, -3.0439e-02, -3.0983e-02,  4.8848e-02, -3.3801e-01,\n",
       "           1.0139e-01,  4.5979e-01,  3.5202e-01,  1.2008e-01,  1.1287e-01,\n",
       "           3.7743e-01, -5.2559e-02, -8.1720e-02, -4.4461e-01,  3.9502e-01,\n",
       "          -1.9914e-01, -1.5698e-01, -4.0457e-01,  1.7056e-02, -3.9023e-01,\n",
       "          -3.1559e-02,  4.9758e-01,  1.0530e-01, -2.1541e-01,  7.6637e-01,\n",
       "          -1.3564e-01, -5.3044e-01,  5.6785e-01, -5.8205e-01, -2.7019e-02,\n",
       "          -1.0802e-01,  1.4719e-01,  1.9803e-01, -3.4899e-02,  5.4911e-01,\n",
       "           2.2840e-01, -3.1969e-01,  6.6607e-02, -5.7386e+00, -8.4800e-01,\n",
       "          -3.4324e-01, -3.4309e-01,  4.3916e-01, -1.6261e-02, -3.2684e-01,\n",
       "           1.4898e-01, -1.0194e-01,  1.6715e-01,  7.0174e-02,  6.9751e-02,\n",
       "          -1.6893e-01,  4.7008e-01,  1.4663e-01, -1.7622e-01, -4.9635e-01,\n",
       "          -3.2621e-01, -2.2366e-01,  3.4731e-01, -2.1274e-01, -5.8560e-01,\n",
       "           3.4221e-01,  2.4527e-01,  3.1794e-02, -7.1387e-02,  2.5584e-01,\n",
       "           2.1199e-01, -1.0031e+00, -5.3786e-01, -2.3816e-02, -7.0064e-02,\n",
       "          -1.5383e-01,  4.1333e-01,  1.3097e-02, -5.6767e-03,  3.4410e-01,\n",
       "          -1.5743e-01,  9.2486e-01,  3.6741e-01,  5.1266e-01, -1.7521e-01,\n",
       "           1.4068e-01,  3.2234e-01,  7.0088e-02, -1.7058e-01,  5.7620e-01,\n",
       "          -4.5712e-01,  4.9387e-02,  3.0303e-02,  1.3606e-01, -5.8278e-01,\n",
       "           5.7831e-02, -6.4216e-01,  2.5194e-01,  3.3675e-01, -3.0941e-01,\n",
       "           6.2003e-01,  4.1805e-01, -4.1915e-02,  5.9177e-01,  2.8081e-01,\n",
       "          -1.2920e-01,  2.4486e-01, -7.3533e-01,  2.6816e-01,  2.0334e-02,\n",
       "          -9.6500e-01,  7.3215e-02,  3.2941e-01, -3.6021e-01,  1.3731e-01,\n",
       "          -1.9634e-02, -1.0253e+00, -3.2273e-01, -6.4032e-02, -1.3981e-01,\n",
       "          -3.7541e-01, -3.8959e-01, -1.4326e-01, -1.7738e-01, -2.0208e-01,\n",
       "           3.3810e-01,  4.2659e-01,  1.1520e-01,  2.5439e-01,  3.5910e-01,\n",
       "          -9.5078e-01,  6.3155e-01,  4.9680e-01, -8.2677e-02, -1.5084e-01,\n",
       "           4.4073e-01,  1.6514e-01,  6.1769e-01,  1.8268e-01,  3.0209e-01,\n",
       "          -3.1548e-01,  4.7511e-01, -2.7750e-01, -4.1326e-01, -3.2201e-01,\n",
       "          -1.8968e-01, -1.4953e-01,  3.0425e-03,  1.3488e-01, -9.6919e-01,\n",
       "           2.2280e-01,  3.2070e-01, -3.2888e-02,  2.0638e-01,  4.0592e-01,\n",
       "           1.7077e-01,  5.3967e-01, -2.3894e-01, -6.2024e-02,  1.2390e-01,\n",
       "           2.7443e-01,  3.7987e-01,  4.5288e-01, -5.7746e-01,  6.6940e-01,\n",
       "          -2.0566e-01, -1.3148e-01,  4.6806e-01,  4.9161e-02, -1.4451e-02,\n",
       "           2.8743e-02, -4.4862e-01,  2.0794e-01,  5.3106e-01,  1.1014e-01,\n",
       "           3.0436e-01,  1.5264e-02, -1.5066e-01, -2.5778e-01,  1.3207e-01,\n",
       "          -2.0924e-01, -3.5997e-02,  6.1522e-01,  4.7116e-01, -3.2085e-01,\n",
       "          -1.0158e-01,  4.1503e-01,  4.9651e-01,  2.0985e-01,  5.7755e-01,\n",
       "          -1.5010e-01,  1.2627e-01,  2.8222e-01,  8.6244e-01, -8.8222e-01,\n",
       "           1.7768e-01,  2.7793e-01, -1.4089e-01, -4.1912e-01,  4.0391e-01,\n",
       "          -8.5521e-01, -3.1575e-01, -3.4006e-01, -1.8511e-02, -7.9231e-01,\n",
       "           2.1683e-01,  2.4488e-01,  1.4217e-01,  6.2527e-01, -3.1016e-01,\n",
       "           7.9013e-02, -3.5192e-01,  1.7446e-01,  4.6025e-01, -8.4996e-01,\n",
       "          -3.6831e-01,  3.9849e-01,  1.3609e-02, -5.6228e-02, -2.1693e-01,\n",
       "          -4.0183e-01, -1.6610e-01,  2.1076e-01,  6.5671e-02,  1.9757e-01,\n",
       "          -1.9613e-01, -1.1437e-02,  6.5047e-01,  4.1983e-01, -9.6938e-01,\n",
       "          -9.6555e-02,  2.7178e-01,  6.1986e-01, -1.1824e-01, -4.9666e-01,\n",
       "          -1.2449e-01, -3.3851e-01,  7.1044e-03, -9.7110e-02,  1.7650e-01,\n",
       "          -4.3607e-01,  1.5299e-01,  3.6688e-01,  7.8393e-02, -2.6254e-01,\n",
       "          -6.5338e-02, -5.9910e-01, -3.1158e-01, -3.1827e-01,  2.5824e-01,\n",
       "           6.1060e-01, -4.2756e-01, -3.1532e-01,  7.9930e-01, -2.4900e-01,\n",
       "          -5.8887e-01, -3.0326e-01, -4.2005e-01,  8.1087e-01,  1.9026e-01,\n",
       "           5.8720e-02, -1.0691e-01, -6.5346e-01, -5.2555e-01, -4.9081e-01,\n",
       "           1.2580e-01,  1.2030e-02, -4.9266e-01, -2.7087e-01, -2.6797e-01,\n",
       "          -7.3248e-01,  4.0432e-01,  9.4397e-02,  4.1573e-01,  3.8132e-01,\n",
       "           3.4049e-01,  3.5284e-02, -6.3059e-03, -3.2475e-01, -1.5054e+00,\n",
       "           1.3579e-01, -5.2918e-01, -9.0825e-02, -1.7448e-01, -1.0596e+00,\n",
       "          -5.3396e-01, -1.0775e-01,  1.3616e-02,  9.0569e-02, -6.2837e-03,\n",
       "          -2.7704e-01,  8.5087e-01,  1.0328e+00, -1.7665e-01,  1.9358e-01,\n",
       "          -2.8581e-01, -2.1428e-01,  2.8764e-01, -6.5896e-01,  2.7242e-02,\n",
       "          -5.2619e-01, -1.1935e-01,  4.4186e-01, -2.3673e-01,  8.6830e-01,\n",
       "          -1.1093e-03,  3.5446e-01, -5.3437e-01,  3.8490e-01, -3.8707e-01,\n",
       "          -3.6731e-01,  7.1248e-01,  4.8983e-01, -7.0437e-01,  8.8811e-02,\n",
       "           3.9570e-01,  8.9532e-01, -1.9622e-01, -4.1282e-01,  4.8771e-01,\n",
       "          -7.0093e-01, -1.2869e-01, -5.6034e-01,  2.1214e-01,  9.9610e-01,\n",
       "           3.8482e-01,  5.5123e-01,  4.2034e-01, -5.1566e-01, -3.2046e-01,\n",
       "          -4.8052e-01, -3.0249e-01, -4.9538e-01, -3.4690e-01,  7.9660e-01,\n",
       "          -1.3171e-01,  9.8037e-01, -1.4329e-01,  3.2182e-01, -3.2895e-01,\n",
       "           1.0232e-01, -7.2115e-01, -7.2610e-02, -2.1075e-02, -5.1481e-02,\n",
       "           4.1049e-01,  8.3097e-02, -4.8025e-01,  4.2361e-01,  1.3291e-01,\n",
       "          -4.7740e-01, -8.1656e-02,  2.9443e-01, -5.6092e-01, -4.3095e-01,\n",
       "           3.6996e-02,  9.2584e-01, -5.9734e-01,  5.3030e-02,  2.7681e-01,\n",
       "          -4.9360e-01, -3.4962e-01,  1.8612e-01, -1.5272e-01, -6.0027e-03,\n",
       "           6.4589e-01, -1.1248e-01,  1.2958e-01,  3.8884e-01, -4.0197e-01,\n",
       "          -4.8260e-02,  3.4022e-01,  1.1932e+00,  6.0483e-01, -4.0725e-01,\n",
       "           3.2372e-01, -1.2855e-01,  4.9874e-01, -6.4832e-02,  6.2868e-01,\n",
       "          -1.8566e-01, -7.6984e-01, -6.4750e-02, -1.4007e-01, -2.0999e-01,\n",
       "           4.7020e-01, -8.1570e-02, -8.3275e-02, -1.6809e-01,  4.2806e-02,\n",
       "           6.5108e-02, -2.1349e-01,  7.6605e-01, -3.7299e-01,  1.2313e-01,\n",
       "          -5.5771e-01,  5.7179e-01, -5.3901e-02, -1.2518e-01, -2.1930e-01,\n",
       "          -3.2987e-01,  1.0025e-01,  9.5378e-02, -1.2430e-01,  1.5674e-01,\n",
       "           4.9339e-01,  5.3939e-02, -4.2718e-01, -3.7072e-01,  3.8517e-01,\n",
       "          -2.3588e-01, -1.4953e-01, -4.5271e-01, -2.4501e-01,  3.3158e-01,\n",
       "           4.1701e-01,  5.7923e-01, -5.0769e-02,  1.7115e-01,  2.5949e-01,\n",
       "           1.3008e-01, -7.1007e-01, -6.4604e-01, -1.1201e-01, -3.2931e-01,\n",
       "          -3.6348e-01, -2.7448e-01,  1.0955e+00, -6.5157e-01,  8.2420e-02,\n",
       "           8.2378e-02, -2.5171e-01,  1.0651e-01, -8.1347e-02,  6.4916e-02,\n",
       "           4.5382e-01, -3.1907e-01,  4.2985e-01, -8.9897e-02, -3.2740e-01,\n",
       "           1.5957e-02,  1.7024e-01,  8.1521e-01,  5.3980e-01, -5.8045e-01,\n",
       "           3.1088e-01, -4.9719e-01, -4.7089e-01,  2.5926e-01,  4.6671e-01,\n",
       "          -3.4815e-01, -1.9220e-01, -1.0278e-01,  6.6179e-01,  2.1287e-01,\n",
       "           4.5903e-02,  4.4479e-01, -1.0623e-01,  6.4349e-02,  2.9495e-01,\n",
       "           1.3042e-02,  8.4145e-02, -1.7629e-01, -4.3073e-01,  3.9904e-01,\n",
       "          -6.2312e-02,  1.5984e-01,  8.9297e-04,  6.1710e-01, -2.1893e-01,\n",
       "          -1.4832e-01, -1.0634e-01,  3.2229e-02,  2.3802e-01,  2.9586e-01,\n",
       "          -2.2697e-02,  1.7259e-01, -2.5426e-01,  3.6131e-01,  5.0378e-02,\n",
       "          -3.6757e-01,  4.2117e-02, -2.0894e-01, -2.7974e-01, -1.5783e-01,\n",
       "          -1.6949e-01,  3.0102e-01,  2.0375e-02, -5.4823e-01, -8.9763e-01,\n",
       "          -6.6157e-01, -6.9448e-02, -3.0235e-01,  7.7848e-01,  2.3616e-02,\n",
       "          -2.3526e-01,  4.7954e-01, -2.9828e-01, -6.9186e-03, -3.8520e-02,\n",
       "           3.6089e-01, -2.8091e-02,  2.0648e-01], grad_fn=<UnbindBackward0>)),\n",
       " ('[SEP]',\n",
       "  tensor([ 7.7462e-01,  4.5083e-02, -4.5457e-01,  5.2299e-01, -3.1018e-01,\n",
       "          -6.1663e-01,  5.8903e-01, -8.2441e-01,  6.5156e-01, -1.2359e-02,\n",
       "           1.0839e-01, -1.2305e-01, -6.8602e-02, -1.6586e-01, -6.4495e-01,\n",
       "          -4.0666e-01,  6.5158e-02, -9.5635e-02,  1.8092e-01, -1.0582e-01,\n",
       "           6.1284e-01, -9.0046e-02,  8.0203e-01,  2.5275e-01,  4.2188e-01,\n",
       "           2.8761e-01, -5.7623e-01,  4.1587e-03, -3.6217e-01, -4.4975e-01,\n",
       "          -5.1933e-01, -3.8677e-01, -5.9364e-02,  3.3535e-01,  3.7488e-01,\n",
       "          -3.0885e-01,  8.6581e-02, -1.9244e-01, -3.1670e-01, -7.1608e-01,\n",
       "          -5.0860e-01,  6.7544e-02, -3.9054e-01,  2.4472e-01,  1.7479e-01,\n",
       "          -6.0034e-01,  3.7064e-01,  1.6526e-01, -2.1941e-01,  5.2555e-01,\n",
       "           1.3944e-01,  3.9059e-01, -8.0090e-03,  3.3900e-01,  4.2356e-01,\n",
       "           2.3950e-01,  2.9289e-01, -5.7009e-01,  4.6598e-02,  2.7602e-01,\n",
       "           8.7568e-02,  5.6371e-01, -2.7917e-01, -1.0318e-01,  7.1296e-01,\n",
       "           6.4307e-03,  1.7438e-01, -3.7395e-01, -5.3882e-01, -4.0065e-01,\n",
       "          -1.6881e-01, -8.9433e-01,  5.7819e-01, -4.2940e-02,  3.2963e-01,\n",
       "           2.5601e-01, -5.6439e-01,  9.1342e-01,  3.4015e-01,  3.5006e-01,\n",
       "           2.1721e-01, -2.3483e-01,  7.4344e-02,  3.5048e-01,  2.3050e-01,\n",
       "          -3.8327e-02, -2.4594e-01,  2.1391e-01, -2.1605e-01, -6.6521e-02,\n",
       "           1.1841e-01, -2.2836e-02,  5.9985e-01, -3.1238e-03,  1.1504e-02,\n",
       "           4.4652e-01, -4.8002e-02, -8.1473e-02, -2.1325e-01, -8.0107e-02,\n",
       "           7.2248e-02, -2.9503e-01,  3.7410e-02,  8.9451e-01,  8.4038e-02,\n",
       "           3.7828e-02,  3.4206e-01,  2.9699e-01,  1.3942e-01,  7.9086e-01,\n",
       "           6.6408e-01,  1.5355e-01,  9.4433e-02,  1.8165e-02, -1.4227e-01,\n",
       "          -4.7741e-01,  4.0127e-01,  5.5991e-02,  4.3921e-01,  3.5414e-01,\n",
       "          -6.0230e-01, -7.5784e-01,  4.5087e-01,  1.3690e+00, -6.0626e-02,\n",
       "           3.2838e-03,  1.2462e-01, -9.3007e-01,  1.3757e-01, -6.2904e-01,\n",
       "          -6.6627e-01,  5.1101e-01,  6.9472e-01,  8.6163e-01,  8.0352e-02,\n",
       "           2.5906e-01, -1.8167e-01,  2.7013e-01, -8.9289e-01,  1.4281e-01,\n",
       "          -2.1628e-01,  8.8682e-01,  4.9366e-01, -1.1483e+00,  5.7999e-02,\n",
       "           5.0919e-01,  8.9710e-01, -5.7129e-03,  4.5539e-01, -4.1180e-01,\n",
       "           6.9005e-01, -4.5530e-01, -5.4150e-01, -4.8644e-04, -4.0197e-01,\n",
       "          -1.1655e-01, -1.8229e-01, -1.5919e-01,  8.4745e-01,  8.6210e-01,\n",
       "           2.3077e-01,  3.0414e-01,  5.3278e-01,  1.2450e-01, -4.5327e-01,\n",
       "           3.4631e-01, -1.0887e+00,  1.8362e-02,  3.0290e-01,  5.9025e-01,\n",
       "          -5.5168e-01, -2.5463e-01, -2.2389e-01,  2.4859e-01, -3.7775e-01,\n",
       "           4.4190e-01,  2.0209e-01,  2.9868e-02, -2.0812e-01, -6.4473e-01,\n",
       "          -8.2595e+00, -4.8665e-01, -9.4765e-02, -3.5250e-02,  8.2770e-02,\n",
       "          -3.7832e-01, -6.6918e-01, -2.7923e-02,  3.5794e-01, -1.2063e+00,\n",
       "           7.7077e-02,  2.1445e-02, -7.1426e-01,  6.8059e-01,  4.5255e-01,\n",
       "          -2.6052e-01,  1.8451e-01,  2.9304e-01, -2.2144e-01,  2.3636e-02,\n",
       "           4.3029e-02, -2.5105e-01,  1.2136e-01,  5.8514e-01, -2.4079e-01,\n",
       "          -1.5135e+00,  1.7991e-02, -2.8095e-01,  3.0443e-01,  2.6459e-01,\n",
       "          -1.2507e+00, -3.2693e-02,  1.5526e-01, -5.6737e-01,  1.9778e-01,\n",
       "          -4.5388e-01,  1.4978e-01, -5.8951e-01, -9.5583e-01, -3.1278e-01,\n",
       "          -6.5740e-01, -4.4526e-01, -1.7324e-01, -2.2278e-01,  6.6257e-01,\n",
       "          -1.7352e+00,  3.4252e-01,  8.3997e-01,  8.3119e-01,  1.6861e-01,\n",
       "          -5.1658e-02, -2.0038e-02,  7.3184e-01,  3.2780e-01,  2.5248e-01,\n",
       "           9.7308e-02,  3.1479e-01, -7.3903e-02, -2.6768e-01, -6.1836e-01,\n",
       "           4.7526e-02,  1.1585e-01,  2.7419e-01, -1.9075e-01, -6.4674e-01,\n",
       "          -7.2396e-01,  8.7378e-02,  8.8689e-01,  8.8368e-01, -3.2738e-01,\n",
       "           2.4410e-02, -4.4196e-01,  3.7361e-02, -5.4437e-01,  5.3439e-01,\n",
       "           7.6529e-01,  1.3153e-01, -2.3916e-01,  7.1392e-01, -4.6199e-01,\n",
       "           5.3815e-01,  7.2952e-01,  3.2353e-01,  1.9768e-01, -6.7095e-01,\n",
       "           9.5471e-01,  3.4342e-01,  3.1329e-01, -2.9453e-01,  3.5213e-01,\n",
       "           4.0190e-01, -1.2122e-01, -3.8060e-01,  6.1800e-01, -4.9397e-02,\n",
       "          -1.0055e+00,  3.7200e-01, -2.5517e-01,  2.1123e-01, -3.2009e-01,\n",
       "          -3.4710e-01,  2.7085e-01, -1.2820e-01,  4.9886e-01,  3.6340e-01,\n",
       "          -3.4854e-01, -6.5122e-01, -1.3138e-01,  3.3445e-01, -5.8115e-01,\n",
       "          -1.9150e-01, -2.3784e-01,  2.6921e-01,  6.1261e-01, -8.4926e-02,\n",
       "           3.2389e-02,  6.3053e-01,  3.3511e-01, -6.6502e-01, -1.9666e-01,\n",
       "           2.5086e-01, -7.3007e-01, -1.7305e-01,  1.6281e-01, -2.7690e-01,\n",
       "          -1.0238e-01,  3.5961e-01,  5.1796e-02,  5.0550e-01, -8.7550e-02,\n",
       "           4.2700e-01, -6.6868e-01,  3.1546e-01, -3.8149e-02,  5.0014e-02,\n",
       "          -2.7094e-02, -3.1198e-01, -1.6594e-01,  2.5097e-02, -5.3964e-01,\n",
       "           4.0228e-01,  3.5546e-01, -1.7636e-01,  6.3819e-01, -7.4826e-02,\n",
       "          -2.4551e-01, -6.6927e-01, -5.8153e-01, -7.2533e-02,  2.6276e-01,\n",
       "           3.5180e-01, -4.7340e-02,  8.0457e-01, -3.3416e-01, -6.0466e-01,\n",
       "          -2.5961e-01,  3.3150e-01,  2.0226e-01, -7.8263e-02, -6.0058e-01,\n",
       "          -6.6092e-01, -4.5742e-02,  9.5517e-02,  1.7855e-01, -1.9722e-01,\n",
       "           3.2411e-01,  5.4660e-01, -3.5308e-01, -2.2666e-02,  7.2124e-01,\n",
       "          -2.7408e-03, -9.2128e-01, -7.4043e-01, -1.3087e-02, -4.5992e-01,\n",
       "          -5.1979e-01,  1.6134e-02,  4.0469e-01,  8.6272e-01, -1.2656e-01,\n",
       "          -4.4370e-01,  1.4804e-01, -6.2327e-01, -6.9325e-01,  6.2756e-02,\n",
       "           5.4030e-01, -3.1700e-01, -3.2374e-01,  2.2595e-01, -4.7920e-01,\n",
       "           4.3534e-01, -4.3477e-02, -2.7840e-01,  1.0686e-01,  1.7364e-01,\n",
       "           3.7536e-01, -2.0127e-01, -1.5204e-01, -3.3496e-02, -5.1742e-01,\n",
       "          -5.9455e-01, -6.3096e-01, -4.4781e-01,  5.0936e-01, -4.8638e-01,\n",
       "           2.6708e-01,  5.1442e-01,  1.5468e-02,  3.5976e-01,  2.1690e-01,\n",
       "           6.9988e-03,  3.8938e-01,  2.7232e-02,  8.3928e-02, -7.4029e-02,\n",
       "          -1.2773e-01,  5.9902e-01, -7.6369e-01,  2.8591e-01,  2.8900e-02,\n",
       "           9.5828e-02, -2.5422e-02, -1.3360e-01,  6.5094e-01,  3.1095e-01,\n",
       "          -5.7303e-02, -6.9302e-02,  2.6403e-02, -2.6286e-01, -1.6668e-01,\n",
       "           5.1342e-01, -4.3400e-01, -3.3983e-01,  4.3069e-01, -6.5055e-01,\n",
       "          -6.0460e-01, -4.1951e-01, -2.4153e-01,  2.0494e-01, -6.9489e-01,\n",
       "           5.4465e-01,  3.4731e-02, -1.8587e-01, -7.5414e-01, -2.4230e-01,\n",
       "           6.1996e-01, -1.1000e-01,  5.1860e-01,  3.1290e-01,  4.2632e-01,\n",
       "           6.7785e-01,  4.8488e-01, -1.2683e-01, -2.2129e-01, -5.6327e-02,\n",
       "          -4.9226e-01,  7.4889e-02, -2.8280e-01,  3.3020e-01,  7.7335e-02,\n",
       "           1.2207e-02, -5.4753e-01, -4.5870e-01,  4.7803e-01,  8.0853e-01,\n",
       "           1.0002e+00,  4.5403e-01,  5.6619e-01,  4.1967e-01,  6.2633e-01,\n",
       "          -7.0099e-01, -4.8164e-01, -8.1179e-02,  6.1172e-01, -2.7872e-01,\n",
       "           3.0183e-01,  9.2749e-01, -9.6235e-02,  1.5708e-01,  4.2654e-01,\n",
       "           3.0762e-01, -1.1784e+00,  3.0936e-01, -4.6072e-01,  2.6990e-01,\n",
       "           9.0744e-03, -1.0570e+00,  6.5896e-01, -5.8161e-01,  2.4989e-01,\n",
       "           3.0053e-01, -9.3917e-03, -6.9271e-01, -9.8877e-01,  4.3127e-01,\n",
       "          -5.8381e-01, -4.1579e-01,  3.5291e-01,  2.2381e-01, -2.2155e-01,\n",
       "           7.0551e-01, -2.1297e-01, -2.2963e-01,  5.7215e-01,  2.4811e-01,\n",
       "          -3.9012e-01, -4.7348e-02, -1.0177e-01,  1.9094e-01, -8.5077e-01,\n",
       "          -5.0190e-02, -7.8092e-02,  3.6164e-01,  1.0238e-01, -8.4401e-02,\n",
       "          -4.9122e-01,  3.3749e-01, -1.5131e-01,  5.0231e-01, -7.2488e-01,\n",
       "          -7.3338e-01,  1.0885e-01, -1.5754e-01,  7.8402e-01,  5.0434e-01,\n",
       "          -4.6194e-01,  3.0205e-01,  2.1072e-01,  6.5540e-01,  3.2947e-01,\n",
       "          -6.6971e-01,  6.7175e-02, -2.7942e-01, -2.7404e-01,  1.7754e-01,\n",
       "           2.1092e-01, -3.7178e-01, -6.0395e-01,  4.7703e-02, -6.5195e-01,\n",
       "          -3.9968e-01, -3.7986e-02,  9.4798e-01,  3.0742e-01,  1.1875e-01,\n",
       "           2.9808e-02,  9.8517e-01, -3.9448e-01, -7.5387e-01, -2.8240e-01,\n",
       "           6.4520e-02,  3.6231e-01,  2.3216e-01, -7.7782e-01, -7.2214e-01,\n",
       "           1.7842e-01, -7.3450e-01,  2.0241e-01,  4.3057e-01,  4.5168e-01,\n",
       "          -6.9618e-01,  4.2595e-02,  7.4483e-01,  4.1876e-01, -9.5895e-02,\n",
       "           7.3596e-02, -1.8278e-01, -2.4518e-01, -3.9707e-01,  4.2520e-02,\n",
       "          -2.4899e-01, -1.2506e-01,  3.1428e-01,  1.5291e-02,  4.4605e-01,\n",
       "           1.4442e+00, -3.1473e-01, -9.0879e-01, -2.2928e-01, -1.2736e-01,\n",
       "           3.2957e-01, -9.0296e-02, -5.9104e-01, -5.9748e-01, -6.3059e-01,\n",
       "          -3.7740e-02, -3.2208e-01, -4.6733e-01,  6.2463e-02, -8.8014e-02,\n",
       "           8.0704e-01, -9.1243e-01,  3.6369e-01,  8.3786e-02, -2.1949e-01,\n",
       "           1.5697e-02,  3.1716e-02,  4.3698e-01,  3.1566e-01,  4.6234e-01,\n",
       "          -2.7883e-01,  3.5539e-02, -6.1957e-01,  2.0789e-01,  5.0532e-01,\n",
       "          -4.6312e-01, -4.7164e-01,  3.3986e-03,  2.1055e-01,  4.8958e-01,\n",
       "          -3.1614e-01, -7.2517e-02, -2.9202e-01, -1.9413e-01,  2.4360e-01,\n",
       "           3.2795e-01, -3.5332e-01, -6.6574e-01,  9.3564e-01, -1.0171e-01,\n",
       "          -3.7799e-01, -2.3139e-01, -5.5975e-01,  1.3868e-01, -2.3953e-01,\n",
       "           4.5908e-01, -3.6948e-01,  3.8043e-02,  8.8031e-02,  6.9464e-01,\n",
       "           1.9848e-02, -2.8962e-02, -1.6180e-01, -2.4429e-01,  2.4723e-01,\n",
       "           2.9600e-02, -3.5002e-02, -1.3855e-01, -6.4000e-01,  4.6287e-01,\n",
       "           4.4430e-01,  3.7453e-01, -1.5941e+00, -1.2756e-01,  1.2236e-02,\n",
       "          -8.6956e-01,  2.5127e-01,  7.3063e-01,  3.2162e-01,  2.9316e-01,\n",
       "           2.3703e-01, -1.5458e-01,  4.2133e-01,  3.1687e-01, -4.7558e-01,\n",
       "          -3.8349e-01, -7.5668e-01, -5.7039e-02,  1.0040e+00,  8.3096e-01,\n",
       "          -1.6328e-01,  5.9497e-01,  2.6549e-01, -3.5476e-01,  3.6886e-01,\n",
       "           5.0896e-01,  8.5721e-02, -6.4767e-01,  1.5499e-02,  1.0420e-01,\n",
       "          -1.1888e-01,  2.1224e-01,  1.4645e-01,  1.7992e-01,  2.5299e-01,\n",
       "          -3.0521e-01,  4.2608e-02, -3.7226e-01,  3.6781e-01, -3.8707e-02,\n",
       "          -2.8447e-01,  3.1520e-01, -5.3031e-01,  3.8415e-02,  3.0338e-01,\n",
       "           4.5126e-01,  1.7065e-01,  1.0820e-01, -1.1846e-01, -6.2245e-01,\n",
       "          -8.6198e-01, -6.1574e-01,  1.6520e-01,  7.6852e-01,  4.1418e-01,\n",
       "          -3.6522e-01, -4.0355e-01,  3.3292e-01,  7.8524e-01,  6.8494e-01,\n",
       "          -2.5255e-01, -8.4868e-01, -1.5818e-01,  3.0093e-01, -6.3073e-01,\n",
       "           6.0088e-01, -9.7856e-01,  1.4137e-01,  4.2605e-01, -9.7516e-02,\n",
       "          -1.6542e-01,  7.5224e-03,  2.3354e-01, -3.0491e-01, -4.0847e-01,\n",
       "          -4.7031e-01, -6.7562e-02,  1.1127e-01,  4.0402e-01, -9.7837e-01,\n",
       "          -1.0201e-01, -1.7468e-01,  5.0195e-01,  3.0746e-01,  8.4361e-01,\n",
       "          -8.3815e-02,  7.0544e-01,  3.7372e-01,  8.3178e-01, -2.0034e-01,\n",
       "          -7.2906e-01,  3.9546e-01,  3.2947e-01, -1.0465e-02,  1.4345e+00,\n",
       "          -3.9200e-01,  7.5230e-01, -2.8715e-01, -7.5316e-01,  5.2569e-02,\n",
       "          -3.0278e+00,  2.6675e-01, -2.9554e-02, -2.2632e-01, -2.6022e-01,\n",
       "           4.2997e-01, -6.8222e-02, -4.0010e-01, -2.5427e-01, -1.6973e-01,\n",
       "           6.0831e-01, -2.3477e-01, -3.7342e-01,  4.1223e-01, -3.9081e-02,\n",
       "           5.9296e-01, -1.4125e-01, -1.3610e-01,  7.8553e-01,  2.7773e-01,\n",
       "           1.4263e-01,  7.9831e-02,  2.6617e-01, -5.4814e-01, -3.9576e-01,\n",
       "           8.7607e-02, -5.2816e-01, -6.1159e-01, -1.4896e-01, -1.4971e-01,\n",
       "           5.4236e-01,  1.3793e-01,  6.8396e-01, -1.2560e-01,  9.4099e-01,\n",
       "          -1.2566e-01,  5.8695e-02, -3.1367e-01,  1.6317e-01,  8.7148e-02,\n",
       "          -5.3695e-01, -5.9805e-01,  9.4683e-02, -7.8507e-01,  5.0292e-02,\n",
       "           2.9994e-01, -7.7845e-01, -3.6873e-01], grad_fn=<UnbindBackward0>))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_embedding_w_token(text):\n",
    "    encoded_text_with_input_ids_and_attention_masks_etc = tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
    "    model_output =  model(**encoded_text_with_input_ids_and_attention_masks_etc)\n",
    "    input_ids = encoded_text_with_input_ids_and_attention_masks_etc[\"input_ids\"]\n",
    "    #print(input_ids)\n",
    "    #print(tokenizer.decode(input_ids[0])) ## can \"skip_special_tokens=True\" if want as arg\n",
    "    #print(tokenizer.convert_ids_to_tokens(input_ids[0]))\n",
    "    tokenized_text_with_special_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    return list(zip(tokenized_text_with_special_tokens, model_output[0][0]))\n",
    "get_word_embedding_w_token(\"hi adasd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: tensor([-0.0822,  0.3846, -0.1603, -0.1345, -0.4700, -0.1406,  0.2869,  0.3630,\n",
      "         0.1515, -0.1577], grad_fn=<SliceBackward0>)\n",
      "hi: tensor([ 0.1907,  0.7592,  0.7074, -0.8120, -0.5279,  0.3422, -0.2485, -0.2750,\n",
      "         0.0132, -0.6560], grad_fn=<SliceBackward0>)\n",
      "there: tensor([-0.7504,  0.7193, -0.3853, -0.0587,  0.3199,  0.0936, -0.2988,  1.1447,\n",
      "         0.4214, -0.4911], grad_fn=<SliceBackward0>)\n",
      "bas: tensor([ 0.4593,  0.4747, -0.0241, -0.5151, -0.8363, -0.6710,  0.7688, -0.1853,\n",
      "        -0.5306, -0.4110], grad_fn=<SliceBackward0>)\n",
      "##ae: tensor([ 0.1660,  0.2491,  0.5833, -0.5256,  0.0690,  0.1758,  0.2441, -0.0761,\n",
      "        -0.0694,  0.3108], grad_fn=<SliceBackward0>)\n",
      "##w: tensor([ 0.2123,  0.1483,  0.0374, -0.1016, -0.1094, -0.0771,  0.1752,  0.1314,\n",
      "        -0.0956, -0.1034], grad_fn=<SliceBackward0>)\n",
      "[SEP]: tensor([ 0.7705,  0.0766, -0.3977,  0.4511, -0.4394, -0.6858,  0.3326, -0.8821,\n",
      "         0.6056, -0.0393], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def show_tok_word_emb(some_text, cut_ten=False):\n",
    "    for tok, emb in get_word_embedding_w_token(some_text):\n",
    "        if cut_ten:\n",
    "            print(f\"{tok}: {emb[:10]}\")\n",
    "        else:\n",
    "            print(f\"{tok}: {emb}\")\n",
    "show_tok_word_emb(\"hi there basaew\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: tensor([-0.2264,  0.4792, -0.2430,  0.0325, -0.4012, -0.6995,  0.2460,  0.9113,\n",
      "        -0.2310, -0.1256], grad_fn=<SliceBackward0>)\n",
      "slap: tensor([ 0.2286,  0.6143,  0.4380, -0.5413, -0.0462, -0.0814,  0.1635, -0.0780,\n",
      "        -0.3251, -0.5345], grad_fn=<SliceBackward0>)\n",
      "you: tensor([-1.2533,  0.2097, -0.1444, -0.8390, -0.8554,  0.2319,  0.0104,  0.9878,\n",
      "        -1.1859, -0.1656], grad_fn=<SliceBackward0>)\n",
      "[SEP]: tensor([ 0.7715,  0.0902, -0.2625,  0.4693, -0.4473, -0.5719,  0.6055, -0.5190,\n",
      "         0.6415,  0.3206], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "show_tok_word_emb(\"slap you\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]: tensor([-0.3022,  0.3190, -0.6128,  0.1541, -0.3523, -0.4283,  0.1539,  0.2861,\n",
      "        -0.1903, -0.1779], grad_fn=<SliceBackward0>)\n",
      "you: tensor([-0.2600,  0.4986, -0.1865, -0.4177, -0.7537,  0.0725, -0.3126,  0.6242,\n",
      "        -0.9493,  0.0482], grad_fn=<SliceBackward0>)\n",
      "slap: tensor([-0.0172,  0.2409, -0.6623, -0.5686, -0.6019, -0.1607,  0.7887,  0.4799,\n",
      "        -0.5663, -0.4142], grad_fn=<SliceBackward0>)\n",
      "[SEP]: tensor([ 0.9696,  0.0754, -0.1899,  0.5092, -0.3665, -0.5967,  0.5519, -0.5004,\n",
      "         0.6059,  0.2141], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "show_tok_word_emb(\"you slap\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cls_embedding(text): # sort of like sentence embedding maybe? i hope so\n",
    "    return get_word_embedding(text)[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3022,  0.3190, -0.6128,  ..., -0.1108,  0.2266,  0.3345],\n",
       "        [-0.2600,  0.4986, -0.1865,  ...,  0.2049,  0.8535, -0.6136],\n",
       "        [-0.0172,  0.2409, -0.6623,  ...,  0.2108,  0.3582, -0.3635],\n",
       "        [ 0.9696,  0.0754, -0.1899,  ..., -0.0337, -0.8699, -0.3466]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_embedding(\"you slap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0216e-01,  3.1903e-01, -6.1283e-01,  1.5407e-01, -3.5226e-01,\n",
       "        -4.2829e-01,  1.5390e-01,  2.8611e-01, -1.9028e-01, -1.7794e-01,\n",
       "         6.2591e-02,  2.2631e-01, -2.7719e-01,  4.4759e-01,  8.0433e-04,\n",
       "         1.1076e-01, -9.8800e-02,  2.7483e-01,  1.9675e-02, -1.0155e-01,\n",
       "         1.9854e-01,  3.4159e-02, -7.7434e-02,  1.0788e-01, -1.1583e-02,\n",
       "        -1.2412e-02, -1.8740e-01, -4.4906e-01,  9.0015e-02, -5.2500e-02,\n",
       "        -1.2867e-01,  1.1498e-02, -4.2578e-01, -3.0835e-02, -1.1381e-01,\n",
       "        -6.6668e-02,  8.3218e-02,  3.4710e-01, -2.2852e-01, -2.0305e-01,\n",
       "        -1.2648e-01,  2.4238e-01, -1.7087e-01,  1.6629e-02,  4.3587e-02,\n",
       "         1.4640e-02, -1.9185e+00,  1.5873e-01,  5.6473e-02, -5.6386e-01,\n",
       "        -5.0768e-02,  1.6419e-01,  3.1613e-01, -7.6420e-02,  2.7087e-01,\n",
       "         2.8472e-01, -3.1631e-05,  6.9438e-01, -2.7928e-01,  7.0762e-02,\n",
       "         2.9739e-02,  2.1687e-01, -4.5777e-02,  2.3344e-02,  2.2826e-01,\n",
       "         2.1865e-01,  9.3328e-02,  7.7339e-01, -4.1245e-01,  4.0291e-01,\n",
       "        -4.1928e-01, -3.6181e-01,  4.1378e-01, -1.6336e-01,  1.0317e-01,\n",
       "        -4.4067e-01, -2.7876e-01,  6.5294e-02, -1.9365e-01, -1.5477e-01,\n",
       "         1.6795e-02,  1.6201e-01,  8.3718e-02, -9.6085e-02,  3.2413e-02,\n",
       "         4.0302e-01,  3.8902e-03, -3.3934e-01, -1.4547e-01,  4.2389e-01,\n",
       "         1.8596e-01,  2.3212e-01,  3.5853e-01,  3.9517e-01,  4.7277e-02,\n",
       "        -2.0624e-01,  5.0785e-01,  4.7412e-02,  1.3625e-01, -2.0703e-01,\n",
       "         5.8801e-02, -3.7876e-01,  3.5633e-01, -3.4073e-01,  1.0994e-01,\n",
       "         3.2010e-01,  3.9570e-02, -3.1380e-02, -2.3001e-02, -2.7556e+00,\n",
       "         4.7550e-01, -3.8089e-01, -1.0403e-02, -3.6889e-01, -2.7151e-01,\n",
       "         7.7844e-02,  4.7097e-01,  1.5503e-01,  1.3748e-01, -1.1831e-01,\n",
       "         5.0020e-02,  1.0278e-01,  2.6593e-01,  4.7978e-02,  4.4148e-01,\n",
       "         1.0068e-01, -3.2156e-01, -5.3439e-02,  2.3204e-01, -1.2199e-01,\n",
       "         2.3683e-01,  3.3221e-01, -1.8750e-02, -2.1213e-01, -3.7402e-01,\n",
       "        -1.2803e-01,  3.7411e-01, -2.3274e-01,  4.4616e-02, -3.9568e-01,\n",
       "        -5.5456e-02, -2.7940e-01, -3.2899e+00,  4.8034e-01,  3.9378e-01,\n",
       "        -3.6177e-01, -7.2770e-01, -1.0333e-01,  7.7551e-02, -2.7465e-02,\n",
       "        -1.5271e-01,  1.3643e-01, -2.2773e-01, -2.1545e-02, -1.9036e-04,\n",
       "        -1.9149e-01, -4.3678e-02, -3.0694e-01, -1.6462e-01,  3.7942e-01,\n",
       "         3.1193e-01, -2.2982e-01,  1.7626e-01, -1.2581e-02, -1.4276e-01,\n",
       "        -1.7223e-01,  1.3962e-01,  3.6115e-01, -8.0917e-04, -3.3694e-02,\n",
       "        -3.3829e-01,  2.0888e-01,  6.8638e-01,  3.6330e-01,  3.4118e-01,\n",
       "        -1.0618e-01,  4.4305e-01,  2.4793e-01,  2.4221e-01, -5.2548e-02,\n",
       "        -2.0648e-01,  6.4978e-01,  1.8898e-02, -2.0206e-02,  4.2801e-01,\n",
       "         3.6390e-01,  2.8540e-01, -3.5374e-01,  1.1779e-01,  9.1421e-02,\n",
       "        -2.5159e-01,  1.9505e-01,  3.4613e-01,  2.4373e-01,  2.0833e-01,\n",
       "        -6.9684e-01, -3.7781e-02, -2.6877e-01,  3.8857e-01,  1.7077e-01,\n",
       "         3.7161e-02,  3.3294e-02, -2.8830e-01,  3.6203e-02, -1.3177e-01,\n",
       "         4.2426e+00, -6.5609e-02, -3.8311e-01,  2.6079e-01,  4.4054e-01,\n",
       "        -2.4274e-01,  6.7816e-01, -1.8640e-01,  2.7957e-01, -4.6941e-02,\n",
       "         4.9484e-02,  6.0769e-02,  1.2539e-01, -8.0371e-02, -1.7930e-01,\n",
       "         5.1635e-01,  1.1406e-01, -1.4921e-01, -1.2852e-01,  1.6883e-01,\n",
       "         5.8500e-02,  5.5615e-02,  5.4367e-02, -2.1416e-02, -1.4820e+00,\n",
       "         1.0029e-01,  1.0522e-01, -1.5832e-01,  3.7358e-01, -1.8581e-01,\n",
       "         1.8614e-01,  1.2328e-01, -1.9044e-01, -4.0732e-02,  5.6514e-02,\n",
       "         1.0237e-01,  4.3967e-01,  3.4417e-01,  1.0596e-01, -1.1586e-01,\n",
       "         3.0616e-01,  4.1759e-01, -1.5467e-01,  4.2579e-01,  8.2863e-02,\n",
       "         2.2320e-01, -3.3161e-01, -8.4889e-02, -1.6451e-01, -2.9910e-01,\n",
       "        -2.4058e-01, -9.7154e-02,  3.0165e-01, -3.7962e-01,  5.1222e-02,\n",
       "        -1.3042e-01, -2.7926e-01, -5.7349e-02,  1.0263e-01, -2.6383e-01,\n",
       "         4.9546e-02,  6.6063e-01, -1.5946e-02,  2.1820e-01, -6.7036e-03,\n",
       "         1.5619e-02,  5.0714e-02, -9.1638e-02, -4.3368e+00,  1.0257e-01,\n",
       "         2.4046e-01,  2.0304e-01,  5.2267e-01,  6.9457e-02, -1.5208e-01,\n",
       "         1.7361e-01, -9.4615e-02, -5.4637e-01,  1.9370e-01,  3.9269e-01,\n",
       "        -1.6798e-01,  2.1988e-01, -4.4461e-01,  2.5130e-01,  1.5310e-01,\n",
       "         4.4021e-02,  8.6622e-02, -1.0350e-01, -6.2705e-03,  5.0736e-01,\n",
       "        -3.8504e-01,  4.5571e-02,  9.6540e-02,  3.0507e-01, -3.7656e-01,\n",
       "        -4.8082e-02,  5.4115e-01, -6.5671e-02,  7.0245e-02, -2.6350e-02,\n",
       "         2.2261e-01,  7.0113e-02, -5.3680e-01, -1.7586e+00, -8.6069e-02,\n",
       "         1.6613e-01, -5.8941e-01,  3.9082e-01, -1.8872e-01,  3.2482e-01,\n",
       "        -1.8042e-01, -6.9501e-01,  1.8123e-01, -2.2414e-02, -1.1655e-01,\n",
       "         4.3075e-02,  1.5083e-01,  2.0445e-01, -4.8591e-01,  2.4382e-01,\n",
       "        -1.1325e-01, -1.2127e-01,  9.9167e-03,  1.4776e-01, -2.0037e-02,\n",
       "         3.4553e-01,  1.4592e-01, -2.0293e-03,  3.4223e-01, -2.9330e-01,\n",
       "        -1.8467e-01, -2.1310e-01, -3.1566e-01, -2.2653e-01, -4.1877e-01,\n",
       "         1.9840e-01,  3.7080e-01,  6.8882e-02, -3.8919e-01,  2.6263e-01,\n",
       "         1.5371e-01,  5.6646e-01,  6.3491e-02,  3.7417e-01,  2.7244e-01,\n",
       "         2.5486e-01,  5.8406e-01,  5.8223e-01,  2.5799e-01, -3.1895e-02,\n",
       "        -1.6285e-01, -4.2109e-01,  8.8467e-02,  3.2106e-01, -4.1638e-01,\n",
       "         1.2229e+00, -5.8135e-01,  1.1192e-01, -1.5256e-01,  1.0361e-01,\n",
       "        -1.2431e-01,  1.3822e-01, -1.1372e-01,  4.9710e-01,  1.9996e-01,\n",
       "         3.5299e-02,  5.3074e-01, -1.7758e-01, -4.5200e-01, -3.7568e-02,\n",
       "        -4.9113e-01,  3.8700e-01,  3.2924e-01,  3.5486e-02,  5.9623e-02,\n",
       "        -2.7264e-01, -9.8824e-01, -2.7904e-01,  3.8662e-01,  5.0260e-02,\n",
       "        -7.9070e-02,  2.8147e-01, -3.5749e-01, -3.0785e-02, -1.4496e-01,\n",
       "         9.7805e-02,  2.2930e-01, -4.4995e-01,  1.9500e-01,  2.4927e-01,\n",
       "         3.0885e-02,  1.0132e-02,  7.1548e-02, -1.6299e-01,  3.5818e-01,\n",
       "         1.8167e-01, -1.1285e-01,  4.4329e-02,  1.7787e-02,  3.2266e-02,\n",
       "        -6.2577e-01,  1.5352e-01, -3.2760e-01, -4.6940e-01, -4.0676e-01,\n",
       "        -3.3379e-01,  2.9465e-01, -2.5413e-01,  7.0845e-02, -7.6027e-01,\n",
       "         2.6524e-01, -2.6257e-01,  5.6491e-01, -9.1524e-03,  1.3640e-01,\n",
       "         3.2539e-01,  1.5922e-01,  5.5800e-01, -8.3918e-02,  3.5351e-01,\n",
       "         3.1714e-01, -1.0540e-01,  5.0520e-02,  1.0876e-02,  4.5797e-01,\n",
       "        -3.3590e-01,  1.8235e-01,  3.5544e-01,  1.5331e-01,  4.6425e-03,\n",
       "        -4.5927e-01, -2.5609e-01, -1.2196e-01,  1.9411e-01, -8.1818e-02,\n",
       "        -1.6957e-01, -4.7461e-01, -3.9288e-02, -2.8530e-01, -2.0318e-01,\n",
       "        -8.8294e-02, -9.6994e-02,  1.7446e-01,  1.0274e-01,  3.7550e-02,\n",
       "        -4.6575e-01,  3.3493e-01,  2.5060e-02,  5.0201e-01, -4.3851e-01,\n",
       "         1.2111e-01,  2.9676e-01,  6.1099e-01, -1.3660e-01, -3.3689e-01,\n",
       "         1.9566e-01, -1.1645e-01,  1.2058e-01,  3.6611e-01, -2.8622e-01,\n",
       "        -4.6788e-01,  1.8664e-01,  5.6509e-02, -4.3529e-01,  3.9721e-01,\n",
       "        -1.5340e+00,  1.2604e-01,  6.7640e-02, -3.9702e-01,  5.3916e-01,\n",
       "         1.8636e-01, -3.7509e-01,  6.3011e-01,  3.4937e-01,  3.6117e-03,\n",
       "        -1.1656e-02,  2.0342e-01, -1.0555e-01,  1.0513e-01, -1.0994e-01,\n",
       "        -2.1745e-03,  4.8318e-01, -1.9176e-01,  4.4097e-02, -5.3394e-02,\n",
       "        -1.5231e-01,  3.4701e-01,  7.2896e-02, -3.1473e-01, -1.1973e-01,\n",
       "         2.5812e-01,  1.1971e-01,  4.6424e-01, -3.3529e-01, -9.6727e-02,\n",
       "         4.1950e-01, -2.6121e-01, -4.8247e-01, -1.9466e-01,  4.4419e-02,\n",
       "        -1.9492e-01, -9.0341e-02,  3.2293e-01,  9.0145e-02,  1.6904e-01,\n",
       "         1.1435e-01,  6.4890e-02,  1.6499e-01, -2.8675e-01,  1.4943e-01,\n",
       "         9.0741e-02, -3.4499e-01, -4.4406e-02,  2.0878e-01, -3.4212e-01,\n",
       "        -5.6393e-01,  5.2120e-02, -2.6423e-01, -3.5125e-01,  2.8071e-01,\n",
       "         6.9792e-02, -1.3034e-01, -2.8973e-01, -6.1615e-01,  1.1026e-01,\n",
       "         5.8751e-02, -7.6137e-02, -1.3013e-01,  2.6355e-01, -7.2323e-01,\n",
       "        -3.5802e-01,  3.4616e-01, -7.5927e-02,  3.2541e-01, -3.1318e-03,\n",
       "         1.7594e-01, -1.1980e-01,  6.6695e-02,  1.4339e-01, -2.6372e-01,\n",
       "         2.8697e-01,  6.2493e-02,  1.5200e-02,  1.2126e-01, -2.3792e-01,\n",
       "        -4.7075e-01, -4.2247e-02, -1.8681e-02,  1.0742e-01, -9.1367e-02,\n",
       "         5.7936e-01,  4.8788e-01, -2.3291e-02, -3.6559e-01,  2.4100e-01,\n",
       "        -3.2220e-01,  1.4054e-02,  2.2441e-01,  4.0189e-02, -2.6893e-01,\n",
       "        -3.4323e-01,  3.0691e-01,  1.1039e-01, -2.0364e-01,  3.5700e-01,\n",
       "         7.6891e-02,  4.0365e-01,  3.5670e-01, -1.4020e-01,  1.6451e-01,\n",
       "         5.4923e-02,  3.9413e-01,  3.2931e-01,  2.2695e-03, -1.6567e-01,\n",
       "        -2.3411e-01,  3.9799e-02, -2.0689e-01, -6.1466e-02,  4.5320e-02,\n",
       "        -6.0107e-02,  3.9252e-01, -4.2025e-02,  2.4671e+00,  5.9533e-01,\n",
       "         4.3833e-02, -1.1311e-01,  6.1881e-02,  1.6363e-01,  1.5949e-01,\n",
       "        -2.1544e-01, -2.7266e-01, -1.8765e-02,  2.3656e-01,  2.2283e-01,\n",
       "         3.6299e-01,  3.4400e-02,  7.8310e-01,  3.9824e-01, -1.7747e-01,\n",
       "        -1.0231e-02, -7.3003e-01,  1.8450e-01, -4.9052e-02,  1.7828e-01,\n",
       "         3.4240e-01, -5.1175e-02,  8.2784e-02,  3.8145e-01,  1.7230e-01,\n",
       "        -5.2151e-02, -2.1753e-01, -1.9537e-01, -4.5584e-01, -4.3574e-01,\n",
       "         6.0960e-02, -3.5581e-01, -3.7799e-01,  3.4320e-01,  3.2095e-01,\n",
       "        -3.2994e-01,  2.4694e-01,  2.3691e-02, -9.6979e-02, -1.5378e-01,\n",
       "         6.5905e-01,  3.2034e-01,  2.7468e-01,  5.1482e-01, -1.2401e-01,\n",
       "        -8.1927e-02,  4.0822e-01, -9.8134e-02, -9.1149e-02, -6.7248e-02,\n",
       "        -5.4695e-01,  5.7288e-02, -6.9500e-02, -3.5697e-01,  6.0696e-02,\n",
       "        -6.5336e-02, -1.6879e-01,  9.3601e-03, -1.0201e-01, -6.3897e-02,\n",
       "         3.9621e-01, -1.3471e-01,  1.4396e-01,  2.6462e-01, -1.3375e-01,\n",
       "         5.5976e-03,  3.4723e-01, -5.9051e-02,  1.6861e-01,  1.4938e-01,\n",
       "         2.0632e-01, -9.2595e-02,  2.7472e-01,  9.3809e-02,  5.5253e-02,\n",
       "        -6.5447e-03, -6.3001e-01, -3.3820e+00,  2.3470e-01,  4.0595e-01,\n",
       "         4.5948e-02, -1.7026e-01,  1.8406e-01,  3.1701e-01,  9.0024e-02,\n",
       "         7.0709e-02, -4.1563e-02,  1.7077e-01,  1.0976e-01, -6.8388e-02,\n",
       "         2.1580e-01, -4.1912e-02,  2.5313e-01,  2.0944e-01, -6.1528e-01,\n",
       "        -2.1359e-01, -4.1064e-01, -8.3710e-02, -1.7674e-01, -1.4181e-01,\n",
       "        -3.0793e-01, -4.0789e-02,  4.9168e-01,  2.8411e-01, -1.5762e-01,\n",
       "        -5.0076e-01,  2.3118e-01, -1.2897e-01,  2.4419e-01,  9.3798e-02,\n",
       "        -1.2297e-02, -9.0225e-02, -6.0647e-02,  1.4078e-01, -1.2516e-01,\n",
       "         3.0963e-01,  9.9271e-02,  2.4340e-01,  6.7375e-01, -1.6642e-01,\n",
       "        -1.6373e-01, -1.7776e-01, -2.0297e-01,  4.4338e-01,  6.3007e-02,\n",
       "         5.3656e-01, -1.2315e-01,  1.0672e-01, -9.5986e-02,  9.1745e-02,\n",
       "        -6.9517e-02, -1.2986e-01, -6.1014e-02, -3.9922e-01, -8.1747e-02,\n",
       "        -4.2779e-02,  4.6613e-02,  2.8660e-01, -2.6962e-03, -9.0070e-02,\n",
       "         4.2988e-02,  4.0699e-01, -4.0038e-01,  1.0890e-01, -2.7165e-01,\n",
       "        -5.6262e-02, -1.0275e-01,  1.3369e-02, -3.0308e-01,  2.2683e-01,\n",
       "        -2.2953e-01, -7.0040e-02,  3.1226e-02,  2.7516e-01,  7.2677e-02,\n",
       "        -4.1981e-01, -1.2059e-01,  2.8639e-02,  1.6866e-01, -1.5574e-02,\n",
       "        -2.3324e-01,  2.6682e-02, -8.8357e+00, -1.9912e-01, -2.1892e-01,\n",
       "        -5.7330e-02,  7.8102e-02, -1.0763e-01, -4.9417e-03, -2.0768e-01,\n",
       "         1.7425e-02, -3.5526e-01,  1.4145e-01, -2.6619e-01, -2.6477e-01,\n",
       "        -1.1081e-01,  2.2660e-01,  3.3454e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cls_embedding(\"you slap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.0216e-01,  3.1903e-01, -6.1283e-01,  1.5407e-01, -3.5226e-01,\n",
       "         -4.2829e-01,  1.5390e-01,  2.8611e-01, -1.9028e-01, -1.7794e-01,\n",
       "          6.2591e-02,  2.2631e-01, -2.7719e-01,  4.4759e-01,  8.0433e-04,\n",
       "          1.1076e-01, -9.8800e-02,  2.7483e-01,  1.9675e-02, -1.0155e-01,\n",
       "          1.9854e-01,  3.4159e-02, -7.7434e-02,  1.0788e-01, -1.1583e-02,\n",
       "         -1.2412e-02, -1.8740e-01, -4.4906e-01,  9.0015e-02, -5.2500e-02,\n",
       "         -1.2867e-01,  1.1498e-02, -4.2578e-01, -3.0835e-02, -1.1381e-01,\n",
       "         -6.6668e-02,  8.3218e-02,  3.4710e-01, -2.2852e-01, -2.0305e-01,\n",
       "         -1.2648e-01,  2.4238e-01, -1.7087e-01,  1.6629e-02,  4.3587e-02,\n",
       "          1.4640e-02, -1.9185e+00,  1.5873e-01,  5.6473e-02, -5.6386e-01,\n",
       "         -5.0768e-02,  1.6419e-01,  3.1613e-01, -7.6420e-02,  2.7087e-01,\n",
       "          2.8472e-01, -3.1631e-05,  6.9438e-01, -2.7928e-01,  7.0762e-02,\n",
       "          2.9739e-02,  2.1687e-01, -4.5777e-02,  2.3344e-02,  2.2826e-01,\n",
       "          2.1865e-01,  9.3328e-02,  7.7339e-01, -4.1245e-01,  4.0291e-01,\n",
       "         -4.1928e-01, -3.6181e-01,  4.1378e-01, -1.6336e-01,  1.0317e-01,\n",
       "         -4.4067e-01, -2.7876e-01,  6.5294e-02, -1.9365e-01, -1.5477e-01,\n",
       "          1.6795e-02,  1.6201e-01,  8.3718e-02, -9.6085e-02,  3.2413e-02,\n",
       "          4.0302e-01,  3.8902e-03, -3.3934e-01, -1.4547e-01,  4.2389e-01,\n",
       "          1.8596e-01,  2.3212e-01,  3.5853e-01,  3.9517e-01,  4.7277e-02,\n",
       "         -2.0624e-01,  5.0785e-01,  4.7412e-02,  1.3625e-01, -2.0703e-01,\n",
       "          5.8801e-02, -3.7876e-01,  3.5633e-01, -3.4073e-01,  1.0994e-01,\n",
       "          3.2010e-01,  3.9570e-02, -3.1380e-02, -2.3001e-02, -2.7556e+00,\n",
       "          4.7550e-01, -3.8089e-01, -1.0403e-02, -3.6889e-01, -2.7151e-01,\n",
       "          7.7844e-02,  4.7097e-01,  1.5503e-01,  1.3748e-01, -1.1831e-01,\n",
       "          5.0020e-02,  1.0278e-01,  2.6593e-01,  4.7978e-02,  4.4148e-01,\n",
       "          1.0068e-01, -3.2156e-01, -5.3439e-02,  2.3204e-01, -1.2199e-01,\n",
       "          2.3683e-01,  3.3221e-01, -1.8750e-02, -2.1213e-01, -3.7402e-01,\n",
       "         -1.2803e-01,  3.7411e-01, -2.3274e-01,  4.4616e-02, -3.9568e-01,\n",
       "         -5.5456e-02, -2.7940e-01, -3.2899e+00,  4.8034e-01,  3.9378e-01,\n",
       "         -3.6177e-01, -7.2770e-01, -1.0333e-01,  7.7551e-02, -2.7465e-02,\n",
       "         -1.5271e-01,  1.3643e-01, -2.2773e-01, -2.1545e-02, -1.9036e-04,\n",
       "         -1.9149e-01, -4.3678e-02, -3.0694e-01, -1.6462e-01,  3.7942e-01,\n",
       "          3.1193e-01, -2.2982e-01,  1.7626e-01, -1.2581e-02, -1.4276e-01,\n",
       "         -1.7223e-01,  1.3962e-01,  3.6115e-01, -8.0917e-04, -3.3694e-02,\n",
       "         -3.3829e-01,  2.0888e-01,  6.8638e-01,  3.6330e-01,  3.4118e-01,\n",
       "         -1.0618e-01,  4.4305e-01,  2.4793e-01,  2.4221e-01, -5.2548e-02,\n",
       "         -2.0648e-01,  6.4978e-01,  1.8898e-02, -2.0206e-02,  4.2801e-01,\n",
       "          3.6390e-01,  2.8540e-01, -3.5374e-01,  1.1779e-01,  9.1421e-02,\n",
       "         -2.5159e-01,  1.9505e-01,  3.4613e-01,  2.4373e-01,  2.0833e-01,\n",
       "         -6.9684e-01, -3.7781e-02, -2.6877e-01,  3.8857e-01,  1.7077e-01,\n",
       "          3.7161e-02,  3.3294e-02, -2.8830e-01,  3.6203e-02, -1.3177e-01,\n",
       "          4.2426e+00, -6.5609e-02, -3.8311e-01,  2.6079e-01,  4.4054e-01,\n",
       "         -2.4274e-01,  6.7816e-01, -1.8640e-01,  2.7957e-01, -4.6941e-02,\n",
       "          4.9484e-02,  6.0769e-02,  1.2539e-01, -8.0371e-02, -1.7930e-01,\n",
       "          5.1635e-01,  1.1406e-01, -1.4921e-01, -1.2852e-01,  1.6883e-01,\n",
       "          5.8500e-02,  5.5615e-02,  5.4367e-02, -2.1416e-02, -1.4820e+00,\n",
       "          1.0029e-01,  1.0522e-01, -1.5832e-01,  3.7358e-01, -1.8581e-01,\n",
       "          1.8614e-01,  1.2328e-01, -1.9044e-01, -4.0732e-02,  5.6514e-02,\n",
       "          1.0237e-01,  4.3967e-01,  3.4417e-01,  1.0596e-01, -1.1586e-01,\n",
       "          3.0616e-01,  4.1759e-01, -1.5467e-01,  4.2579e-01,  8.2863e-02,\n",
       "          2.2320e-01, -3.3161e-01, -8.4889e-02, -1.6451e-01, -2.9910e-01,\n",
       "         -2.4058e-01, -9.7154e-02,  3.0165e-01, -3.7962e-01,  5.1222e-02,\n",
       "         -1.3042e-01, -2.7926e-01, -5.7349e-02,  1.0263e-01, -2.6383e-01,\n",
       "          4.9546e-02,  6.6063e-01, -1.5946e-02,  2.1820e-01, -6.7036e-03,\n",
       "          1.5619e-02,  5.0714e-02, -9.1638e-02, -4.3368e+00,  1.0257e-01,\n",
       "          2.4046e-01,  2.0304e-01,  5.2267e-01,  6.9457e-02, -1.5208e-01,\n",
       "          1.7361e-01, -9.4615e-02, -5.4637e-01,  1.9370e-01,  3.9269e-01,\n",
       "         -1.6798e-01,  2.1988e-01, -4.4461e-01,  2.5130e-01,  1.5310e-01,\n",
       "          4.4021e-02,  8.6622e-02, -1.0350e-01, -6.2705e-03,  5.0736e-01,\n",
       "         -3.8504e-01,  4.5571e-02,  9.6540e-02,  3.0507e-01, -3.7656e-01,\n",
       "         -4.8082e-02,  5.4115e-01, -6.5671e-02,  7.0245e-02, -2.6350e-02,\n",
       "          2.2261e-01,  7.0113e-02, -5.3680e-01, -1.7586e+00, -8.6069e-02,\n",
       "          1.6613e-01, -5.8941e-01,  3.9082e-01, -1.8872e-01,  3.2482e-01,\n",
       "         -1.8042e-01, -6.9501e-01,  1.8123e-01, -2.2414e-02, -1.1655e-01,\n",
       "          4.3075e-02,  1.5083e-01,  2.0445e-01, -4.8591e-01,  2.4382e-01,\n",
       "         -1.1325e-01, -1.2127e-01,  9.9167e-03,  1.4776e-01, -2.0037e-02,\n",
       "          3.4553e-01,  1.4592e-01, -2.0293e-03,  3.4223e-01, -2.9330e-01,\n",
       "         -1.8467e-01, -2.1310e-01, -3.1566e-01, -2.2653e-01, -4.1877e-01,\n",
       "          1.9840e-01,  3.7080e-01,  6.8882e-02, -3.8919e-01,  2.6263e-01,\n",
       "          1.5371e-01,  5.6646e-01,  6.3491e-02,  3.7417e-01,  2.7244e-01,\n",
       "          2.5486e-01,  5.8406e-01,  5.8223e-01,  2.5799e-01, -3.1895e-02,\n",
       "         -1.6285e-01, -4.2109e-01,  8.8467e-02,  3.2106e-01, -4.1638e-01,\n",
       "          1.2229e+00, -5.8135e-01,  1.1192e-01, -1.5256e-01,  1.0361e-01,\n",
       "         -1.2431e-01,  1.3822e-01, -1.1372e-01,  4.9710e-01,  1.9996e-01,\n",
       "          3.5299e-02,  5.3074e-01, -1.7758e-01, -4.5200e-01, -3.7568e-02,\n",
       "         -4.9113e-01,  3.8700e-01,  3.2924e-01,  3.5486e-02,  5.9623e-02,\n",
       "         -2.7264e-01, -9.8824e-01, -2.7904e-01,  3.8662e-01,  5.0260e-02,\n",
       "         -7.9070e-02,  2.8147e-01, -3.5749e-01, -3.0785e-02, -1.4496e-01,\n",
       "          9.7805e-02,  2.2930e-01, -4.4995e-01,  1.9500e-01,  2.4927e-01,\n",
       "          3.0885e-02,  1.0132e-02,  7.1548e-02, -1.6299e-01,  3.5818e-01,\n",
       "          1.8167e-01, -1.1285e-01,  4.4329e-02,  1.7787e-02,  3.2266e-02,\n",
       "         -6.2577e-01,  1.5352e-01, -3.2760e-01, -4.6940e-01, -4.0676e-01,\n",
       "         -3.3379e-01,  2.9465e-01, -2.5413e-01,  7.0845e-02, -7.6027e-01,\n",
       "          2.6524e-01, -2.6257e-01,  5.6491e-01, -9.1524e-03,  1.3640e-01,\n",
       "          3.2539e-01,  1.5922e-01,  5.5800e-01, -8.3918e-02,  3.5351e-01,\n",
       "          3.1714e-01, -1.0540e-01,  5.0520e-02,  1.0876e-02,  4.5797e-01,\n",
       "         -3.3590e-01,  1.8235e-01,  3.5544e-01,  1.5331e-01,  4.6425e-03,\n",
       "         -4.5927e-01, -2.5609e-01, -1.2196e-01,  1.9411e-01, -8.1818e-02,\n",
       "         -1.6957e-01, -4.7461e-01, -3.9288e-02, -2.8530e-01, -2.0318e-01,\n",
       "         -8.8294e-02, -9.6994e-02,  1.7446e-01,  1.0274e-01,  3.7550e-02,\n",
       "         -4.6575e-01,  3.3493e-01,  2.5060e-02,  5.0201e-01, -4.3851e-01,\n",
       "          1.2111e-01,  2.9676e-01,  6.1099e-01, -1.3660e-01, -3.3689e-01,\n",
       "          1.9566e-01, -1.1645e-01,  1.2058e-01,  3.6611e-01, -2.8622e-01,\n",
       "         -4.6788e-01,  1.8664e-01,  5.6509e-02, -4.3529e-01,  3.9721e-01,\n",
       "         -1.5340e+00,  1.2604e-01,  6.7640e-02, -3.9702e-01,  5.3916e-01,\n",
       "          1.8636e-01, -3.7509e-01,  6.3011e-01,  3.4937e-01,  3.6117e-03,\n",
       "         -1.1656e-02,  2.0342e-01, -1.0555e-01,  1.0513e-01, -1.0994e-01,\n",
       "         -2.1745e-03,  4.8318e-01, -1.9176e-01,  4.4097e-02, -5.3394e-02,\n",
       "         -1.5231e-01,  3.4701e-01,  7.2896e-02, -3.1473e-01, -1.1973e-01,\n",
       "          2.5812e-01,  1.1971e-01,  4.6424e-01, -3.3529e-01, -9.6727e-02,\n",
       "          4.1950e-01, -2.6121e-01, -4.8247e-01, -1.9466e-01,  4.4419e-02,\n",
       "         -1.9492e-01, -9.0341e-02,  3.2293e-01,  9.0145e-02,  1.6904e-01,\n",
       "          1.1435e-01,  6.4890e-02,  1.6499e-01, -2.8675e-01,  1.4943e-01,\n",
       "          9.0741e-02, -3.4499e-01, -4.4406e-02,  2.0878e-01, -3.4212e-01,\n",
       "         -5.6393e-01,  5.2120e-02, -2.6423e-01, -3.5125e-01,  2.8071e-01,\n",
       "          6.9792e-02, -1.3034e-01, -2.8973e-01, -6.1615e-01,  1.1026e-01,\n",
       "          5.8751e-02, -7.6137e-02, -1.3013e-01,  2.6355e-01, -7.2323e-01,\n",
       "         -3.5802e-01,  3.4616e-01, -7.5927e-02,  3.2541e-01, -3.1318e-03,\n",
       "          1.7594e-01, -1.1980e-01,  6.6695e-02,  1.4339e-01, -2.6372e-01,\n",
       "          2.8697e-01,  6.2493e-02,  1.5200e-02,  1.2126e-01, -2.3792e-01,\n",
       "         -4.7075e-01, -4.2247e-02, -1.8681e-02,  1.0742e-01, -9.1367e-02,\n",
       "          5.7936e-01,  4.8788e-01, -2.3291e-02, -3.6559e-01,  2.4100e-01,\n",
       "         -3.2220e-01,  1.4054e-02,  2.2441e-01,  4.0189e-02, -2.6893e-01,\n",
       "         -3.4323e-01,  3.0691e-01,  1.1039e-01, -2.0364e-01,  3.5700e-01,\n",
       "          7.6891e-02,  4.0365e-01,  3.5670e-01, -1.4020e-01,  1.6451e-01,\n",
       "          5.4923e-02,  3.9413e-01,  3.2931e-01,  2.2695e-03, -1.6567e-01,\n",
       "         -2.3411e-01,  3.9799e-02, -2.0689e-01, -6.1466e-02,  4.5320e-02,\n",
       "         -6.0107e-02,  3.9252e-01, -4.2025e-02,  2.4671e+00,  5.9533e-01,\n",
       "          4.3833e-02, -1.1311e-01,  6.1881e-02,  1.6363e-01,  1.5949e-01,\n",
       "         -2.1544e-01, -2.7266e-01, -1.8765e-02,  2.3656e-01,  2.2283e-01,\n",
       "          3.6299e-01,  3.4400e-02,  7.8310e-01,  3.9824e-01, -1.7747e-01,\n",
       "         -1.0231e-02, -7.3003e-01,  1.8450e-01, -4.9052e-02,  1.7828e-01,\n",
       "          3.4240e-01, -5.1175e-02,  8.2784e-02,  3.8145e-01,  1.7230e-01,\n",
       "         -5.2151e-02, -2.1753e-01, -1.9537e-01, -4.5584e-01, -4.3574e-01,\n",
       "          6.0960e-02, -3.5581e-01, -3.7799e-01,  3.4320e-01,  3.2095e-01,\n",
       "         -3.2994e-01,  2.4694e-01,  2.3691e-02, -9.6979e-02, -1.5378e-01,\n",
       "          6.5905e-01,  3.2034e-01,  2.7468e-01,  5.1482e-01, -1.2401e-01,\n",
       "         -8.1927e-02,  4.0822e-01, -9.8134e-02, -9.1149e-02, -6.7248e-02,\n",
       "         -5.4695e-01,  5.7288e-02, -6.9500e-02, -3.5697e-01,  6.0696e-02,\n",
       "         -6.5336e-02, -1.6879e-01,  9.3601e-03, -1.0201e-01, -6.3897e-02,\n",
       "          3.9621e-01, -1.3471e-01,  1.4396e-01,  2.6462e-01, -1.3375e-01,\n",
       "          5.5976e-03,  3.4723e-01, -5.9051e-02,  1.6861e-01,  1.4938e-01,\n",
       "          2.0632e-01, -9.2595e-02,  2.7472e-01,  9.3809e-02,  5.5253e-02,\n",
       "         -6.5447e-03, -6.3001e-01, -3.3820e+00,  2.3470e-01,  4.0595e-01,\n",
       "          4.5948e-02, -1.7026e-01,  1.8406e-01,  3.1701e-01,  9.0024e-02,\n",
       "          7.0709e-02, -4.1563e-02,  1.7077e-01,  1.0976e-01, -6.8388e-02,\n",
       "          2.1580e-01, -4.1912e-02,  2.5313e-01,  2.0944e-01, -6.1528e-01,\n",
       "         -2.1359e-01, -4.1064e-01, -8.3710e-02, -1.7674e-01, -1.4181e-01,\n",
       "         -3.0793e-01, -4.0789e-02,  4.9168e-01,  2.8411e-01, -1.5762e-01,\n",
       "         -5.0076e-01,  2.3118e-01, -1.2897e-01,  2.4419e-01,  9.3798e-02,\n",
       "         -1.2297e-02, -9.0225e-02, -6.0647e-02,  1.4078e-01, -1.2516e-01,\n",
       "          3.0963e-01,  9.9271e-02,  2.4340e-01,  6.7375e-01, -1.6642e-01,\n",
       "         -1.6373e-01, -1.7776e-01, -2.0297e-01,  4.4338e-01,  6.3007e-02,\n",
       "          5.3656e-01, -1.2315e-01,  1.0672e-01, -9.5986e-02,  9.1745e-02,\n",
       "         -6.9517e-02, -1.2986e-01, -6.1014e-02, -3.9922e-01, -8.1747e-02,\n",
       "         -4.2779e-02,  4.6613e-02,  2.8660e-01, -2.6962e-03, -9.0070e-02,\n",
       "          4.2988e-02,  4.0699e-01, -4.0038e-01,  1.0890e-01, -2.7165e-01,\n",
       "         -5.6262e-02, -1.0275e-01,  1.3369e-02, -3.0308e-01,  2.2683e-01,\n",
       "         -2.2953e-01, -7.0040e-02,  3.1226e-02,  2.7516e-01,  7.2677e-02,\n",
       "         -4.1981e-01, -1.2059e-01,  2.8639e-02,  1.6866e-01, -1.5574e-02,\n",
       "         -2.3324e-01,  2.6682e-02, -8.8357e+00, -1.9912e-01, -2.1892e-01,\n",
       "         -5.7330e-02,  7.8102e-02, -1.0763e-01, -4.9417e-03, -2.0768e-01,\n",
       "          1.7425e-02, -3.5526e-01,  1.4145e-01, -2.6619e-01, -2.6477e-01,\n",
       "         -1.1081e-01,  2.2660e-01,  3.3454e-01], grad_fn=<SelectBackward0>),\n",
       " tensor([-3.0216e-01,  3.1903e-01, -6.1283e-01,  1.5407e-01, -3.5226e-01,\n",
       "         -4.2829e-01,  1.5390e-01,  2.8611e-01, -1.9028e-01, -1.7794e-01,\n",
       "          6.2591e-02,  2.2631e-01, -2.7719e-01,  4.4759e-01,  8.0433e-04,\n",
       "          1.1076e-01, -9.8800e-02,  2.7483e-01,  1.9675e-02, -1.0155e-01,\n",
       "          1.9854e-01,  3.4159e-02, -7.7434e-02,  1.0788e-01, -1.1583e-02,\n",
       "         -1.2412e-02, -1.8740e-01, -4.4906e-01,  9.0015e-02, -5.2500e-02,\n",
       "         -1.2867e-01,  1.1498e-02, -4.2578e-01, -3.0835e-02, -1.1381e-01,\n",
       "         -6.6668e-02,  8.3218e-02,  3.4710e-01, -2.2852e-01, -2.0305e-01,\n",
       "         -1.2648e-01,  2.4238e-01, -1.7087e-01,  1.6629e-02,  4.3587e-02,\n",
       "          1.4640e-02, -1.9185e+00,  1.5873e-01,  5.6473e-02, -5.6386e-01,\n",
       "         -5.0768e-02,  1.6419e-01,  3.1613e-01, -7.6420e-02,  2.7087e-01,\n",
       "          2.8472e-01, -3.1631e-05,  6.9438e-01, -2.7928e-01,  7.0762e-02,\n",
       "          2.9739e-02,  2.1687e-01, -4.5777e-02,  2.3344e-02,  2.2826e-01,\n",
       "          2.1865e-01,  9.3328e-02,  7.7339e-01, -4.1245e-01,  4.0291e-01,\n",
       "         -4.1928e-01, -3.6181e-01,  4.1378e-01, -1.6336e-01,  1.0317e-01,\n",
       "         -4.4067e-01, -2.7876e-01,  6.5294e-02, -1.9365e-01, -1.5477e-01,\n",
       "          1.6795e-02,  1.6201e-01,  8.3718e-02, -9.6085e-02,  3.2413e-02,\n",
       "          4.0302e-01,  3.8902e-03, -3.3934e-01, -1.4547e-01,  4.2389e-01,\n",
       "          1.8596e-01,  2.3212e-01,  3.5853e-01,  3.9517e-01,  4.7277e-02,\n",
       "         -2.0624e-01,  5.0785e-01,  4.7412e-02,  1.3625e-01, -2.0703e-01,\n",
       "          5.8801e-02, -3.7876e-01,  3.5633e-01, -3.4073e-01,  1.0994e-01,\n",
       "          3.2010e-01,  3.9570e-02, -3.1380e-02, -2.3001e-02, -2.7556e+00,\n",
       "          4.7550e-01, -3.8089e-01, -1.0403e-02, -3.6889e-01, -2.7151e-01,\n",
       "          7.7844e-02,  4.7097e-01,  1.5503e-01,  1.3748e-01, -1.1831e-01,\n",
       "          5.0020e-02,  1.0278e-01,  2.6593e-01,  4.7978e-02,  4.4148e-01,\n",
       "          1.0068e-01, -3.2156e-01, -5.3439e-02,  2.3204e-01, -1.2199e-01,\n",
       "          2.3683e-01,  3.3221e-01, -1.8750e-02, -2.1213e-01, -3.7402e-01,\n",
       "         -1.2803e-01,  3.7411e-01, -2.3274e-01,  4.4616e-02, -3.9568e-01,\n",
       "         -5.5456e-02, -2.7940e-01, -3.2899e+00,  4.8034e-01,  3.9378e-01,\n",
       "         -3.6177e-01, -7.2770e-01, -1.0333e-01,  7.7551e-02, -2.7465e-02,\n",
       "         -1.5271e-01,  1.3643e-01, -2.2773e-01, -2.1545e-02, -1.9036e-04,\n",
       "         -1.9149e-01, -4.3678e-02, -3.0694e-01, -1.6462e-01,  3.7942e-01,\n",
       "          3.1193e-01, -2.2982e-01,  1.7626e-01, -1.2581e-02, -1.4276e-01,\n",
       "         -1.7223e-01,  1.3962e-01,  3.6115e-01, -8.0917e-04, -3.3694e-02,\n",
       "         -3.3829e-01,  2.0888e-01,  6.8638e-01,  3.6330e-01,  3.4118e-01,\n",
       "         -1.0618e-01,  4.4305e-01,  2.4793e-01,  2.4221e-01, -5.2548e-02,\n",
       "         -2.0648e-01,  6.4978e-01,  1.8898e-02, -2.0206e-02,  4.2801e-01,\n",
       "          3.6390e-01,  2.8540e-01, -3.5374e-01,  1.1779e-01,  9.1421e-02,\n",
       "         -2.5159e-01,  1.9505e-01,  3.4613e-01,  2.4373e-01,  2.0833e-01,\n",
       "         -6.9684e-01, -3.7781e-02, -2.6877e-01,  3.8857e-01,  1.7077e-01,\n",
       "          3.7161e-02,  3.3294e-02, -2.8830e-01,  3.6203e-02, -1.3177e-01,\n",
       "          4.2426e+00, -6.5609e-02, -3.8311e-01,  2.6079e-01,  4.4054e-01,\n",
       "         -2.4274e-01,  6.7816e-01, -1.8640e-01,  2.7957e-01, -4.6941e-02,\n",
       "          4.9484e-02,  6.0769e-02,  1.2539e-01, -8.0371e-02, -1.7930e-01,\n",
       "          5.1635e-01,  1.1406e-01, -1.4921e-01, -1.2852e-01,  1.6883e-01,\n",
       "          5.8500e-02,  5.5615e-02,  5.4367e-02, -2.1416e-02, -1.4820e+00,\n",
       "          1.0029e-01,  1.0522e-01, -1.5832e-01,  3.7358e-01, -1.8581e-01,\n",
       "          1.8614e-01,  1.2328e-01, -1.9044e-01, -4.0732e-02,  5.6514e-02,\n",
       "          1.0237e-01,  4.3967e-01,  3.4417e-01,  1.0596e-01, -1.1586e-01,\n",
       "          3.0616e-01,  4.1759e-01, -1.5467e-01,  4.2579e-01,  8.2863e-02,\n",
       "          2.2320e-01, -3.3161e-01, -8.4889e-02, -1.6451e-01, -2.9910e-01,\n",
       "         -2.4058e-01, -9.7154e-02,  3.0165e-01, -3.7962e-01,  5.1222e-02,\n",
       "         -1.3042e-01, -2.7926e-01, -5.7349e-02,  1.0263e-01, -2.6383e-01,\n",
       "          4.9546e-02,  6.6063e-01, -1.5946e-02,  2.1820e-01, -6.7036e-03,\n",
       "          1.5619e-02,  5.0714e-02, -9.1638e-02, -4.3368e+00,  1.0257e-01,\n",
       "          2.4046e-01,  2.0304e-01,  5.2267e-01,  6.9457e-02, -1.5208e-01,\n",
       "          1.7361e-01, -9.4615e-02, -5.4637e-01,  1.9370e-01,  3.9269e-01,\n",
       "         -1.6798e-01,  2.1988e-01, -4.4461e-01,  2.5130e-01,  1.5310e-01,\n",
       "          4.4021e-02,  8.6622e-02, -1.0350e-01, -6.2705e-03,  5.0736e-01,\n",
       "         -3.8504e-01,  4.5571e-02,  9.6540e-02,  3.0507e-01, -3.7656e-01,\n",
       "         -4.8082e-02,  5.4115e-01, -6.5671e-02,  7.0245e-02, -2.6350e-02,\n",
       "          2.2261e-01,  7.0113e-02, -5.3680e-01, -1.7586e+00, -8.6069e-02,\n",
       "          1.6613e-01, -5.8941e-01,  3.9082e-01, -1.8872e-01,  3.2482e-01,\n",
       "         -1.8042e-01, -6.9501e-01,  1.8123e-01, -2.2414e-02, -1.1655e-01,\n",
       "          4.3075e-02,  1.5083e-01,  2.0445e-01, -4.8591e-01,  2.4382e-01,\n",
       "         -1.1325e-01, -1.2127e-01,  9.9167e-03,  1.4776e-01, -2.0037e-02,\n",
       "          3.4553e-01,  1.4592e-01, -2.0293e-03,  3.4223e-01, -2.9330e-01,\n",
       "         -1.8467e-01, -2.1310e-01, -3.1566e-01, -2.2653e-01, -4.1877e-01,\n",
       "          1.9840e-01,  3.7080e-01,  6.8882e-02, -3.8919e-01,  2.6263e-01,\n",
       "          1.5371e-01,  5.6646e-01,  6.3491e-02,  3.7417e-01,  2.7244e-01,\n",
       "          2.5486e-01,  5.8406e-01,  5.8223e-01,  2.5799e-01, -3.1895e-02,\n",
       "         -1.6285e-01, -4.2109e-01,  8.8467e-02,  3.2106e-01, -4.1638e-01,\n",
       "          1.2229e+00, -5.8135e-01,  1.1192e-01, -1.5256e-01,  1.0361e-01,\n",
       "         -1.2431e-01,  1.3822e-01, -1.1372e-01,  4.9710e-01,  1.9996e-01,\n",
       "          3.5299e-02,  5.3074e-01, -1.7758e-01, -4.5200e-01, -3.7568e-02,\n",
       "         -4.9113e-01,  3.8700e-01,  3.2924e-01,  3.5486e-02,  5.9623e-02,\n",
       "         -2.7264e-01, -9.8824e-01, -2.7904e-01,  3.8662e-01,  5.0260e-02,\n",
       "         -7.9070e-02,  2.8147e-01, -3.5749e-01, -3.0785e-02, -1.4496e-01,\n",
       "          9.7805e-02,  2.2930e-01, -4.4995e-01,  1.9500e-01,  2.4927e-01,\n",
       "          3.0885e-02,  1.0132e-02,  7.1548e-02, -1.6299e-01,  3.5818e-01,\n",
       "          1.8167e-01, -1.1285e-01,  4.4329e-02,  1.7787e-02,  3.2266e-02,\n",
       "         -6.2577e-01,  1.5352e-01, -3.2760e-01, -4.6940e-01, -4.0676e-01,\n",
       "         -3.3379e-01,  2.9465e-01, -2.5413e-01,  7.0845e-02, -7.6027e-01,\n",
       "          2.6524e-01, -2.6257e-01,  5.6491e-01, -9.1524e-03,  1.3640e-01,\n",
       "          3.2539e-01,  1.5922e-01,  5.5800e-01, -8.3918e-02,  3.5351e-01,\n",
       "          3.1714e-01, -1.0540e-01,  5.0520e-02,  1.0876e-02,  4.5797e-01,\n",
       "         -3.3590e-01,  1.8235e-01,  3.5544e-01,  1.5331e-01,  4.6425e-03,\n",
       "         -4.5927e-01, -2.5609e-01, -1.2196e-01,  1.9411e-01, -8.1818e-02,\n",
       "         -1.6957e-01, -4.7461e-01, -3.9288e-02, -2.8530e-01, -2.0318e-01,\n",
       "         -8.8294e-02, -9.6994e-02,  1.7446e-01,  1.0274e-01,  3.7550e-02,\n",
       "         -4.6575e-01,  3.3493e-01,  2.5060e-02,  5.0201e-01, -4.3851e-01,\n",
       "          1.2111e-01,  2.9676e-01,  6.1099e-01, -1.3660e-01, -3.3689e-01,\n",
       "          1.9566e-01, -1.1645e-01,  1.2058e-01,  3.6611e-01, -2.8622e-01,\n",
       "         -4.6788e-01,  1.8664e-01,  5.6509e-02, -4.3529e-01,  3.9721e-01,\n",
       "         -1.5340e+00,  1.2604e-01,  6.7640e-02, -3.9702e-01,  5.3916e-01,\n",
       "          1.8636e-01, -3.7509e-01,  6.3011e-01,  3.4937e-01,  3.6117e-03,\n",
       "         -1.1656e-02,  2.0342e-01, -1.0555e-01,  1.0513e-01, -1.0994e-01,\n",
       "         -2.1745e-03,  4.8318e-01, -1.9176e-01,  4.4097e-02, -5.3394e-02,\n",
       "         -1.5231e-01,  3.4701e-01,  7.2896e-02, -3.1473e-01, -1.1973e-01,\n",
       "          2.5812e-01,  1.1971e-01,  4.6424e-01, -3.3529e-01, -9.6727e-02,\n",
       "          4.1950e-01, -2.6121e-01, -4.8247e-01, -1.9466e-01,  4.4419e-02,\n",
       "         -1.9492e-01, -9.0341e-02,  3.2293e-01,  9.0145e-02,  1.6904e-01,\n",
       "          1.1435e-01,  6.4890e-02,  1.6499e-01, -2.8675e-01,  1.4943e-01,\n",
       "          9.0741e-02, -3.4499e-01, -4.4406e-02,  2.0878e-01, -3.4212e-01,\n",
       "         -5.6393e-01,  5.2120e-02, -2.6423e-01, -3.5125e-01,  2.8071e-01,\n",
       "          6.9792e-02, -1.3034e-01, -2.8973e-01, -6.1615e-01,  1.1026e-01,\n",
       "          5.8751e-02, -7.6137e-02, -1.3013e-01,  2.6355e-01, -7.2323e-01,\n",
       "         -3.5802e-01,  3.4616e-01, -7.5927e-02,  3.2541e-01, -3.1318e-03,\n",
       "          1.7594e-01, -1.1980e-01,  6.6695e-02,  1.4339e-01, -2.6372e-01,\n",
       "          2.8697e-01,  6.2493e-02,  1.5200e-02,  1.2126e-01, -2.3792e-01,\n",
       "         -4.7075e-01, -4.2247e-02, -1.8681e-02,  1.0742e-01, -9.1367e-02,\n",
       "          5.7936e-01,  4.8788e-01, -2.3291e-02, -3.6559e-01,  2.4100e-01,\n",
       "         -3.2220e-01,  1.4054e-02,  2.2441e-01,  4.0189e-02, -2.6893e-01,\n",
       "         -3.4323e-01,  3.0691e-01,  1.1039e-01, -2.0364e-01,  3.5700e-01,\n",
       "          7.6891e-02,  4.0365e-01,  3.5670e-01, -1.4020e-01,  1.6451e-01,\n",
       "          5.4923e-02,  3.9413e-01,  3.2931e-01,  2.2695e-03, -1.6567e-01,\n",
       "         -2.3411e-01,  3.9799e-02, -2.0689e-01, -6.1466e-02,  4.5320e-02,\n",
       "         -6.0107e-02,  3.9252e-01, -4.2025e-02,  2.4671e+00,  5.9533e-01,\n",
       "          4.3833e-02, -1.1311e-01,  6.1881e-02,  1.6363e-01,  1.5949e-01,\n",
       "         -2.1544e-01, -2.7266e-01, -1.8765e-02,  2.3656e-01,  2.2283e-01,\n",
       "          3.6299e-01,  3.4400e-02,  7.8310e-01,  3.9824e-01, -1.7747e-01,\n",
       "         -1.0231e-02, -7.3003e-01,  1.8450e-01, -4.9052e-02,  1.7828e-01,\n",
       "          3.4240e-01, -5.1175e-02,  8.2784e-02,  3.8145e-01,  1.7230e-01,\n",
       "         -5.2151e-02, -2.1753e-01, -1.9537e-01, -4.5584e-01, -4.3574e-01,\n",
       "          6.0960e-02, -3.5581e-01, -3.7799e-01,  3.4320e-01,  3.2095e-01,\n",
       "         -3.2994e-01,  2.4694e-01,  2.3691e-02, -9.6979e-02, -1.5378e-01,\n",
       "          6.5905e-01,  3.2034e-01,  2.7468e-01,  5.1482e-01, -1.2401e-01,\n",
       "         -8.1927e-02,  4.0822e-01, -9.8134e-02, -9.1149e-02, -6.7248e-02,\n",
       "         -5.4695e-01,  5.7288e-02, -6.9500e-02, -3.5697e-01,  6.0696e-02,\n",
       "         -6.5336e-02, -1.6879e-01,  9.3601e-03, -1.0201e-01, -6.3897e-02,\n",
       "          3.9621e-01, -1.3471e-01,  1.4396e-01,  2.6462e-01, -1.3375e-01,\n",
       "          5.5976e-03,  3.4723e-01, -5.9051e-02,  1.6861e-01,  1.4938e-01,\n",
       "          2.0632e-01, -9.2595e-02,  2.7472e-01,  9.3809e-02,  5.5253e-02,\n",
       "         -6.5447e-03, -6.3001e-01, -3.3820e+00,  2.3470e-01,  4.0595e-01,\n",
       "          4.5948e-02, -1.7026e-01,  1.8406e-01,  3.1701e-01,  9.0024e-02,\n",
       "          7.0709e-02, -4.1563e-02,  1.7077e-01,  1.0976e-01, -6.8388e-02,\n",
       "          2.1580e-01, -4.1912e-02,  2.5313e-01,  2.0944e-01, -6.1528e-01,\n",
       "         -2.1359e-01, -4.1064e-01, -8.3710e-02, -1.7674e-01, -1.4181e-01,\n",
       "         -3.0793e-01, -4.0789e-02,  4.9168e-01,  2.8411e-01, -1.5762e-01,\n",
       "         -5.0076e-01,  2.3118e-01, -1.2897e-01,  2.4419e-01,  9.3798e-02,\n",
       "         -1.2297e-02, -9.0225e-02, -6.0647e-02,  1.4078e-01, -1.2516e-01,\n",
       "          3.0963e-01,  9.9271e-02,  2.4340e-01,  6.7375e-01, -1.6642e-01,\n",
       "         -1.6373e-01, -1.7776e-01, -2.0297e-01,  4.4338e-01,  6.3007e-02,\n",
       "          5.3656e-01, -1.2315e-01,  1.0672e-01, -9.5986e-02,  9.1745e-02,\n",
       "         -6.9517e-02, -1.2986e-01, -6.1014e-02, -3.9922e-01, -8.1747e-02,\n",
       "         -4.2779e-02,  4.6613e-02,  2.8660e-01, -2.6962e-03, -9.0070e-02,\n",
       "          4.2988e-02,  4.0699e-01, -4.0038e-01,  1.0890e-01, -2.7165e-01,\n",
       "         -5.6262e-02, -1.0275e-01,  1.3369e-02, -3.0308e-01,  2.2683e-01,\n",
       "         -2.2953e-01, -7.0040e-02,  3.1226e-02,  2.7516e-01,  7.2677e-02,\n",
       "         -4.1981e-01, -1.2059e-01,  2.8639e-02,  1.6866e-01, -1.5574e-02,\n",
       "         -2.3324e-01,  2.6682e-02, -8.8357e+00, -1.9912e-01, -2.1892e-01,\n",
       "         -5.7330e-02,  7.8102e-02, -1.0763e-01, -4.9417e-03, -2.0768e-01,\n",
       "          1.7425e-02, -3.5526e-01,  1.4145e-01, -2.6619e-01, -2.6477e-01,\n",
       "         -1.1081e-01,  2.2660e-01,  3.3454e-01], grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_embedding(\"you slap\")[0], get_word_embedding(\"you slap\")[:][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "def get_length(embedding_1d):\n",
    "    sum = 0\n",
    "    for i in embedding_1d:\n",
    "        sum+=(i**2)\n",
    "    return math.sqrt(sum)\n",
    "def normalise_embedding(embedding_1d):\n",
    "    length = get_length(embedding_1d)\n",
    "    for i in range(len(embedding_1d)):\n",
    "        embedding_1d[i] /= length\n",
    "def get_normalise_embedding(embedding_1d):\n",
    "    if type(embedding_1d) is torch.Tensor:\n",
    "        temp_embedding_1d = (embedding_1d.detach().numpy()).copy()\n",
    "    else:\n",
    "        temp_embedding_1d = embedding_1d.copy()\n",
    "    length = get_length(temp_embedding_1d)\n",
    "    for i in range(len(temp_embedding_1d)):\n",
    "        temp_embedding_1d[i] /= length\n",
    "    return temp_embedding_1d\n",
    "\n",
    "\n",
    "def cosine_sim(embedding_1, embedding_2):\n",
    "    embedding_1 = get_normalise_embedding(embedding_1)\n",
    "    embedding_2 = get_normalise_embedding(embedding_2)\n",
    "    sim_sum = 0\n",
    "    for e_1, e_2 in zip(embedding_1, embedding_2):\n",
    "        sim_sum += (e_1*e_2)\n",
    "    return sim_sum\n",
    "def norm_ed_cosine_sim(embedding_1, embedding_2):\n",
    "    sim_sum = 0\n",
    "    for e_1, e_2 in zip(embedding_1, embedding_2):\n",
    "        sim_sum += (e_1*e_2)\n",
    "    return sim_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999959719127\n"
     ]
    }
   ],
   "source": [
    "aa = get_normalise_embedding(get_cls_embedding(\"hi there\"))\n",
    "print(get_length(aa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9716051474177263"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(get_cls_embedding(\"i love you\"), get_cls_embedding(\" i like you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9689928427400734"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(get_cls_embedding(\"i love you\"), get_cls_embedding(\" i hate you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8936620383051874"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(get_cls_embedding(\"i love you\"), get_cls_embedding(\" i am dying and would like to be saved so i can kill you\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9317314271919477"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(get_cls_embedding(\"employee benefit\"), get_cls_embedding(\"tax relief\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8601194937180958"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim(get_cls_embedding(\"employee benefit\"), get_cls_embedding(\"salary bonus\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 different ones lol, but no \"s\" is what normally use bah, the \"s\" one use for within the naively avg and all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_embedding(text):\n",
    "    encoded_text_with_input_ids_and_attention_masks_etc = tokenizer.encode_plus(text, return_tensors=\"pt\")\n",
    "    model_output =  model(**encoded_text_with_input_ids_and_attention_masks_etc)\n",
    "    return model_output[0][0]\n",
    "\n",
    "def get_word_embeddings(sentence):\n",
    "    t_encoded_input = tokenizer(sentence, return_tensors='pt'\n",
    "                             , padding=True, truncation=True, add_special_tokens=True ## idk if need??? got huge diff?\n",
    "                             )\n",
    "    t_output = model(**t_encoded_input)    \n",
    "    return t_output.last_hidden_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### below is like other laptop try attempts on stuff like avg embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def get_word_embeddings(sentence):\n",
    "    t_encoded_input = tokenizer(sentence, return_tensors='pt'\n",
    "                             , padding=True, truncation=True, add_special_tokens=True ## idk if need??? got huge diff?\n",
    "                             )\n",
    "\n",
    "    #print(tokenizer.tokenize(sentence))\n",
    "\n",
    "    #print(\"input_id:\", t_encoded_input[\"input_ids\"])\n",
    "    #print(\"attention_mask:\", t_encoded_input[\"attention_mask\"])\n",
    "\n",
    "    t_output = model(**t_encoded_input)\n",
    "    #t_output.last_hidden_state.shape, t_output.last_hidden_state\n",
    "    \n",
    "    return t_output.last_hidden_state\n",
    "\n",
    "def text_embedding_via_avg_naively(text):\n",
    "    word_embedding_list = get_word_embeddings(text)[0]\n",
    "    token_count = len(word_embedding_list)\n",
    "    sum_tensor = torch.tensor(word_embedding_list[0])\n",
    "    for word_emb in word_embedding_list[1:]:\n",
    "        sum_tensor += word_emb\n",
    "    avg_tensor = sum_tensor/token_count\n",
    "    return avg_tensor\n",
    "def text_embedding_via_avg_naively(text): ## never normalise each word embedding prior... is it necessary? like stronger words affect more... or dw?\n",
    "    word_embedding_list = get_word_embeddings(text)[0]\n",
    "    token_count = len(word_embedding_list)\n",
    "    sum_tensor = word_embedding_list[0].clone().detach().requires_grad_(False)\n",
    "    for word_emb in word_embedding_list[1:]:\n",
    "        sum_tensor += word_emb\n",
    "    avg_tensor = sum_tensor/token_count\n",
    "    return avg_tensor\n",
    "\n",
    "\n",
    "def text_embedding_via_avg_naively_normlised_words(text): ## never normalise each word embedding prior... is it necessary? like stronger words affect more... or dw?\n",
    "    word_embedding_list = [get_normalise_embedding(word_emb) for word_emb in get_word_embeddings(text)[0]]\n",
    "    token_count = len(word_embedding_list)\n",
    "    sum_tensor = word_embedding_list[0]\n",
    "    for word_emb in word_embedding_list[1:]:\n",
    "        sum_tensor += word_emb\n",
    "    avg_tensor = sum_tensor/token_count\n",
    "    return avg_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naively_avg_cosine_sim(t1, t2):\n",
    "    return cosine_sim(text_embedding_via_avg_naively(t1), text_embedding_via_avg_naively(t2))\n",
    "    #return norm_ed_cosine_sim(get_normalise_embedding(text_embedding_via_avg_naively(t1)), get_normalise_embedding(text_embedding_via_avg_naively(t2)))\n",
    "def naively_normalised_avg_cosine_sim(t1, t2):\n",
    "    return cosine_sim(text_embedding_via_avg_naively_normlised_words(t1), text_embedding_via_avg_naively_normlised_words(t2))\n",
    "    #return norm_ed_cosine_sim(get_normalise_embedding(text_embedding_via_avg_naively_normlised_words(t1)), get_normalise_embedding(text_embedding_via_avg_naively_normlised_words(t2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7771767107832801"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_avg_cosine_sim(\"i love you\", \"i like you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792556218753361"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_normalised_avg_cosine_sim(\"i love you\", \"i like you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.818678379633063"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_avg_cosine_sim(\"i love you\", \"i hate you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8233166842416892"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_normalised_avg_cosine_sim(\"i love you\", \"i hate you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.522591160227222"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_avg_cosine_sim(\"i love you\", \"food is the best way to relieve hunger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6090393860771925"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_avg_cosine_sim(\"i love food\", \"food is the best way to relieve hunger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5243620184164968"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_normalised_avg_cosine_sim(\"i love you\", \"food is the best way to relieve hunger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.617445310014034"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_normalised_avg_cosine_sim(\"i love food\", \"food is the best way to relieve hunger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74544929323595"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naively_normalised_avg_cosine_sim(\"i love trash that can be pooped and vomiting shit which cannot be eaten\", \"food is the best way to relieve hunger and i love food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.4789e-01,  3.9649e-01, -2.4775e-01, -2.0591e-01, -3.3936e-01,\n",
       "         -4.9942e-01,  5.7701e-01,  6.1992e-01,  1.1338e-01, -1.7785e-01,\n",
       "          2.1542e-01, -9.2569e-02,  1.1369e-01,  6.0125e-01,  1.2243e-01,\n",
       "         -1.4392e-01, -1.4674e-01,  3.5705e-01,  2.4601e-01,  2.6711e-02,\n",
       "          1.9500e-01, -3.0176e-01,  7.4834e-02,  5.2450e-02, -2.5367e-01,\n",
       "         -2.6850e-01, -1.7908e-01, -3.0084e-01,  2.6835e-01, -1.0506e-01,\n",
       "         -1.4552e-02,  3.0471e-01, -4.3338e-01, -1.3430e-01,  1.6945e-01,\n",
       "          2.1488e-01,  1.3354e-01,  1.5895e-01, -3.3153e-01,  9.7612e-02,\n",
       "         -1.0803e-01,  4.5685e-02,  1.6506e-01,  1.7767e-01, -1.2236e-01,\n",
       "         -4.3633e-01, -2.7322e+00, -1.5028e-01, -2.2578e-01, -5.7526e-01,\n",
       "          5.2121e-01, -3.9550e-01,  1.1658e-01, -1.3485e-01, -1.2878e-01,\n",
       "          4.6183e-01, -4.6208e-01,  4.1482e-01, -3.1442e-02,  2.8678e-01,\n",
       "          6.9310e-04, -1.0354e-01,  8.6396e-03,  3.3226e-01,  5.5989e-02,\n",
       "          1.8962e-01,  2.6571e-01,  5.6467e-01, -4.2481e-01,  7.4649e-01,\n",
       "         -5.4168e-01, -3.4182e-01,  5.1184e-01,  2.7010e-01, -1.1314e-01,\n",
       "         -2.0112e-01, -3.8301e-02,  1.6351e-01, -9.9111e-02,  8.0431e-02,\n",
       "         -9.3713e-02,  2.3587e-01,  3.2821e-01,  3.1662e-01,  7.6685e-02,\n",
       "          5.6163e-01, -4.6061e-01, -4.4040e-01,  2.7243e-01,  6.1059e-01,\n",
       "         -1.2956e-01,  3.8169e-02,  1.8960e-01,  2.9209e-01,  3.2757e-01,\n",
       "          4.5264e-02,  1.6311e-01,  2.3878e-01,  5.8898e-02,  5.7663e-02,\n",
       "          2.7933e-02,  6.7249e-02,  2.8611e-01, -2.1610e-01,  1.4463e-01,\n",
       "         -6.7766e-03, -1.9298e-01, -3.0158e-01,  1.4638e-01, -2.8641e+00,\n",
       "          6.7145e-01,  5.5571e-02, -6.2217e-01, -1.3935e-01, -3.8822e-01,\n",
       "          6.8160e-01,  5.5067e-01, -2.5401e-01,  2.7301e-01,  3.4760e-01,\n",
       "         -1.3116e-01,  3.6365e-01, -2.6760e-01, -4.0615e-01,  1.0759e-01,\n",
       "          5.2525e-01,  1.6323e-01, -3.4156e-01,  6.7055e-01,  5.2339e-02,\n",
       "          3.4107e-01,  4.2823e-01, -3.6001e-02, -2.1925e-01, -3.3169e-01,\n",
       "         -9.1909e-02,  1.6184e-01, -7.3876e-02,  1.2168e-01, -1.4722e-01,\n",
       "         -5.2350e-01, -2.3491e-01, -3.0959e+00,  3.4957e-01,  5.4101e-01,\n",
       "          2.7694e-01, -5.2677e-01, -2.4177e-01,  1.0505e-02,  3.1436e-02,\n",
       "          2.2422e-02, -1.6675e-01, -2.9391e-01,  6.3544e-01, -3.9439e-01,\n",
       "          6.5789e-02,  2.2879e-02, -4.4302e-01,  3.6972e-01,  5.7439e-01,\n",
       "          2.5585e-01, -2.1971e-01,  1.8439e-01,  1.4028e-01, -3.9007e-01,\n",
       "          7.2587e-02,  5.8726e-01,  2.6401e-01,  1.3341e-01,  1.5601e-02,\n",
       "         -4.3296e-01,  3.4927e-01,  3.9018e-01,  1.3522e-01, -1.5889e-01,\n",
       "         -4.4799e-01,  4.1044e-01,  2.8076e-01,  1.5319e-02,  1.0643e-01,\n",
       "         -1.0432e-01,  4.1100e-01, -1.0046e-02,  1.6086e-01,  4.0431e-01,\n",
       "          1.3320e-01,  2.2272e-01,  3.6531e-01, -3.1590e-01,  3.9093e-01,\n",
       "         -1.6902e-01,  3.8497e-02,  7.1926e-02,  4.8160e-01,  5.0831e-01,\n",
       "          9.0336e-02,  2.5162e-01, -2.8609e-01,  4.0683e-01,  4.1407e-01,\n",
       "          2.0147e-01, -2.2541e-01, -2.3831e-01,  2.1192e-01, -1.8840e-02,\n",
       "          3.8530e+00,  1.1877e-01, -3.8784e-01,  4.8344e-01,  2.8565e-01,\n",
       "         -3.0641e-01, -1.2972e-01,  1.8064e-02, -1.2807e-02,  2.0243e-02,\n",
       "         -3.7910e-02,  4.0786e-01,  2.6217e-03, -4.4281e-01, -3.3589e-02,\n",
       "          4.5677e-01, -1.7903e-03, -2.1949e-01,  2.0683e-01,  4.1092e-02,\n",
       "         -8.7980e-02,  2.8925e-01,  2.3660e-01, -5.1804e-02, -1.6146e+00,\n",
       "         -1.4088e-01, -2.4521e-01, -1.9623e-01,  4.9951e-01, -2.2619e-01,\n",
       "          1.3228e-01, -2.1103e-01, -6.3903e-01,  1.7523e-01,  2.4487e-01,\n",
       "          1.7510e-01,  1.4983e-01,  1.1523e-01,  1.6531e-01, -1.6257e-01,\n",
       "          4.9973e-01,  5.1549e-01, -3.0118e-02,  5.1093e-01,  1.1053e-01,\n",
       "          7.3394e-01, -8.8371e-02,  1.1606e-01, -5.5692e-01,  3.2060e-01,\n",
       "         -7.5674e-02, -1.1914e-01,  2.3810e-01, -4.9066e-01,  1.4681e-01,\n",
       "         -1.3679e-01,  1.3864e-01,  2.7406e-01, -5.9901e-02, -6.5788e-01,\n",
       "         -2.6544e-01,  3.1619e-01, -5.4641e-01, -1.2796e-01, -2.1509e-01,\n",
       "          2.0507e-01, -5.1942e-01, -1.4229e-01, -3.8163e+00,  1.3852e-01,\n",
       "          9.4863e-02,  1.1626e-01,  3.8622e-01, -4.2539e-02, -2.9845e-01,\n",
       "          6.4520e-01,  1.9234e-01, -6.8312e-01,  3.5011e-01, -2.6352e-01,\n",
       "         -3.8071e-01,  2.8529e-01, -2.1073e-01,  1.0420e-01,  6.9226e-02,\n",
       "          2.9035e-01, -2.7877e-01, -2.0260e-01,  4.8318e-01,  1.8823e-01,\n",
       "         -9.9556e-02,  4.5981e-01,  5.1596e-02, -1.6128e-01,  1.2028e-01,\n",
       "          6.7623e-02,  5.0453e-01, -3.6796e-01,  2.3343e-01, -2.8162e-01,\n",
       "          1.0485e-01,  1.2050e-01, -6.1355e-01, -2.2266e+00, -2.5912e-01,\n",
       "          5.8391e-02, -2.0681e-01, -1.9642e-01, -1.0312e-01,  2.8812e-01,\n",
       "          8.1655e-03, -4.8864e-01,  7.9987e-02,  9.1867e-02,  3.6807e-01,\n",
       "         -3.9608e-01,  3.1875e-01,  3.0513e-01, -1.0876e-01,  6.5482e-01,\n",
       "          2.6608e-01,  2.6751e-01,  2.5146e-01, -2.5206e-01,  1.4719e-01,\n",
       "         -3.8870e-02, -4.6506e-02,  2.1072e-01,  2.7753e-01, -9.8589e-02,\n",
       "         -3.1614e-01, -1.0404e-01,  2.7943e-01,  1.0371e-01, -2.0226e-01,\n",
       "          4.4082e-02,  7.9076e-02, -2.0059e-01, -3.5469e-01,  4.1596e-01,\n",
       "          7.3277e-02,  6.2860e-01, -1.1468e-01,  1.4441e-01,  3.3665e-01,\n",
       "          3.7974e-01,  4.3018e-01,  2.8408e-01,  1.1000e-01, -3.8209e-01,\n",
       "         -2.3867e-01, -2.7045e-01, -8.9022e-02, -1.6728e-01, -3.2550e-01,\n",
       "          1.0453e+00, -2.8090e-01,  1.0204e-01, -2.6437e-01,  9.3795e-02,\n",
       "          1.9485e-01,  8.4348e-02,  3.2060e-01,  5.9483e-01,  1.5727e-01,\n",
       "          3.5986e-01,  9.6956e-02,  3.5527e-02, -2.3220e-01,  9.5915e-02,\n",
       "         -5.2979e-01, -2.1744e-01,  1.6661e-01,  9.9157e-02,  1.2844e-01,\n",
       "         -1.8769e-01, -9.2425e-01, -3.2251e-01,  2.3170e-01, -1.5955e-01,\n",
       "          7.9290e-02,  2.9419e-01, -4.8677e-01, -8.7960e-02, -1.9904e-01,\n",
       "         -3.3134e-01,  5.7319e-01, -4.2334e-01, -2.6439e-02,  1.8395e-01,\n",
       "         -2.8694e-01, -2.0998e-01,  2.2981e-01, -3.9288e-01,  4.8166e-01,\n",
       "         -2.4918e-01,  4.8627e-01, -3.1620e-01,  9.2514e-02,  8.1178e-02,\n",
       "         -9.6172e-01, -7.6357e-02, -2.4967e-01, -7.7196e-02, -7.4186e-02,\n",
       "         -1.2178e-01,  4.5233e-01,  3.0635e-01,  7.4556e-02, -2.9149e-01,\n",
       "         -7.5507e-02,  2.0998e-02,  3.5240e-01, -2.1300e-02, -2.2895e-01,\n",
       "         -1.4418e-01,  5.1395e-01,  6.9495e-01, -9.1724e-02,  1.6953e-01,\n",
       "          4.4017e-01, -7.3246e-02,  6.4989e-01,  1.3837e-01,  1.9823e-01,\n",
       "          7.4854e-02,  2.9436e-01, -6.1051e-01,  5.7065e-02, -7.8497e-03,\n",
       "         -3.6827e-01, -6.4384e-01, -4.2169e-01,  2.3597e-01, -1.8785e-03,\n",
       "         -3.1908e-01, -6.8339e-01,  1.6937e-02, -3.8068e-01, -4.4734e-01,\n",
       "         -1.6402e-02,  3.0997e-01,  2.6295e-01,  3.8051e-01, -2.2588e-01,\n",
       "         -4.4181e-01,  4.5684e-01,  1.5288e-01,  4.0539e-01, -1.7881e-02,\n",
       "          6.9741e-03, -5.7481e-01,  4.8618e-01, -8.8373e-02, -4.1166e-01,\n",
       "         -6.3005e-02, -6.2955e-01,  4.8653e-01,  3.1049e-01,  3.5432e-01,\n",
       "         -3.1729e-01, -1.9428e-01, -6.8060e-02,  2.6702e-02,  8.7120e-02,\n",
       "         -9.7346e-01,  7.7772e-01,  4.1876e-01,  7.9796e-02,  1.7213e-01,\n",
       "          7.2744e-02, -6.6895e-01,  4.0967e-01, -9.6743e-02,  5.3160e-01,\n",
       "         -6.0398e-03,  1.1299e-01,  1.8661e-02,  4.3255e-01, -3.2980e-02,\n",
       "          2.1502e-01,  4.1948e-01, -4.1559e-01, -3.6663e-01, -2.8041e-01,\n",
       "         -1.4781e-01,  2.5524e-01,  1.9202e-02, -3.3103e-01, -1.8274e-01,\n",
       "         -1.5204e-01, -2.3951e-01,  6.6137e-01, -1.7687e-01,  2.8011e-01,\n",
       "         -3.8733e-02, -3.4290e-01, -6.0110e-01, -2.1980e-01,  2.6743e-02,\n",
       "         -4.2836e-01, -4.4201e-02, -2.9945e-01,  6.4239e-01,  1.8654e-01,\n",
       "          1.0082e-01,  7.1221e-01,  3.2042e-01, -1.9595e-01,  2.4274e-01,\n",
       "          4.6006e-01, -3.7654e-01,  4.8437e-01,  3.6747e-01, -7.7667e-01,\n",
       "          1.7681e-02,  6.8008e-02, -1.1513e-02, -2.5006e-01,  9.5975e-02,\n",
       "         -1.0332e-01,  2.0575e-01, -1.6151e-01, -3.8715e-01,  1.1135e-03,\n",
       "         -1.8268e-01, -1.9110e-01, -6.2386e-01, -1.5047e-01, -4.2429e-01,\n",
       "         -4.3610e-01, -1.6557e-01, -5.6869e-01, -4.2700e-01,  5.7468e-02,\n",
       "          6.0186e-01,  9.8941e-02, -2.5558e-01,  2.0901e-01, -7.1595e-01,\n",
       "          2.3856e-01,  3.2392e-01,  3.8358e-01, -2.4739e-02, -1.5289e-01,\n",
       "          2.1994e-01, -4.5773e-01, -2.6595e-01,  1.7735e-01,  3.2706e-03,\n",
       "          4.3834e-01, -8.6402e-02, -2.4955e-01, -1.6416e-01, -3.5189e-02,\n",
       "         -3.2140e-01, -3.6396e-01,  3.1696e-01,  3.1367e-01,  3.1305e-02,\n",
       "          1.8894e-01,  7.3451e-02,  2.6322e-02,  1.3698e-02,  4.1265e-02,\n",
       "         -2.2399e-01,  3.0181e-01,  2.9515e-01, -1.4903e-01, -1.6263e-02,\n",
       "          1.5979e-01,  4.5236e-01,  2.7588e-01, -3.4155e-01, -3.0613e-01,\n",
       "         -3.3922e-01, -5.3993e-02, -3.2999e-01, -3.0002e-01,  1.7753e-01,\n",
       "         -4.4019e-01,  1.1825e-01, -1.2579e-01,  2.3059e+00,  6.2682e-01,\n",
       "          4.7256e-02, -4.8021e-01,  5.0676e-01, -1.5952e-01, -1.1581e-01,\n",
       "         -1.5818e-01, -1.6194e-01,  4.3539e-01, -2.2914e-01,  2.3942e-01,\n",
       "         -6.3369e-02,  2.4686e-01,  6.3680e-01,  1.8212e-01, -3.6147e-01,\n",
       "         -2.4254e-01, -7.6624e-01, -3.0973e-02, -3.0832e-01,  4.5608e-01,\n",
       "          1.6796e-01, -2.8850e-01,  1.1688e-01,  4.7691e-01,  1.5951e-01,\n",
       "         -2.2852e-01,  1.0030e-01,  2.4817e-01, -5.0528e-01, -1.2576e-01,\n",
       "         -5.2549e-02,  3.0196e-01, -2.0180e-01,  4.4670e-01, -1.2968e-01,\n",
       "         -6.4021e-01, -3.1649e-01,  2.9233e-01, -1.2183e-01, -2.7670e-01,\n",
       "          3.4286e-01,  1.7311e-01,  1.0935e-01,  9.4541e-01, -4.0167e-01,\n",
       "         -2.8135e-01,  4.3542e-01,  1.5234e-01,  1.7269e-02, -2.0642e-01,\n",
       "         -4.3527e-01, -9.2780e-02,  5.6084e-02, -5.4130e-01,  3.7691e-01,\n",
       "         -2.4458e-01, -2.4056e-01,  2.7671e-01, -1.1805e-01,  4.6933e-01,\n",
       "          1.6504e-01, -1.9784e-01, -1.0981e-01,  7.4558e-03, -3.2497e-01,\n",
       "          2.2253e-01, -2.6372e-01, -4.9588e-01, -1.0158e-01,  4.2843e-01,\n",
       "          4.9627e-01, -2.6720e-03,  1.7637e-01, -7.0341e-02, -2.3104e-02,\n",
       "         -1.4328e-01, -2.4015e-01, -3.2590e+00,  1.8189e-01, -2.7963e-01,\n",
       "          1.2766e-01,  6.7087e-02, -1.3260e-01, -6.9318e-02,  1.0632e-01,\n",
       "          6.6242e-02, -3.2931e-01,  6.3560e-02,  2.9831e-01,  3.7603e-01,\n",
       "          4.1830e-01,  1.9024e-01,  2.5750e-01,  5.7155e-02, -4.1467e-01,\n",
       "         -1.4410e-01, -3.8259e-01,  3.1193e-01,  2.9645e-01, -7.3266e-02,\n",
       "         -5.8629e-02, -1.1773e-02,  4.6687e-01, -1.8292e-01, -2.1859e-01,\n",
       "          5.1100e-02,  5.9939e-01, -3.5067e-01,  6.0459e-01, -1.9626e-02,\n",
       "         -1.2881e-01, -6.3127e-02, -3.8423e-02, -5.0565e-01,  6.4271e-02,\n",
       "          3.7571e-01,  4.5636e-02, -6.3407e-02,  4.5432e-01,  6.2590e-02,\n",
       "          3.7844e-01, -2.9870e-01, -3.6200e-01,  5.0688e-01, -1.1502e-01,\n",
       "          4.2972e-01,  2.0203e-01,  1.9937e-01, -8.8481e-02, -1.8421e-02,\n",
       "          8.3498e-03,  9.0842e-02,  1.3631e-01, -1.0042e-01, -7.5143e-02,\n",
       "          5.7289e-02, -2.8921e-01,  3.0106e-01, -3.9652e-03, -1.7617e-01,\n",
       "          2.2470e-01,  2.0782e-01, -2.4291e-02,  1.5985e-01, -1.0514e-01,\n",
       "          4.1875e-02,  3.0374e-01, -2.2883e-01, -2.8921e-01,  3.5065e-01,\n",
       "          2.2884e-02, -3.7112e-01, -7.0024e-02,  4.6041e-01,  1.5167e-01,\n",
       "          2.9960e-01,  3.2259e-01, -3.4147e-01, -2.0103e-01, -3.8121e-01,\n",
       "          1.7541e-01, -2.4282e-01, -8.2775e+00, -1.4453e-01, -4.0495e-01,\n",
       "         -4.4229e-01,  3.3408e-01, -6.7739e-01,  1.7683e-01, -5.8558e-01,\n",
       "          2.1137e-01, -8.3851e-02,  1.2385e-01,  6.4620e-02, -2.2673e-01,\n",
       "         -1.2281e-01,  1.4289e-01,  3.2144e-01]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_word_embedding(\"hi there\")[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.4789e-01,  3.9649e-01, -2.4775e-01, -2.0591e-01, -3.3936e-01,\n",
       "        -4.9942e-01,  5.7701e-01,  6.1992e-01,  1.1338e-01, -1.7785e-01,\n",
       "         2.1542e-01, -9.2569e-02,  1.1369e-01,  6.0125e-01,  1.2243e-01,\n",
       "        -1.4392e-01, -1.4674e-01,  3.5705e-01,  2.4601e-01,  2.6711e-02,\n",
       "         1.9500e-01, -3.0176e-01,  7.4834e-02,  5.2450e-02, -2.5367e-01,\n",
       "        -2.6850e-01, -1.7908e-01, -3.0084e-01,  2.6835e-01, -1.0506e-01,\n",
       "        -1.4552e-02,  3.0471e-01, -4.3338e-01, -1.3430e-01,  1.6945e-01,\n",
       "         2.1488e-01,  1.3354e-01,  1.5895e-01, -3.3153e-01,  9.7612e-02,\n",
       "        -1.0803e-01,  4.5685e-02,  1.6506e-01,  1.7767e-01, -1.2236e-01,\n",
       "        -4.3633e-01, -2.7322e+00, -1.5028e-01, -2.2578e-01, -5.7526e-01,\n",
       "         5.2121e-01, -3.9550e-01,  1.1658e-01, -1.3485e-01, -1.2878e-01,\n",
       "         4.6183e-01, -4.6208e-01,  4.1482e-01, -3.1442e-02,  2.8678e-01,\n",
       "         6.9310e-04, -1.0354e-01,  8.6396e-03,  3.3226e-01,  5.5989e-02,\n",
       "         1.8962e-01,  2.6571e-01,  5.6467e-01, -4.2481e-01,  7.4649e-01,\n",
       "        -5.4168e-01, -3.4182e-01,  5.1184e-01,  2.7010e-01, -1.1314e-01,\n",
       "        -2.0112e-01, -3.8301e-02,  1.6351e-01, -9.9111e-02,  8.0431e-02,\n",
       "        -9.3713e-02,  2.3587e-01,  3.2821e-01,  3.1662e-01,  7.6685e-02,\n",
       "         5.6163e-01, -4.6061e-01, -4.4040e-01,  2.7243e-01,  6.1059e-01,\n",
       "        -1.2956e-01,  3.8169e-02,  1.8960e-01,  2.9209e-01,  3.2757e-01,\n",
       "         4.5264e-02,  1.6311e-01,  2.3878e-01,  5.8898e-02,  5.7663e-02,\n",
       "         2.7933e-02,  6.7249e-02,  2.8611e-01, -2.1610e-01,  1.4463e-01,\n",
       "        -6.7766e-03, -1.9298e-01, -3.0158e-01,  1.4638e-01, -2.8641e+00,\n",
       "         6.7145e-01,  5.5571e-02, -6.2217e-01, -1.3935e-01, -3.8822e-01,\n",
       "         6.8160e-01,  5.5067e-01, -2.5401e-01,  2.7301e-01,  3.4760e-01,\n",
       "        -1.3116e-01,  3.6365e-01, -2.6760e-01, -4.0615e-01,  1.0759e-01,\n",
       "         5.2525e-01,  1.6323e-01, -3.4156e-01,  6.7055e-01,  5.2339e-02,\n",
       "         3.4107e-01,  4.2823e-01, -3.6001e-02, -2.1925e-01, -3.3169e-01,\n",
       "        -9.1909e-02,  1.6184e-01, -7.3876e-02,  1.2168e-01, -1.4722e-01,\n",
       "        -5.2350e-01, -2.3491e-01, -3.0959e+00,  3.4957e-01,  5.4101e-01,\n",
       "         2.7694e-01, -5.2677e-01, -2.4177e-01,  1.0505e-02,  3.1436e-02,\n",
       "         2.2422e-02, -1.6675e-01, -2.9391e-01,  6.3544e-01, -3.9439e-01,\n",
       "         6.5789e-02,  2.2879e-02, -4.4302e-01,  3.6972e-01,  5.7439e-01,\n",
       "         2.5585e-01, -2.1971e-01,  1.8439e-01,  1.4028e-01, -3.9007e-01,\n",
       "         7.2587e-02,  5.8726e-01,  2.6401e-01,  1.3341e-01,  1.5601e-02,\n",
       "        -4.3296e-01,  3.4927e-01,  3.9018e-01,  1.3522e-01, -1.5889e-01,\n",
       "        -4.4799e-01,  4.1044e-01,  2.8076e-01,  1.5319e-02,  1.0643e-01,\n",
       "        -1.0432e-01,  4.1100e-01, -1.0046e-02,  1.6086e-01,  4.0431e-01,\n",
       "         1.3320e-01,  2.2272e-01,  3.6531e-01, -3.1590e-01,  3.9093e-01,\n",
       "        -1.6902e-01,  3.8497e-02,  7.1926e-02,  4.8160e-01,  5.0831e-01,\n",
       "         9.0336e-02,  2.5162e-01, -2.8609e-01,  4.0683e-01,  4.1407e-01,\n",
       "         2.0147e-01, -2.2541e-01, -2.3831e-01,  2.1192e-01, -1.8840e-02,\n",
       "         3.8530e+00,  1.1877e-01, -3.8784e-01,  4.8344e-01,  2.8565e-01,\n",
       "        -3.0641e-01, -1.2972e-01,  1.8064e-02, -1.2807e-02,  2.0243e-02,\n",
       "        -3.7910e-02,  4.0786e-01,  2.6217e-03, -4.4281e-01, -3.3589e-02,\n",
       "         4.5677e-01, -1.7903e-03, -2.1949e-01,  2.0683e-01,  4.1092e-02,\n",
       "        -8.7980e-02,  2.8925e-01,  2.3660e-01, -5.1804e-02, -1.6146e+00,\n",
       "        -1.4088e-01, -2.4521e-01, -1.9623e-01,  4.9951e-01, -2.2619e-01,\n",
       "         1.3228e-01, -2.1103e-01, -6.3903e-01,  1.7523e-01,  2.4487e-01,\n",
       "         1.7510e-01,  1.4983e-01,  1.1523e-01,  1.6531e-01, -1.6257e-01,\n",
       "         4.9973e-01,  5.1549e-01, -3.0118e-02,  5.1093e-01,  1.1053e-01,\n",
       "         7.3394e-01, -8.8371e-02,  1.1606e-01, -5.5692e-01,  3.2060e-01,\n",
       "        -7.5674e-02, -1.1914e-01,  2.3810e-01, -4.9066e-01,  1.4681e-01,\n",
       "        -1.3679e-01,  1.3864e-01,  2.7406e-01, -5.9901e-02, -6.5788e-01,\n",
       "        -2.6544e-01,  3.1619e-01, -5.4641e-01, -1.2796e-01, -2.1509e-01,\n",
       "         2.0507e-01, -5.1942e-01, -1.4229e-01, -3.8163e+00,  1.3852e-01,\n",
       "         9.4863e-02,  1.1626e-01,  3.8622e-01, -4.2539e-02, -2.9845e-01,\n",
       "         6.4520e-01,  1.9234e-01, -6.8312e-01,  3.5011e-01, -2.6352e-01,\n",
       "        -3.8071e-01,  2.8529e-01, -2.1073e-01,  1.0420e-01,  6.9226e-02,\n",
       "         2.9035e-01, -2.7877e-01, -2.0260e-01,  4.8318e-01,  1.8823e-01,\n",
       "        -9.9556e-02,  4.5981e-01,  5.1596e-02, -1.6128e-01,  1.2028e-01,\n",
       "         6.7623e-02,  5.0453e-01, -3.6796e-01,  2.3343e-01, -2.8162e-01,\n",
       "         1.0485e-01,  1.2050e-01, -6.1355e-01, -2.2266e+00, -2.5912e-01,\n",
       "         5.8391e-02, -2.0681e-01, -1.9642e-01, -1.0312e-01,  2.8812e-01,\n",
       "         8.1655e-03, -4.8864e-01,  7.9987e-02,  9.1867e-02,  3.6807e-01,\n",
       "        -3.9608e-01,  3.1875e-01,  3.0513e-01, -1.0876e-01,  6.5482e-01,\n",
       "         2.6608e-01,  2.6751e-01,  2.5146e-01, -2.5206e-01,  1.4719e-01,\n",
       "        -3.8870e-02, -4.6506e-02,  2.1072e-01,  2.7753e-01, -9.8589e-02,\n",
       "        -3.1614e-01, -1.0404e-01,  2.7943e-01,  1.0371e-01, -2.0226e-01,\n",
       "         4.4082e-02,  7.9076e-02, -2.0059e-01, -3.5469e-01,  4.1596e-01,\n",
       "         7.3277e-02,  6.2860e-01, -1.1468e-01,  1.4441e-01,  3.3665e-01,\n",
       "         3.7974e-01,  4.3018e-01,  2.8408e-01,  1.1000e-01, -3.8209e-01,\n",
       "        -2.3867e-01, -2.7045e-01, -8.9022e-02, -1.6728e-01, -3.2550e-01,\n",
       "         1.0453e+00, -2.8090e-01,  1.0204e-01, -2.6437e-01,  9.3795e-02,\n",
       "         1.9485e-01,  8.4348e-02,  3.2060e-01,  5.9483e-01,  1.5727e-01,\n",
       "         3.5986e-01,  9.6956e-02,  3.5527e-02, -2.3220e-01,  9.5915e-02,\n",
       "        -5.2979e-01, -2.1744e-01,  1.6661e-01,  9.9157e-02,  1.2844e-01,\n",
       "        -1.8769e-01, -9.2425e-01, -3.2251e-01,  2.3170e-01, -1.5955e-01,\n",
       "         7.9290e-02,  2.9419e-01, -4.8677e-01, -8.7960e-02, -1.9904e-01,\n",
       "        -3.3134e-01,  5.7319e-01, -4.2334e-01, -2.6439e-02,  1.8395e-01,\n",
       "        -2.8694e-01, -2.0998e-01,  2.2981e-01, -3.9288e-01,  4.8166e-01,\n",
       "        -2.4918e-01,  4.8627e-01, -3.1620e-01,  9.2514e-02,  8.1178e-02,\n",
       "        -9.6172e-01, -7.6357e-02, -2.4967e-01, -7.7196e-02, -7.4186e-02,\n",
       "        -1.2178e-01,  4.5233e-01,  3.0635e-01,  7.4556e-02, -2.9149e-01,\n",
       "        -7.5507e-02,  2.0998e-02,  3.5240e-01, -2.1300e-02, -2.2895e-01,\n",
       "        -1.4418e-01,  5.1395e-01,  6.9495e-01, -9.1724e-02,  1.6953e-01,\n",
       "         4.4017e-01, -7.3246e-02,  6.4989e-01,  1.3837e-01,  1.9823e-01,\n",
       "         7.4854e-02,  2.9436e-01, -6.1051e-01,  5.7065e-02, -7.8497e-03,\n",
       "        -3.6827e-01, -6.4384e-01, -4.2169e-01,  2.3597e-01, -1.8785e-03,\n",
       "        -3.1908e-01, -6.8339e-01,  1.6937e-02, -3.8068e-01, -4.4734e-01,\n",
       "        -1.6402e-02,  3.0997e-01,  2.6295e-01,  3.8051e-01, -2.2588e-01,\n",
       "        -4.4181e-01,  4.5684e-01,  1.5288e-01,  4.0539e-01, -1.7881e-02,\n",
       "         6.9741e-03, -5.7481e-01,  4.8618e-01, -8.8373e-02, -4.1166e-01,\n",
       "        -6.3005e-02, -6.2955e-01,  4.8653e-01,  3.1049e-01,  3.5432e-01,\n",
       "        -3.1729e-01, -1.9428e-01, -6.8060e-02,  2.6702e-02,  8.7120e-02,\n",
       "        -9.7346e-01,  7.7772e-01,  4.1876e-01,  7.9796e-02,  1.7213e-01,\n",
       "         7.2744e-02, -6.6895e-01,  4.0967e-01, -9.6743e-02,  5.3160e-01,\n",
       "        -6.0398e-03,  1.1299e-01,  1.8661e-02,  4.3255e-01, -3.2980e-02,\n",
       "         2.1502e-01,  4.1948e-01, -4.1559e-01, -3.6663e-01, -2.8041e-01,\n",
       "        -1.4781e-01,  2.5524e-01,  1.9202e-02, -3.3103e-01, -1.8274e-01,\n",
       "        -1.5204e-01, -2.3951e-01,  6.6137e-01, -1.7687e-01,  2.8011e-01,\n",
       "        -3.8733e-02, -3.4290e-01, -6.0110e-01, -2.1980e-01,  2.6743e-02,\n",
       "        -4.2836e-01, -4.4201e-02, -2.9945e-01,  6.4239e-01,  1.8654e-01,\n",
       "         1.0082e-01,  7.1221e-01,  3.2042e-01, -1.9595e-01,  2.4274e-01,\n",
       "         4.6006e-01, -3.7654e-01,  4.8437e-01,  3.6747e-01, -7.7667e-01,\n",
       "         1.7681e-02,  6.8008e-02, -1.1513e-02, -2.5006e-01,  9.5975e-02,\n",
       "        -1.0332e-01,  2.0575e-01, -1.6151e-01, -3.8715e-01,  1.1135e-03,\n",
       "        -1.8268e-01, -1.9110e-01, -6.2386e-01, -1.5047e-01, -4.2429e-01,\n",
       "        -4.3610e-01, -1.6557e-01, -5.6869e-01, -4.2700e-01,  5.7468e-02,\n",
       "         6.0186e-01,  9.8941e-02, -2.5558e-01,  2.0901e-01, -7.1595e-01,\n",
       "         2.3856e-01,  3.2392e-01,  3.8358e-01, -2.4739e-02, -1.5289e-01,\n",
       "         2.1994e-01, -4.5773e-01, -2.6595e-01,  1.7735e-01,  3.2706e-03,\n",
       "         4.3834e-01, -8.6402e-02, -2.4955e-01, -1.6416e-01, -3.5189e-02,\n",
       "        -3.2140e-01, -3.6396e-01,  3.1696e-01,  3.1367e-01,  3.1305e-02,\n",
       "         1.8894e-01,  7.3451e-02,  2.6322e-02,  1.3698e-02,  4.1265e-02,\n",
       "        -2.2399e-01,  3.0181e-01,  2.9515e-01, -1.4903e-01, -1.6263e-02,\n",
       "         1.5979e-01,  4.5236e-01,  2.7588e-01, -3.4155e-01, -3.0613e-01,\n",
       "        -3.3922e-01, -5.3993e-02, -3.2999e-01, -3.0002e-01,  1.7753e-01,\n",
       "        -4.4019e-01,  1.1825e-01, -1.2579e-01,  2.3059e+00,  6.2682e-01,\n",
       "         4.7256e-02, -4.8021e-01,  5.0676e-01, -1.5952e-01, -1.1581e-01,\n",
       "        -1.5818e-01, -1.6194e-01,  4.3539e-01, -2.2914e-01,  2.3942e-01,\n",
       "        -6.3369e-02,  2.4686e-01,  6.3680e-01,  1.8212e-01, -3.6147e-01,\n",
       "        -2.4254e-01, -7.6624e-01, -3.0973e-02, -3.0832e-01,  4.5608e-01,\n",
       "         1.6796e-01, -2.8850e-01,  1.1688e-01,  4.7691e-01,  1.5951e-01,\n",
       "        -2.2852e-01,  1.0030e-01,  2.4817e-01, -5.0528e-01, -1.2576e-01,\n",
       "        -5.2549e-02,  3.0196e-01, -2.0180e-01,  4.4670e-01, -1.2968e-01,\n",
       "        -6.4021e-01, -3.1649e-01,  2.9233e-01, -1.2183e-01, -2.7670e-01,\n",
       "         3.4286e-01,  1.7311e-01,  1.0935e-01,  9.4541e-01, -4.0167e-01,\n",
       "        -2.8135e-01,  4.3542e-01,  1.5234e-01,  1.7269e-02, -2.0642e-01,\n",
       "        -4.3527e-01, -9.2780e-02,  5.6084e-02, -5.4130e-01,  3.7691e-01,\n",
       "        -2.4458e-01, -2.4056e-01,  2.7671e-01, -1.1805e-01,  4.6933e-01,\n",
       "         1.6504e-01, -1.9784e-01, -1.0981e-01,  7.4558e-03, -3.2497e-01,\n",
       "         2.2253e-01, -2.6372e-01, -4.9588e-01, -1.0158e-01,  4.2843e-01,\n",
       "         4.9627e-01, -2.6720e-03,  1.7637e-01, -7.0341e-02, -2.3104e-02,\n",
       "        -1.4328e-01, -2.4015e-01, -3.2590e+00,  1.8189e-01, -2.7963e-01,\n",
       "         1.2766e-01,  6.7087e-02, -1.3260e-01, -6.9318e-02,  1.0632e-01,\n",
       "         6.6242e-02, -3.2931e-01,  6.3560e-02,  2.9831e-01,  3.7603e-01,\n",
       "         4.1830e-01,  1.9024e-01,  2.5750e-01,  5.7155e-02, -4.1467e-01,\n",
       "        -1.4410e-01, -3.8259e-01,  3.1193e-01,  2.9645e-01, -7.3266e-02,\n",
       "        -5.8629e-02, -1.1773e-02,  4.6687e-01, -1.8292e-01, -2.1859e-01,\n",
       "         5.1100e-02,  5.9939e-01, -3.5067e-01,  6.0459e-01, -1.9626e-02,\n",
       "        -1.2881e-01, -6.3127e-02, -3.8423e-02, -5.0565e-01,  6.4271e-02,\n",
       "         3.7571e-01,  4.5636e-02, -6.3407e-02,  4.5432e-01,  6.2590e-02,\n",
       "         3.7844e-01, -2.9870e-01, -3.6200e-01,  5.0688e-01, -1.1502e-01,\n",
       "         4.2972e-01,  2.0203e-01,  1.9937e-01, -8.8481e-02, -1.8421e-02,\n",
       "         8.3498e-03,  9.0842e-02,  1.3631e-01, -1.0042e-01, -7.5143e-02,\n",
       "         5.7289e-02, -2.8921e-01,  3.0106e-01, -3.9652e-03, -1.7617e-01,\n",
       "         2.2470e-01,  2.0782e-01, -2.4291e-02,  1.5985e-01, -1.0514e-01,\n",
       "         4.1875e-02,  3.0374e-01, -2.2883e-01, -2.8921e-01,  3.5065e-01,\n",
       "         2.2884e-02, -3.7112e-01, -7.0024e-02,  4.6041e-01,  1.5167e-01,\n",
       "         2.9960e-01,  3.2259e-01, -3.4147e-01, -2.0103e-01, -3.8121e-01,\n",
       "         1.7541e-01, -2.4282e-01, -8.2775e+00, -1.4453e-01, -4.0495e-01,\n",
       "        -4.4229e-01,  3.3408e-01, -6.7739e-01,  1.7683e-01, -5.8558e-01,\n",
       "         2.1137e-01, -8.3851e-02,  1.2385e-01,  6.4620e-02, -2.2673e-01,\n",
       "        -1.2281e-01,  1.4289e-01,  3.2144e-01], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cls_embedding(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(sentence):\n",
    "    #sentence_embeddings = torch.nn.functional.normalize(torch.tensor(get_cls_embedding(sentence)), p=2, dim=1) ## the \"torch.nn.functional.normalize\" function needs a tensor with like tensor(s) in tensor, so cannot just 1d tensor??? idk\n",
    "    sentence_embeddings = torch.nn.functional.normalize(torch.tensor(get_word_embedding(sentence)[:1]), p=2, dim=1)\n",
    "    return sentence_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_cos_sim(t1, t2):\n",
    "    return cosine_sim(get_sentence_embedding(t1)[0], get_sentence_embedding(t2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Audric Ho\\AppData\\Local\\Temp\\ipykernel_10296\\1698119748.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embeddings = torch.nn.functional.normalize(torch.tensor(get_word_embedding(sentence)[:1]), p=2, dim=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-9.9402e-03,  2.6649e-02, -1.6652e-02, -1.3840e-02, -2.2809e-02,\n",
       "         -3.3567e-02,  3.8782e-02,  4.1666e-02,  7.6206e-03, -1.1954e-02,\n",
       "          1.4478e-02, -6.2217e-03,  7.6412e-03,  4.0411e-02,  8.2289e-03,\n",
       "         -9.6733e-03, -9.8628e-03,  2.3998e-02,  1.6535e-02,  1.7953e-03,\n",
       "          1.3106e-02, -2.0282e-02,  5.0297e-03,  3.5252e-03, -1.7050e-02,\n",
       "         -1.8046e-02, -1.2036e-02, -2.0220e-02,  1.8036e-02, -7.0615e-03,\n",
       "         -9.7804e-04,  2.0480e-02, -2.9128e-02, -9.0266e-03,  1.1389e-02,\n",
       "          1.4442e-02,  8.9755e-03,  1.0684e-02, -2.2283e-02,  6.5606e-03,\n",
       "         -7.2608e-03,  3.0706e-03,  1.1094e-02,  1.1941e-02, -8.2243e-03,\n",
       "         -2.9326e-02, -1.8363e-01, -1.0101e-02, -1.5175e-02, -3.8664e-02,\n",
       "          3.5031e-02, -2.6582e-02,  7.8358e-03, -9.0633e-03, -8.6557e-03,\n",
       "          3.1040e-02, -3.1057e-02,  2.7881e-02, -2.1132e-03,  1.9275e-02,\n",
       "          4.6584e-05, -6.9592e-03,  5.8068e-04,  2.2331e-02,  3.7631e-03,\n",
       "          1.2745e-02,  1.7859e-02,  3.7952e-02, -2.8552e-02,  5.0173e-02,\n",
       "         -3.6407e-02, -2.2974e-02,  3.4402e-02,  1.8154e-02, -7.6041e-03,\n",
       "         -1.3517e-02, -2.5743e-03,  1.0990e-02, -6.6614e-03,  5.4059e-03,\n",
       "         -6.2986e-03,  1.5853e-02,  2.2059e-02,  2.1280e-02,  5.1541e-03,\n",
       "          3.7748e-02, -3.0958e-02, -2.9600e-02,  1.8310e-02,  4.1039e-02,\n",
       "         -8.7078e-03,  2.5654e-03,  1.2743e-02,  1.9632e-02,  2.2017e-02,\n",
       "          3.0422e-03,  1.0963e-02,  1.6049e-02,  3.9587e-03,  3.8756e-03,\n",
       "          1.8774e-03,  4.5199e-03,  1.9230e-02, -1.4525e-02,  9.7205e-03,\n",
       "         -4.5547e-04, -1.2970e-02, -2.0270e-02,  9.8385e-03, -1.9250e-01,\n",
       "          4.5129e-02,  3.7350e-03, -4.1817e-02, -9.3660e-03, -2.6093e-02,\n",
       "          4.5811e-02,  3.7011e-02, -1.7073e-02,  1.8349e-02,  2.3363e-02,\n",
       "         -8.8152e-03,  2.4441e-02, -1.7986e-02, -2.7298e-02,  7.2312e-03,\n",
       "          3.5303e-02,  1.0971e-02, -2.2957e-02,  4.5069e-02,  3.5178e-03,\n",
       "          2.2924e-02,  2.8782e-02, -2.4197e-03, -1.4736e-02, -2.2293e-02,\n",
       "         -6.1773e-03,  1.0878e-02, -4.9653e-03,  8.1780e-03, -9.8949e-03,\n",
       "         -3.5185e-02, -1.5788e-02, -2.0808e-01,  2.3495e-02,  3.6362e-02,\n",
       "          1.8614e-02, -3.5405e-02, -1.6250e-02,  7.0605e-04,  2.1129e-03,\n",
       "          1.5070e-03, -1.1208e-02, -1.9754e-02,  4.2709e-02, -2.6508e-02,\n",
       "          4.4218e-03,  1.5378e-03, -2.9776e-02,  2.4849e-02,  3.8605e-02,\n",
       "          1.7196e-02, -1.4767e-02,  1.2393e-02,  9.4282e-03, -2.6217e-02,\n",
       "          4.8787e-03,  3.9470e-02,  1.7744e-02,  8.9668e-03,  1.0486e-03,\n",
       "         -2.9100e-02,  2.3475e-02,  2.6225e-02,  9.0886e-03, -1.0679e-02,\n",
       "         -3.0110e-02,  2.7587e-02,  1.8870e-02,  1.0296e-03,  7.1532e-03,\n",
       "         -7.0116e-03,  2.7624e-02, -6.7521e-04,  1.0811e-02,  2.7174e-02,\n",
       "          8.9524e-03,  1.4969e-02,  2.4553e-02, -2.1232e-02,  2.6275e-02,\n",
       "         -1.1360e-02,  2.5874e-03,  4.8343e-03,  3.2369e-02,  3.4164e-02,\n",
       "          6.0716e-03,  1.6912e-02, -1.9229e-02,  2.7344e-02,  2.7831e-02,\n",
       "          1.3541e-02, -1.5150e-02, -1.6017e-02,  1.4243e-02, -1.2662e-03,\n",
       "          2.5897e-01,  7.9826e-03, -2.6068e-02,  3.2492e-02,  1.9199e-02,\n",
       "         -2.0594e-02, -8.7190e-03,  1.2141e-03, -8.6078e-04,  1.3606e-03,\n",
       "         -2.5480e-03,  2.7413e-02,  1.7621e-04, -2.9762e-02, -2.2576e-03,\n",
       "          3.0700e-02, -1.2033e-04, -1.4752e-02,  1.3902e-02,  2.7618e-03,\n",
       "         -5.9133e-03,  1.9441e-02,  1.5903e-02, -3.4819e-03, -1.0852e-01,\n",
       "         -9.4690e-03, -1.6481e-02, -1.3189e-02,  3.3573e-02, -1.5202e-02,\n",
       "          8.8905e-03, -1.4184e-02, -4.2950e-02,  1.1777e-02,  1.6458e-02,\n",
       "          1.1769e-02,  1.0070e-02,  7.7451e-03,  1.1111e-02, -1.0927e-02,\n",
       "          3.3587e-02,  3.4647e-02, -2.0243e-03,  3.4340e-02,  7.4286e-03,\n",
       "          4.9329e-02, -5.9395e-03,  7.8004e-03, -3.7432e-02,  2.1548e-02,\n",
       "         -5.0862e-03, -8.0075e-03,  1.6003e-02, -3.2978e-02,  9.8676e-03,\n",
       "         -9.1936e-03,  9.3183e-03,  1.8420e-02, -4.0260e-03, -4.4217e-02,\n",
       "         -1.7840e-02,  2.1252e-02, -3.6725e-02, -8.6004e-03, -1.4457e-02,\n",
       "          1.3783e-02, -3.4911e-02, -9.5636e-03, -2.5650e-01,  9.3103e-03,\n",
       "          6.3759e-03,  7.8143e-03,  2.5959e-02, -2.8591e-03, -2.0059e-02,\n",
       "          4.3365e-02,  1.2928e-02, -4.5913e-02,  2.3532e-02, -1.7711e-02,\n",
       "         -2.5588e-02,  1.9175e-02, -1.4163e-02,  7.0035e-03,  4.6528e-03,\n",
       "          1.9515e-02, -1.8737e-02, -1.3617e-02,  3.2475e-02,  1.2652e-02,\n",
       "         -6.6913e-03,  3.0905e-02,  3.4679e-03, -1.0840e-02,  8.0839e-03,\n",
       "          4.5450e-03,  3.3910e-02, -2.4731e-02,  1.5689e-02, -1.8928e-02,\n",
       "          7.0473e-03,  8.0991e-03, -4.1238e-02, -1.4965e-01, -1.7416e-02,\n",
       "          3.9246e-03, -1.3900e-02, -1.3202e-02, -6.9306e-03,  1.9365e-02,\n",
       "          5.4882e-04, -3.2842e-02,  5.3761e-03,  6.1745e-03,  2.4738e-02,\n",
       "         -2.6621e-02,  2.1423e-02,  2.0508e-02, -7.3096e-03,  4.4011e-02,\n",
       "          1.7883e-02,  1.7980e-02,  1.6901e-02, -1.6942e-02,  9.8928e-03,\n",
       "         -2.6125e-03, -3.1257e-03,  1.4163e-02,  1.8653e-02, -6.6264e-03,\n",
       "         -2.1248e-02, -6.9929e-03,  1.8781e-02,  6.9707e-03, -1.3594e-02,\n",
       "          2.9628e-03,  5.3148e-03, -1.3482e-02, -2.3840e-02,  2.7957e-02,\n",
       "          4.9251e-03,  4.2249e-02, -7.7080e-03,  9.7060e-03,  2.2627e-02,\n",
       "          2.5523e-02,  2.8913e-02,  1.9093e-02,  7.3934e-03, -2.5681e-02,\n",
       "         -1.6042e-02, -1.8177e-02, -5.9833e-03, -1.1243e-02, -2.1878e-02,\n",
       "          7.0258e-02, -1.8880e-02,  6.8582e-03, -1.7769e-02,  6.3041e-03,\n",
       "          1.3096e-02,  5.6692e-03,  2.1548e-02,  3.9979e-02,  1.0570e-02,\n",
       "          2.4187e-02,  6.5166e-03,  2.3878e-03, -1.5606e-02,  6.4466e-03,\n",
       "         -3.5608e-02, -1.4614e-02,  1.1198e-02,  6.6645e-03,  8.6326e-03,\n",
       "         -1.2615e-02, -6.2120e-02, -2.1677e-02,  1.5573e-02, -1.0724e-02,\n",
       "          5.3292e-03,  1.9773e-02, -3.2717e-02, -5.9120e-03, -1.3378e-02,\n",
       "         -2.2270e-02,  3.8525e-02, -2.8453e-02, -1.7770e-03,  1.2364e-02,\n",
       "         -1.9286e-02, -1.4113e-02,  1.5446e-02, -2.6406e-02,  3.2373e-02,\n",
       "         -1.6748e-02,  3.2683e-02, -2.1252e-02,  6.2180e-03,  5.4561e-03,\n",
       "         -6.4639e-02, -5.1321e-03, -1.6781e-02, -5.1885e-03, -4.9862e-03,\n",
       "         -8.1847e-03,  3.0402e-02,  2.0590e-02,  5.0110e-03, -1.9592e-02,\n",
       "         -5.0750e-03,  1.4113e-03,  2.3685e-02, -1.4316e-03, -1.5388e-02,\n",
       "         -9.6907e-03,  3.4544e-02,  4.6709e-02, -6.1649e-03,  1.1394e-02,\n",
       "          2.9584e-02, -4.9230e-03,  4.3680e-02,  9.3000e-03,  1.3324e-02,\n",
       "          5.0311e-03,  1.9785e-02, -4.1033e-02,  3.8354e-03, -5.2759e-04,\n",
       "         -2.4752e-02, -4.3273e-02, -2.8343e-02,  1.5860e-02, -1.2626e-04,\n",
       "         -2.1446e-02, -4.5931e-02,  1.1384e-03, -2.5586e-02, -3.0066e-02,\n",
       "         -1.1024e-03,  2.0834e-02,  1.7674e-02,  2.5575e-02, -1.5182e-02,\n",
       "         -2.9695e-02,  3.0705e-02,  1.0275e-02,  2.7247e-02, -1.2018e-03,\n",
       "          4.6874e-04, -3.8634e-02,  3.2677e-02, -5.9397e-03, -2.7669e-02,\n",
       "         -4.2347e-03, -4.2313e-02,  3.2701e-02,  2.0869e-02,  2.3814e-02,\n",
       "         -2.1326e-02, -1.3058e-02, -4.5744e-03,  1.7947e-03,  5.8555e-03,\n",
       "         -6.5427e-02,  5.2272e-02,  2.8145e-02,  5.3632e-03,  1.1569e-02,\n",
       "          4.8893e-03, -4.4961e-02,  2.7535e-02, -6.5023e-03,  3.5730e-02,\n",
       "         -4.0594e-04,  7.5945e-03,  1.2542e-03,  2.9072e-02, -2.2166e-03,\n",
       "          1.4452e-02,  2.8194e-02, -2.7932e-02, -2.4642e-02, -1.8847e-02,\n",
       "         -9.9342e-03,  1.7155e-02,  1.2906e-03, -2.2249e-02, -1.2282e-02,\n",
       "         -1.0219e-02, -1.6098e-02,  4.4452e-02, -1.1888e-02,  1.8827e-02,\n",
       "         -2.6033e-03, -2.3047e-02, -4.0401e-02, -1.4773e-02,  1.7974e-03,\n",
       "         -2.8791e-02, -2.9709e-03, -2.0126e-02,  4.3176e-02,  1.2538e-02,\n",
       "          6.7761e-03,  4.7869e-02,  2.1536e-02, -1.3170e-02,  1.6315e-02,\n",
       "          3.0922e-02, -2.5308e-02,  3.2555e-02,  2.4698e-02, -5.2201e-02,\n",
       "          1.1884e-03,  4.5709e-03, -7.7384e-04, -1.6807e-02,  6.4506e-03,\n",
       "         -6.9446e-03,  1.3829e-02, -1.0855e-02, -2.6021e-02,  7.4843e-05,\n",
       "         -1.2278e-02, -1.2844e-02, -4.1930e-02, -1.0113e-02, -2.8517e-02,\n",
       "         -2.9311e-02, -1.1128e-02, -3.8222e-02, -2.8699e-02,  3.8625e-03,\n",
       "          4.0452e-02,  6.6500e-03, -1.7178e-02,  1.4048e-02, -4.8120e-02,\n",
       "          1.6034e-02,  2.1771e-02,  2.5781e-02, -1.6627e-03, -1.0276e-02,\n",
       "          1.4783e-02, -3.0765e-02, -1.7875e-02,  1.1920e-02,  2.1982e-04,\n",
       "          2.9462e-02, -5.8072e-03, -1.6773e-02, -1.1034e-02, -2.3651e-03,\n",
       "         -2.1602e-02, -2.4462e-02,  2.1304e-02,  2.1083e-02,  2.1041e-03,\n",
       "          1.2699e-02,  4.9367e-03,  1.7691e-03,  9.2066e-04,  2.7735e-03,\n",
       "         -1.5055e-02,  2.0285e-02,  1.9837e-02, -1.0016e-02, -1.0931e-03,\n",
       "          1.0740e-02,  3.0404e-02,  1.8542e-02, -2.2956e-02, -2.0576e-02,\n",
       "         -2.2800e-02, -3.6289e-03, -2.2179e-02, -2.0165e-02,  1.1932e-02,\n",
       "         -2.9586e-02,  7.9477e-03, -8.4548e-03,  1.5498e-01,  4.2130e-02,\n",
       "          3.1762e-03, -3.2276e-02,  3.4060e-02, -1.0722e-02, -7.7839e-03,\n",
       "         -1.0632e-02, -1.0884e-02,  2.9263e-02, -1.5401e-02,  1.6092e-02,\n",
       "         -4.2592e-03,  1.6592e-02,  4.2801e-02,  1.2241e-02, -2.4295e-02,\n",
       "         -1.6302e-02, -5.1500e-02, -2.0818e-03, -2.0723e-02,  3.0654e-02,\n",
       "          1.1289e-02, -1.9391e-02,  7.8560e-03,  3.2054e-02,  1.0721e-02,\n",
       "         -1.5359e-02,  6.7414e-03,  1.6680e-02, -3.3961e-02, -8.4522e-03,\n",
       "         -3.5319e-03,  2.0295e-02, -1.3563e-02,  3.0023e-02, -8.7162e-03,\n",
       "         -4.3029e-02, -2.1272e-02,  1.9648e-02, -8.1887e-03, -1.8597e-02,\n",
       "          2.3044e-02,  1.1635e-02,  7.3498e-03,  6.3543e-02, -2.6997e-02,\n",
       "         -1.8910e-02,  2.9265e-02,  1.0239e-02,  1.1607e-03, -1.3874e-02,\n",
       "         -2.9255e-02, -6.2359e-03,  3.7695e-03, -3.6382e-02,  2.5332e-02,\n",
       "         -1.6439e-02, -1.6168e-02,  1.8598e-02, -7.9341e-03,  3.1545e-02,\n",
       "          1.1092e-02, -1.3297e-02, -7.3804e-03,  5.0112e-04, -2.1842e-02,\n",
       "          1.4957e-02, -1.7725e-02, -3.3329e-02, -6.8275e-03,  2.8796e-02,\n",
       "          3.3355e-02, -1.7959e-04,  1.1854e-02, -4.7277e-03, -1.5528e-03,\n",
       "         -9.6303e-03, -1.6141e-02, -2.1904e-01,  1.2225e-02, -1.8794e-02,\n",
       "          8.5799e-03,  4.5090e-03, -8.9125e-03, -4.6590e-03,  7.1458e-03,\n",
       "          4.4522e-03, -2.2133e-02,  4.2720e-03,  2.0050e-02,  2.5274e-02,\n",
       "          2.8115e-02,  1.2786e-02,  1.7307e-02,  3.8415e-03, -2.7871e-02,\n",
       "         -9.6849e-03, -2.5714e-02,  2.0965e-02,  1.9925e-02, -4.9243e-03,\n",
       "         -3.9405e-03, -7.9126e-04,  3.1379e-02, -1.2294e-02, -1.4692e-02,\n",
       "          3.4345e-03,  4.0286e-02, -2.3569e-02,  4.0635e-02, -1.3191e-03,\n",
       "         -8.6577e-03, -4.2429e-03, -2.5825e-03, -3.3985e-02,  4.3198e-03,\n",
       "          2.5252e-02,  3.0673e-03, -4.2617e-03,  3.0536e-02,  4.2067e-03,\n",
       "          2.5436e-02, -2.0076e-02, -2.4330e-02,  3.4068e-02, -7.7307e-03,\n",
       "          2.8882e-02,  1.3579e-02,  1.3400e-02, -5.9470e-03, -1.2381e-03,\n",
       "          5.6120e-04,  6.1057e-03,  9.1619e-03, -6.7492e-03, -5.0505e-03,\n",
       "          3.8505e-03, -1.9438e-02,  2.0235e-02, -2.6651e-04, -1.1840e-02,\n",
       "          1.5102e-02,  1.3968e-02, -1.6327e-03,  1.0744e-02, -7.0666e-03,\n",
       "          2.8145e-03,  2.0415e-02, -1.5380e-02, -1.9438e-02,  2.3568e-02,\n",
       "          1.5380e-03, -2.4944e-02, -4.7064e-03,  3.0945e-02,  1.0194e-02,\n",
       "          2.0137e-02,  2.1682e-02, -2.2951e-02, -1.3512e-02, -2.5622e-02,\n",
       "          1.1789e-02, -1.6320e-02, -5.5634e-01, -9.7142e-03, -2.7217e-02,\n",
       "         -2.9727e-02,  2.2454e-02, -4.5528e-02,  1.1885e-02, -3.9358e-02,\n",
       "          1.4207e-02, -5.6358e-03,  8.3242e-03,  4.3432e-03, -1.5239e-02,\n",
       "         -8.2544e-03,  9.6040e-03,  2.1604e-02]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_embedding(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Audric Ho\\AppData\\Local\\Temp\\ipykernel_10296\\1698119748.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embeddings = torch.nn.functional.normalize(torch.tensor(get_word_embedding(sentence)[:1]), p=2, dim=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9317314202044775"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"tax relief\", \"employee benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Audric Ho\\AppData\\Local\\Temp\\ipykernel_10296\\1698119748.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embeddings = torch.nn.functional.normalize(torch.tensor(get_word_embedding(sentence)[:1]), p=2, dim=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9344516149574389"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"the world is green\", \"i hate soda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Audric Ho\\AppData\\Local\\Temp\\ipykernel_10296\\1698119748.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  sentence_embeddings = torch.nn.functional.normalize(torch.tensor(get_word_embedding(sentence)[:1]), p=2, dim=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9999997615813925"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_length(get_sentence_embedding(\"i love rice\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-base-uncased",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
