{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformers, more interesting one!\n",
    "- can learn and see the mean pooling too!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['This is an example sentence', 'Each sentence is converted']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\embedding\\miniLM\\MiniLM-venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "#sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "#embeddings = model.encode(sentences)\n",
    "def get_sentence_embedding(sentence):\n",
    "    return model.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "def get_length(embedding_1d):\n",
    "    sum = 0\n",
    "    for i in embedding_1d:\n",
    "        sum+=(i**2)\n",
    "    return math.sqrt(sum)\n",
    "def normalise_embedding(embedding_1d):\n",
    "    length = get_length(embedding_1d)\n",
    "    for i in range(len(embedding_1d)):\n",
    "        embedding_1d[i] /= length\n",
    "def get_normalise_embedding(embedding_1d):\n",
    "    if type(embedding_1d) is torch.Tensor:\n",
    "        temp_embedding_1d = (embedding_1d.detach().numpy()).copy()\n",
    "    else:\n",
    "        temp_embedding_1d = embedding_1d.copy()\n",
    "    length = get_length(temp_embedding_1d)\n",
    "    for i in range(len(temp_embedding_1d)):\n",
    "        temp_embedding_1d[i] /= length\n",
    "    return temp_embedding_1d\n",
    "\n",
    "\n",
    "def cosine_sim(embedding_1, embedding_2):\n",
    "    embedding_1 = get_normalise_embedding(embedding_1)\n",
    "    embedding_2 = get_normalise_embedding(embedding_2)\n",
    "    sim_sum = 0\n",
    "    for e_1, e_2 in zip(embedding_1, embedding_2):\n",
    "        sim_sum += (e_1*e_2)\n",
    "    return sim_sum\n",
    "def norm_ed_cosine_sim(embedding_1, embedding_2):\n",
    "    sim_sum = 0\n",
    "    for e_1, e_2 in zip(embedding_1, embedding_2):\n",
    "        sim_sum += (e_1*e_2)\n",
    "    return sim_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_cos_sim(t1, t2):\n",
    "    return cosine_sim(get_sentence_embedding(t1), get_sentence_embedding(t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47740065903457224"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"tax relief\", \"employee benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6383227884201512"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"tax relief for employees\", \"employee benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19512417193595885"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"the world is green\", \"i hate soda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_sent_cos_sim(model_emb_func, t1, t2, additional_nesting = False):\n",
    "    if additional_nesting:\n",
    "        return cosine_sim(model_emb_func(t1)[0], model_emb_func(t2)[0])    \n",
    "    return cosine_sim(model_emb_func(t1), model_emb_func(t2))\n",
    "\n",
    "def test_emb_model(model_emb_func, sent_pair_comparison_list, sorting = False, additional_nesting = False):\n",
    "    ending_dict = {}\n",
    "    for comp1, comp2 in sent_pair_comparison_list:\n",
    "        ending_dict[(comp1, comp2)] = generic_sent_cos_sim(model_emb_func, comp1, comp2, additional_nesting)\n",
    "    if sorting:\n",
    "        sorted_ending_dict = {comps:comps_res for comps, comps_res in (sorted(ending_dict.items(), key=lambda dict_item: dict_item[1], reverse = True))}\n",
    "        return sorted_ending_dict\n",
    "    return ending_dict\n",
    "def test_emb_model_results(ending_dict, sorting = False):\n",
    "    print(\"Similarity level:\")\n",
    "    #res_sum = 0\n",
    "    if sorting:\n",
    "        for comps, res in (sorted(ending_dict.items(), key= lambda dict_item: dict_item[1], reverse=True)):\n",
    "            ## print(f\"{comps[0]:20.5}-{comps[1]:5.20}: {res:.5}\") # \"{:min_pad.max_pad}\", max pad is essentially also the max number of chars permitted!!\n",
    "            print(f\"{comps[0]:20.20} /-/ {comps[1]:20.20} : {res:.5}\")\n",
    "            #res_sum += res\n",
    "    else:\n",
    "        for comps, res in ending_dict.items():\n",
    "            ## print(f\"{comps[0]:20.5}-{comps[1]:5.20}: {res:.5}\") # \"{:min_pad.max_pad}\", max pad is essentially also the max number of chars permitted!!\n",
    "            print(f\"{comps[0]:20.20} /-/ {comps[1]:20.20} : {res:.5}\")\n",
    "            #res_sum += res\n",
    "        \n",
    "    ## res_sum no purpose and stuff yet since no measure of accuracy present, like it should/should not match, dont know so cannot say the sum is good or not, etc or avg, but later on can try with these and maybe weighted based on certain comparisons more impt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_pair_list = [(\"tax relief\", \"employee benefit\"), (\"tax relief for employees\", \"employee benefit\"), (\"the world is green\", \"i hate soda\")]\n",
    "comparison_pair_list.append((\"yearly flight tickets home for employees\", \"home passage\"))\n",
    "comparison_pair_list.append((\"yearly flight tickets home for employees\", \"subsidised flights to employee home country\"))\n",
    "comparison_pair_list.append((\"night shift\", \"overtime pay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity level:\n",
      "tax relief for emplo /-/ employee benefit     : 0.63832\n",
      "yearly flight ticket /-/ subsidised flights t : 0.58396\n",
      "tax relief           /-/ employee benefit     : 0.4774\n",
      "night shift          /-/ overtime pay         : 0.27412\n",
      "the world is green   /-/ i hate soda          : 0.19512\n",
      "yearly flight ticket /-/ home passage         : 0.17969\n"
     ]
    }
   ],
   "source": [
    "# eg:\n",
    "## function is \"get_sentenceS_embedding\"\n",
    "## comparison list is \"comparison_pair_list\"\n",
    "res_dict = test_emb_model(get_sentence_embedding, comparison_pair_list, sorting=False , additional_nesting=False)\n",
    "test_emb_model_results(res_dict, sorting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MiniLM-venv-kernel",
   "language": "python",
   "name": "minilm-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
