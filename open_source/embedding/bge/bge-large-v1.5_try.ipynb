{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Audric Ho\\Downloads\\LLM related stuff\\open_source\\embedding\\bge\\bge-venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-large-en-v1.5\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-large-en-v1.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings: tensor([[ 0.0356,  0.0118,  0.0048,  ..., -0.0115, -0.0170, -0.0047],\n",
      "        [ 0.0287, -0.0219, -0.0046,  ..., -0.0400, -0.0092,  0.0066]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "#tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-large-zh-v1.5')\n",
    "#model = AutoModel.from_pretrained('BAAI/bge-large-zh-v1.5')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-large-en-v1.5\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "#sentences = [\"样例数据-1\", \"样例数据-2\"]\n",
    "sentences = [\"i like you\", \"i want to kill you\"]\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "# for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "# encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "    # Perform pooling. In this case, cls pooling.\n",
    "    sentence_embeddings = model_output[0][:, 0]\n",
    "# normalize embeddings\n",
    "sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)\n",
    "print(\"Sentence embeddings:\", sentence_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "def get_length(embedding_1d):\n",
    "    sum = 0\n",
    "    for i in embedding_1d:\n",
    "        sum+=(i**2)\n",
    "    return math.sqrt(sum)\n",
    "def normalise_embedding(embedding_1d):\n",
    "    length = get_length(embedding_1d)\n",
    "    for i in range(len(embedding_1d)):\n",
    "        embedding_1d[i] /= length\n",
    "def get_normalise_embedding(embedding_1d):\n",
    "    if type(embedding_1d) is torch.Tensor:\n",
    "        temp_embedding_1d = (embedding_1d.detach().numpy()).copy()\n",
    "    else:\n",
    "        temp_embedding_1d = embedding_1d.copy()\n",
    "    length = get_length(temp_embedding_1d)\n",
    "    for i in range(len(temp_embedding_1d)):\n",
    "        temp_embedding_1d[i] /= length\n",
    "    return temp_embedding_1d\n",
    "\n",
    "\n",
    "def cosine_sim(embedding_1, embedding_2):\n",
    "    embedding_1 = get_normalise_embedding(embedding_1)\n",
    "    embedding_2 = get_normalise_embedding(embedding_2)\n",
    "    sim_sum = 0\n",
    "    for e_1, e_2 in zip(embedding_1, embedding_2):\n",
    "        sim_sum += (e_1*e_2)\n",
    "    return sim_sum\n",
    "def norm_ed_cosine_sim(embedding_1, embedding_2):\n",
    "    sim_sum = 0\n",
    "    for e_1, e_2 in zip(embedding_1, embedding_2):\n",
    "        sim_sum += (e_1*e_2)\n",
    "    return sim_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 0.6573,  0.2178,  0.0891,  ..., -0.2121, -0.3139, -0.0860],\n",
       "         [ 0.3542,  0.2991,  0.4106,  ..., -0.1956, -0.4351, -0.1892],\n",
       "         [ 0.2387,  0.2182,  0.5341,  ..., -0.0778, -0.8269, -0.8682],\n",
       "         ...,\n",
       "         [ 0.4592,  0.6778,  0.0939,  ..., -0.1172, -0.4387, -0.5490],\n",
       "         [ 0.4478,  0.3215, -0.0040,  ..., -0.0741, -0.4161, -0.1557],\n",
       "         [ 0.4373,  0.3175,  0.0090,  ..., -0.0785, -0.4132, -0.1504]],\n",
       "\n",
       "        [[ 0.5374, -0.4100, -0.0864,  ..., -0.7484, -0.1726,  0.1235],\n",
       "         [ 0.4699, -0.3668,  0.3440,  ..., -0.7859, -0.2531,  0.0738],\n",
       "         [ 0.1904, -0.1502,  0.3137,  ..., -0.4904, -0.7493,  0.1013],\n",
       "         ...,\n",
       "         [ 0.4872, -0.3801, -0.0678,  ..., -0.6916, -0.1074,  0.1410],\n",
       "         [ 0.5912, -0.4069,  0.1806,  ..., -0.6609, -0.0664,  0.3569],\n",
       "         [ 0.2079, -0.2927, -0.0442,  ..., -1.2791, -0.5430, -0.1691]]]), pooler_output=tensor([[-0.9754, -0.6804, -0.6011,  ..., -0.2353,  0.9816, -0.8564],\n",
       "        [-0.8543, -0.5125, -0.8204,  ..., -0.0988,  0.9674, -0.7822]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.6573,  0.2178,  0.0891,  ..., -0.2121, -0.3139, -0.0860],\n",
       "          [ 0.3542,  0.2991,  0.4106,  ..., -0.1956, -0.4351, -0.1892],\n",
       "          [ 0.2387,  0.2182,  0.5341,  ..., -0.0778, -0.8269, -0.8682],\n",
       "          ...,\n",
       "          [ 0.4592,  0.6778,  0.0939,  ..., -0.1172, -0.4387, -0.5490],\n",
       "          [ 0.4478,  0.3215, -0.0040,  ..., -0.0741, -0.4161, -0.1557],\n",
       "          [ 0.4373,  0.3175,  0.0090,  ..., -0.0785, -0.4132, -0.1504]],\n",
       " \n",
       "         [[ 0.5374, -0.4100, -0.0864,  ..., -0.7484, -0.1726,  0.1235],\n",
       "          [ 0.4699, -0.3668,  0.3440,  ..., -0.7859, -0.2531,  0.0738],\n",
       "          [ 0.1904, -0.1502,  0.3137,  ..., -0.4904, -0.7493,  0.1013],\n",
       "          ...,\n",
       "          [ 0.4872, -0.3801, -0.0678,  ..., -0.6916, -0.1074,  0.1410],\n",
       "          [ 0.5912, -0.4069,  0.1806,  ..., -0.6609, -0.0664,  0.3569],\n",
       "          [ 0.2079, -0.2927, -0.0442,  ..., -1.2791, -0.5430, -0.1691]]]),\n",
       " tensor([[[ 0.6573,  0.2178,  0.0891,  ..., -0.2121, -0.3139, -0.0860],\n",
       "          [ 0.3542,  0.2991,  0.4106,  ..., -0.1956, -0.4351, -0.1892],\n",
       "          [ 0.2387,  0.2182,  0.5341,  ..., -0.0778, -0.8269, -0.8682],\n",
       "          ...,\n",
       "          [ 0.4592,  0.6778,  0.0939,  ..., -0.1172, -0.4387, -0.5490],\n",
       "          [ 0.4478,  0.3215, -0.0040,  ..., -0.0741, -0.4161, -0.1557],\n",
       "          [ 0.4373,  0.3175,  0.0090,  ..., -0.0785, -0.4132, -0.1504]],\n",
       " \n",
       "         [[ 0.5374, -0.4100, -0.0864,  ..., -0.7484, -0.1726,  0.1235],\n",
       "          [ 0.4699, -0.3668,  0.3440,  ..., -0.7859, -0.2531,  0.0738],\n",
       "          [ 0.1904, -0.1502,  0.3137,  ..., -0.4904, -0.7493,  0.1013],\n",
       "          ...,\n",
       "          [ 0.4872, -0.3801, -0.0678,  ..., -0.6916, -0.1074,  0.1410],\n",
       "          [ 0.5912, -0.4069,  0.1806,  ..., -0.6609, -0.0664,  0.3569],\n",
       "          [ 0.2079, -0.2927, -0.0442,  ..., -1.2791, -0.5430, -0.1691]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[0], model_output.last_hidden_state # last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.9754, -0.6804, -0.6011,  ..., -0.2353,  0.9816, -0.8564],\n",
       "         [-0.8543, -0.5125, -0.8204,  ..., -0.0988,  0.9674, -0.7822]]),\n",
       " tensor([[-0.9754, -0.6804, -0.6011,  ..., -0.2353,  0.9816, -0.8564],\n",
       "         [-0.8543, -0.5125, -0.8204,  ..., -0.0988,  0.9674, -0.7822]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output[1], model_output.pooler_output # pooler_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "#tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-large-zh-v1.5')\n",
    "#model = AutoModel.from_pretrained('BAAI/bge-large-zh-v1.5')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-large-en-v1.5\")\n",
    "model = AutoModel.from_pretrained(\"BAAI/bge-large-en-v1.5\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def get_sentenceS_embedding(sentenceS): ## already normalised due to \"torch.nn.functional.normalize\" function\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentenceS, padding=True, truncation=True, return_tensors='pt')\n",
    "    # for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "    # encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        # Perform pooling. In this case, cls pooling.\n",
    "        sentenceS_embeddings = model_output[0][:, 0]\n",
    "    # normalize embeddings\n",
    "    sentenceS_embeddings = torch.nn.functional.normalize(sentenceS_embeddings, p=2, dim=1)\n",
    "    #print(\"SentenceS embeddings:\", sentenceS_embeddings)\n",
    "\n",
    "    return sentenceS_embeddings ## if not input a list of sentences, then just one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': tensor([[ 101, 1045, 2066, 2017,  102,    0,    0],\n",
       "         [ 101, 1045, 2215, 2000, 3102, 2017,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1]])},\n",
       " tensor([[[ 0.6573,  0.2178,  0.0891,  ..., -0.2121, -0.3139, -0.0860],\n",
       "          [ 0.3542,  0.2991,  0.4106,  ..., -0.1956, -0.4351, -0.1892],\n",
       "          [ 0.2387,  0.2182,  0.5341,  ..., -0.0778, -0.8269, -0.8682],\n",
       "          ...,\n",
       "          [ 0.4592,  0.6778,  0.0939,  ..., -0.1172, -0.4387, -0.5490],\n",
       "          [ 0.4478,  0.3215, -0.0040,  ..., -0.0741, -0.4161, -0.1557],\n",
       "          [ 0.4373,  0.3175,  0.0090,  ..., -0.0785, -0.4132, -0.1504]],\n",
       " \n",
       "         [[ 0.5374, -0.4100, -0.0864,  ..., -0.7484, -0.1726,  0.1235],\n",
       "          [ 0.4699, -0.3668,  0.3440,  ..., -0.7859, -0.2531,  0.0738],\n",
       "          [ 0.1904, -0.1502,  0.3137,  ..., -0.4904, -0.7493,  0.1013],\n",
       "          ...,\n",
       "          [ 0.4872, -0.3801, -0.0678,  ..., -0.6916, -0.1074,  0.1410],\n",
       "          [ 0.5912, -0.4069,  0.1806,  ..., -0.6609, -0.0664,  0.3569],\n",
       "          [ 0.2079, -0.2927, -0.0442,  ..., -1.2791, -0.5430, -0.1691]]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input, model_output.last_hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 7, 7, 1024, 1024)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_output.last_hidden_state), len(model_output.last_hidden_state[0]), len(model_output.last_hidden_state[1]), len(model_output.last_hidden_state[0][0]), len(model_output.last_hidden_state[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6573,  0.2178,  0.0891,  ..., -0.2121, -0.3139, -0.0860],\n",
       "        [ 0.3542,  0.2991,  0.4106,  ..., -0.1956, -0.4351, -0.1892],\n",
       "        [ 0.2387,  0.2182,  0.5341,  ..., -0.0778, -0.8269, -0.8682],\n",
       "        ...,\n",
       "        [ 0.4592,  0.6778,  0.0939,  ..., -0.1172, -0.4387, -0.5490],\n",
       "        [ 0.4478,  0.3215, -0.0040,  ..., -0.0741, -0.4161, -0.1557],\n",
       "        [ 0.4373,  0.3175,  0.0090,  ..., -0.0785, -0.4132, -0.1504]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.last_hidden_state[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5374, -0.4100, -0.0864,  ..., -0.7484, -0.1726,  0.1235],\n",
       "        [ 0.4699, -0.3668,  0.3440,  ..., -0.7859, -0.2531,  0.0738],\n",
       "        [ 0.1904, -0.1502,  0.3137,  ..., -0.4904, -0.7493,  0.1013],\n",
       "        ...,\n",
       "        [ 0.4872, -0.3801, -0.0678,  ..., -0.6916, -0.1074,  0.1410],\n",
       "        [ 0.5912, -0.4069,  0.1806,  ..., -0.6609, -0.0664,  0.3569],\n",
       "        [ 0.2079, -0.2927, -0.0442,  ..., -1.2791, -0.5430, -0.1691]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.last_hidden_state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6573,  0.2178,  0.0891,  ..., -0.2121, -0.3139, -0.0860],\n",
       "        [ 0.5374, -0.4100, -0.0864,  ..., -0.7484, -0.1726,  0.1235]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0619,  0.0241, -0.0185,  ...,  0.0011, -0.0292, -0.0021]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentenceS_embedding(\"hi there hero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0619,  0.0241, -0.0185,  ...,  0.0011, -0.0292, -0.0021],\n",
       "        [ 0.0253,  0.0182, -0.0108,  ..., -0.0258,  0.0063, -0.0036]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentenceS_embedding([\"hi there hero\", \"yolo is the name\"]) ## if accept list, then 2 output, but if not then yea!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_cos_sim(t1, t2):\n",
    "    return cosine_sim(get_sentenceS_embedding(t1)[0], get_sentenceS_embedding(t2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938344566627492"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"tax relief\", \"employee benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801148301470235"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"tax relief for employees\", \"employee benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4368856924218676"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim(\"the world is green\", \"i hate soda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 1024)\n",
       "    (token_type_embeddings): Embedding(2, 1024)\n",
       "    (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-23): 24 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_cos_sim_v2_add_padding(t1, t2):\n",
    "    sent_emb_list = get_sentenceS_embedding([t1, t2])\n",
    "    return cosine_sim(sent_emb_list[0], sent_emb_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6938344566627492"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim_v2_add_padding(\"tax relief\", \"employee benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.801148303952786"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim_v2_add_padding(\"tax relief for employees\", \"employee benefit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43688567712712256"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_cos_sim_v2_add_padding(\"the world is green\", \"i hate soda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_cos_sim(t1, t2):\n",
    "    return cosine_sim(get_sentenceS_embedding(t1)[0], get_sentenceS_embedding(t2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generic_sent_cos_sim(model_emb_func, t1, t2, additional_nesting = False):\n",
    "    if additional_nesting:\n",
    "        return cosine_sim(model_emb_func(t1)[0], model_emb_func(t2)[0])    \n",
    "    return cosine_sim(model_emb_func(t1), model_emb_func(t2))\n",
    "\n",
    "def test_emb_model(model_emb_func, sent_pair_comparison_list, sorting = False, additional_nesting = False):\n",
    "    ending_dict = {}\n",
    "    for comp1, comp2 in sent_pair_comparison_list:\n",
    "        ending_dict[(comp1, comp2)] = generic_sent_cos_sim(model_emb_func, comp1, comp2, additional_nesting)\n",
    "    if sorting:\n",
    "        sorted_ending_dict = {comps:comps_res for comps, comps_res in (sorted(ending_dict.items(), key=lambda dict_item: dict_item[1], reverse = True))}\n",
    "        return sorted_ending_dict\n",
    "    return ending_dict\n",
    "def test_emb_model_results(ending_dict, sorting = False):\n",
    "    print(\"Similarity level:\")\n",
    "    #res_sum = 0\n",
    "    if sorting:\n",
    "        for comps, res in (sorted(ending_dict.items(), key= lambda dict_item: dict_item[1], reverse=True)):\n",
    "            ## print(f\"{comps[0]:20.5}-{comps[1]:5.20}: {res:.5}\") # \"{:min_pad.max_pad}\", max pad is essentially also the max number of chars permitted!!\n",
    "            print(f\"{comps[0]:20.20} /-/ {comps[1]:20.20} : {res:.5}\")\n",
    "            #res_sum += res\n",
    "    else:\n",
    "        for comps, res in ending_dict.items():\n",
    "            ## print(f\"{comps[0]:20.5}-{comps[1]:5.20}: {res:.5}\") # \"{:min_pad.max_pad}\", max pad is essentially also the max number of chars permitted!!\n",
    "            print(f\"{comps[0]:20.20} /-/ {comps[1]:20.20} : {res:.5}\")\n",
    "            #res_sum += res\n",
    "        \n",
    "    ## res_sum no purpose and stuff yet since no measure of accuracy present, like it should/should not match, dont know so cannot say the sum is good or not, etc or avg, but later on can try with these and maybe weighted based on certain comparisons more impt?\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_pair_list = [(\"tax relief\", \"employee benefit\"), (\"tax relief for employees\", \"employee benefit\"), (\"the world is green\", \"i hate soda\")]\n",
    "comparison_pair_list.append((\"yearly flight tickets home for employees\", \"home passage\"))\n",
    "comparison_pair_list.append((\"yearly flight tickets home for employees\", \"subsidised flights to employee home country\"))\n",
    "comparison_pair_list.append((\"night shift\", \"overtime pay\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## a bit useless since when test with \"get_tok_emb\", the padding does not affect cls token embedding so... yeaaa\n",
    "def test_emb_model_for_v2_only(sent_pair_comparison_list, sorting = False):\n",
    "    ending_dict = {}\n",
    "    for comp1, comp2 in sent_pair_comparison_list:\n",
    "        ending_dict[(comp1, comp2)] = sent_cos_sim_v2_add_padding(comp1, comp2)\n",
    "    if sorting:\n",
    "        sorted_ending_dict = {comps:comps_res for comps, comps_res in (sorted(ending_dict.items(), key=lambda dict_item: dict_item[1], reverse = True))}\n",
    "        return sorted_ending_dict\n",
    "    return ending_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity level:\n",
      "tax relief for emplo /-/ employee benefit     : 0.80115\n",
      "yearly flight ticket /-/ subsidised flights t : 0.78594\n",
      "tax relief           /-/ employee benefit     : 0.69383\n",
      "yearly flight ticket /-/ home passage         : 0.60292\n",
      "night shift          /-/ overtime pay         : 0.59808\n",
      "the world is green   /-/ i hate soda          : 0.43689\n"
     ]
    }
   ],
   "source": [
    "res_dict = test_emb_model(get_sentenceS_embedding, comparison_pair_list, sorting=False , additional_nesting=True)\n",
    "test_emb_model_results(res_dict, sorting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity level:\n",
      "tax relief for emplo /-/ employee benefit     : 0.80115\n",
      "yearly flight ticket /-/ subsidised flights t : 0.78594\n",
      "tax relief           /-/ employee benefit     : 0.69383\n",
      "yearly flight ticket /-/ home passage         : 0.60292\n",
      "night shift          /-/ overtime pay         : 0.59808\n",
      "the world is green   /-/ i hate soda          : 0.43689\n"
     ]
    }
   ],
   "source": [
    "res_dict_2 = test_emb_model_for_v2_only(comparison_pair_list, sorting=False)\n",
    "test_emb_model_results(res_dict_2, sorting=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0332,  0.0097,  0.0034,  ..., -0.0026, -0.0248, -0.0165]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentenceS_embedding(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0479,  0.0263,  0.0269,  ..., -0.0055, -0.0038, -0.0152]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentenceS_embedding(\"hey there vixen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0332,  0.0097,  0.0034,  ..., -0.0026, -0.0248, -0.0165],\n",
       "        [ 0.0479,  0.0263,  0.0269,  ..., -0.0055, -0.0038, -0.0152]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentenceS_embedding([\"hi there\", \"hey there vixen\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tok_emb(sentenceS): ## already normalised due to \"torch.nn.functional.normalize\" function\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(sentenceS, padding=True, truncation=True, return_tensors='pt')\n",
    "    # for s2p(short query to long passage) retrieval task, add an instruction to query (not add instruction for passages)\n",
    "    # encoded_input = tokenizer([instruction + q for q in queries], padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "        return model_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6008,  0.1745,  0.0613,  ..., -0.0468, -0.4488, -0.2984],\n",
       "         [ 0.5065,  0.3489,  0.3199,  ..., -0.1757, -0.3878, -0.2594],\n",
       "         [ 0.3713,  0.2677,  0.2782,  ..., -0.0365, -0.7608, -0.1022],\n",
       "         [ 0.6859,  0.3338,  0.4754,  ...,  0.1192, -0.8447, -0.4623]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tok_emb(\"hi there\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8593,  0.4729,  0.4823,  ..., -0.0984, -0.0689, -0.2731],\n",
       "         [ 0.6250,  0.7473,  0.8183,  ..., -0.1553, -0.0921, -0.4358],\n",
       "         [ 0.7799,  0.5088,  0.6466,  ..., -0.3468, -0.1345, -0.1214],\n",
       "         ...,\n",
       "         [ 0.6439,  0.3157,  0.6030,  ..., -0.3038,  0.5707, -0.6640],\n",
       "         [ 0.4212,  0.4156,  0.6218,  ..., -0.4362,  0.3738, -0.2459],\n",
       "         [ 0.4339,  0.2644,  0.6481,  ..., -0.3074,  0.0161, -0.4605]]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tok_emb(\"hey there vixen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6008,  0.1745,  0.0613,  ..., -0.0468, -0.4488, -0.2984],\n",
       "         [ 0.5065,  0.3489,  0.3199,  ..., -0.1757, -0.3878, -0.2594],\n",
       "         [ 0.3713,  0.2677,  0.2782,  ..., -0.0365, -0.7608, -0.1022],\n",
       "         [ 0.6859,  0.3338,  0.4754,  ...,  0.1192, -0.8447, -0.4623],\n",
       "         [ 0.6471,  0.2915, -0.1407,  ...,  0.0160, -0.7138, -0.1993]],\n",
       "\n",
       "        [[ 0.8593,  0.4729,  0.4823,  ..., -0.0984, -0.0689, -0.2731],\n",
       "         [ 0.6250,  0.7473,  0.8183,  ..., -0.1553, -0.0921, -0.4358],\n",
       "         [ 0.7799,  0.5088,  0.6466,  ..., -0.3468, -0.1345, -0.1214],\n",
       "         [ 0.2075,  0.4856,  0.5409,  ..., -0.0751,  0.4361, -0.2125],\n",
       "         [ 0.6439,  0.3157,  0.6030,  ..., -0.3038,  0.5707, -0.6640]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tok_emb([\"hi there\", \"hey there vixen\"])[:,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bge-venv-kernel",
   "language": "python",
   "name": "bge-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
